## Updated on 2025.10.19
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#vla>VLA</a></li>
    <li><a href=#long-horizon-planning>Long-horizon Planning</a></li>
    <li><a href=#open-vocabulary-robotics>Open Vocabulary Robotics</a></li>
    <li><a href=#robot-reasoning>Robot Reasoning</a></li>
    <li><a href=#subtask-decomposition>Subtask Decomposition</a></li>
    <li><a href=#robot-memory>Robot Memory</a></li>
    <li><a href=#temporal-understanding>Temporal Understanding</a></li>
    <li><a href=#robot-datasets>Robot Datasets</a></li>
    <li><a href=#multi-task-learning>Multi-task Learning</a></li>
    <li><a href=#robot-foundation-models>Robot Foundation Models</a></li>
    <li><a href=#vision-language-models>Vision Language Models</a></li>
  </ol>
</details>

## VLA

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Jiale Cao Team|[2508.09071](http://arxiv.org/abs/2508.09071)|**[link](https://linsun449.github.io/GeoVLA/)**|
|**2025-08-12**|**Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding**|Aleksandr I. Panov Team|[2508.09032](http://arxiv.org/abs/2508.09032)|null|
|**2025-08-13**|**Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors**|Hua Zou Team|[2508.08896](http://arxiv.org/abs/2508.08896)|null|
|**2025-08-12**|**DiffPhysCam: Differentiable Physics-Based Camera Simulation for Inverse Rendering and Embodied AI**|Dan Negrut Team|[2508.08831](http://arxiv.org/abs/2508.08831)|null|
|**2025-08-12**|**OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing**|Hengdi Zhang Team|[2508.08706](http://arxiv.org/abs/2508.08706)|null|
|**2025-08-11**|**ReferSplat: Referring Segmentation in 3D Gaussian Splatting**|Henghui Ding Team|[2508.08252](http://arxiv.org/abs/2508.08252)|**[link](https://github.com/heshuting555/ReferSplat)**|
|**2025-08-11**|**Reinforcement Learning in Vision: A Survey**|Mike Zheng Shou Team|[2508.08189](http://arxiv.org/abs/2508.08189)|null|
|**2025-08-12**|**MolmoAct: Action Reasoning Models that can Reason in Space**|Ranjay Krishna Team|[2508.07917](http://arxiv.org/abs/2508.07917)|**[link](https://allenai.org/blog/molmoact)**|
|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Lei Han Team|[2508.07770](http://arxiv.org/abs/2508.07770)|null|
|**2025-08-11**|**GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions**|Hong Zhang Team|[2508.07650](http://arxiv.org/abs/2508.07650)|null|
|**2025-08-10**|**FormCoach: Lift Smarter, Not Harder**|Lingjie Liu Team|[2508.07501](http://arxiv.org/abs/2508.07501)|null|
|**2025-08-09**|**PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems**|Nimal Gamini Senarath Team|[2508.06767](http://arxiv.org/abs/2508.06767)|null|
|**2025-08-12**|**IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model**|Li Sun Team|[2508.06571](http://arxiv.org/abs/2508.06571)|null|
|**2025-08-07**|**Safety of Embodied Navigation: A Survey**|Ronghui Mu Team|[2508.05855](http://arxiv.org/abs/2508.05855)|null|
|**2025-08-07**|**OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks**|Yueting Zhuang Team|[2508.05614](http://arxiv.org/abs/2508.05614)|**[link](https://zju-real.github.io/OmniEmbodied)**|
|**2025-08-07**|**CleanUpBench: Embodied Sweeping and Grasping Benchmark**|Shenghai Yuan Team|[2508.05543](http://arxiv.org/abs/2508.05543)|null|
|**2025-08-07**|**Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control**|Hamid Reza Karimi Team|[2508.05342](http://arxiv.org/abs/2508.05342)|null|
|**2025-08-07**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Jorge Peña Queralta Team|[2508.05294](http://arxiv.org/abs/2508.05294)|null|
|**2025-08-07**|**Learning to See and Act: Task-Aware View Planning for Robotic Manipulation**|Liang Lin Team|[2508.05186](http://arxiv.org/abs/2508.05186)|**[link](https://hcplab-sysu.github.io/TAVP)**|
|**2025-08-06**|**Perceiving and Acting in First-Person: A Dataset and Benchmark for Egocentric Human-Object-Human Interactions**|Xiaokang Yang Team|[2508.04681](http://arxiv.org/abs/2508.04681)|**[link](https://liangxuy.github.io/InterVLA/)**|
|**2025-07-23**|**InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation**|Jiangmiao Pang Team|[2507.17520](http://arxiv.org/abs/2507.17520)|null|
|**2025-07-23**|**ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents**|Hesheng Wang Team|[2507.17462](http://arxiv.org/abs/2507.17462)|null|
|**2025-07-23**|**Confidence Calibration in Vision-Language-Action Models**|Richard Zemel Team|[2507.17383](http://arxiv.org/abs/2507.17383)|null|
|**2025-07-23**|**VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback**|Harold Soh Team|[2507.17294](http://arxiv.org/abs/2507.17294)|null|
|**2025-07-22**|**ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning**|Fu-En Yang Team|[2507.16815](http://arxiv.org/abs/2507.16815)|null|
|**2025-07-21**|**Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos**|Zongqing Lu Team|[2507.15597](http://arxiv.org/abs/2507.15597)|null|
|**2025-07-22**|**GR-3 Technical Report**|Yichu Yang Team|[2507.15493](http://arxiv.org/abs/2507.15493)|null|
|**2025-07-21**|**EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent**|Xinlei Chen Team|[2507.15428](http://arxiv.org/abs/2507.15428)|null|
|**2025-07-18**|**EdgeVLA: Efficient Vision-Language-Action Models**|Benjamin Bolte Team|[2507.14049](http://arxiv.org/abs/2507.14049)|null|
|**2025-07-21**|**LaViPlan : Language-Guided Visual Path Planning with RLVR**|Hayeon Oh Team|[2507.12911](http://arxiv.org/abs/2507.12911)|null|
|**2025-07-17**|**AnyPos: Automated Task-Agnostic Actions for Bimanual Manipulation**|Jun Zhu Team|[2507.12768](http://arxiv.org/abs/2507.12768)|null|
|**2025-07-20**|**PhysX-3D: Physical-Grounded 3D Asset Generation**|Ziwei Liu Team|[2507.12465](http://arxiv.org/abs/2507.12465)|null|
|**2025-07-18**|**EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos**|Xiaolong Wang Team|[2507.12440](http://arxiv.org/abs/2507.12440)|null|
|**2025-07-15**|**NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization**|Qijun Chen Team|[2507.10894](http://arxiv.org/abs/2507.10894)|null|
|**2025-07-14**|**React to This (RTT): A Nonverbal Turing Test for Embodied AI**|Angelica Lim Team|[2507.10812](http://arxiv.org/abs/2507.10812)|null|
|**2025-07-14**|**Vision Language Action Models in Robotic Manipulation: A Systematic Review**|Irfan Hussain Team|[2507.10672](http://arxiv.org/abs/2507.10672)|null|
|**2025-07-14**|**ViTCoT: Video-Text Interleaved Chain-of-Thought for Boosting Video Understanding in Large Language Models**|Libo Qin Team|[2507.09876](http://arxiv.org/abs/2507.09876)|null|
|**2025-07-12**|**Online Long-term Point Tracking in the Foundation Model Era**|Görkay Aydemir Team|[2507.09217](http://arxiv.org/abs/2507.09217)|null|
|**2025-07-12**|**Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization**|Yang Gao Team|[2507.09160](http://arxiv.org/abs/2507.09160)|null|
|**2025-07-15**|**View Invariant Learning for Vision-Language Navigation in Continuous Environments**|Mark Crowley Team|[2507.08831](http://arxiv.org/abs/2507.08831)|null|
|**2025-07-11**|**LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning**|Lei Fan Team|[2507.08496](http://arxiv.org/abs/2507.08496)|null|
|**2025-07-10**|**SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes**|Mingming Gong Team|[2507.07781](http://arxiv.org/abs/2507.07781)|null|
|**2025-07-09**|**A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding**|Yanwei Fu Team|[2507.06719](http://arxiv.org/abs/2507.06719)|null|
|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Nick Haber Team|[2507.06484](http://arxiv.org/abs/2507.06484)|null|
|**2025-07-08**|**DreamArt: Generating Interactable Articulated Objects from a Single Image**|Siyuan Huang Team|[2507.05763](http://arxiv.org/abs/2507.05763)|null|
|**2025-07-08**|**PAPRLE (Plug-And-Play Robotic Limb Environment): A Modular Ecosystem for Robotic Limbs**|Joohyung Kim Team|[2507.05555](http://arxiv.org/abs/2507.05555)|null|
|**2025-07-07**|**NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving**|Cheng Lu Team|[2507.05227](http://arxiv.org/abs/2507.05227)|null|
|**2025-07-07**|**EmbodieDreamer: Advancing Real2Sim2Real Transfer for Policy Training via Embodied World Modeling**|Xingang Wang Team|[2507.05198](http://arxiv.org/abs/2507.05198)|null|
|**2025-07-10**|**VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting**|Yanzhi Wang Team|[2507.05116](http://arxiv.org/abs/2507.05116)|null|
|**2025-07-07**|**Training-free Generation of Temporally Consistent Rewards from VLMs**|Jian Tang Team|[2507.04789](http://arxiv.org/abs/2507.04789)|null|
|**2025-07-06**|**SimLauncher: Launching Sample-Efficient Real-world Robotic Reinforcement Learning via Simulation Pre-training**|Hao Dong Team|[2507.04452](http://arxiv.org/abs/2507.04452)|null|
|**2025-07-06**|**DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge**|Xin Jin Team|[2507.04447](http://arxiv.org/abs/2507.04447)|null|
|**2025-07-06**|**Hijacking JARVIS: Benchmarking Mobile GUI Agents against Unprivileged Third Parties**|Yunxin Liu Team|[2507.04227](http://arxiv.org/abs/2507.04227)|null|
|**2025-07-05**|**Move to Understand a 3D Scene: Bridging Visual Grounding and Exploration for Efficient and Versatile Embodied Navigation**|Qing Li Team|[2507.04047](http://arxiv.org/abs/2507.04047)|null|
|**2025-07-03**|**DexVLG: Dexterous Vision-Language-Grasp Model at Scale**|He Wang Team|[2507.02747](http://arxiv.org/abs/2507.02747)|null|
|**2025-07-02**|**cVLA: Towards Efficient Camera-Space VLAs**|Thomas Brox Team|[2507.02190](http://arxiv.org/abs/2507.02190)|null|
|**2025-07-05**|**RoboBrain 2.0 Technical Report**|Shanghang Zhang Team|[2507.02029](http://arxiv.org/abs/2507.02029)|null|
|**2025-07-02**|**A Survey on Vision-Language-Action Models: An Action Tokenization Perspective**|Yaodong Yang Team|[2507.01925](http://arxiv.org/abs/2507.01925)|null|
|**2025-07-02**|**MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics**|Nadiya Shvai Team|[2507.01843](http://arxiv.org/abs/2507.01843)|null|
|**2025-07-02**|**What does really matter in image goal navigation?**|Christian Wolf Team|[2507.01667](http://arxiv.org/abs/2507.01667)|null|
|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Yanwei Fu Team|[2507.01424](http://arxiv.org/abs/2507.01424)|null|
|**2025-07-01**|**VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers**|Tong He Team|[2507.01016](http://arxiv.org/abs/2507.01016)|null|
|**2025-07-01**|**A Survey: Learning Embodied Intelligence from Physical Simulators and World Models**|Qionghai Dai Team|[2507.00917](http://arxiv.org/abs/2507.00917)|null|
|**2025-07-01**|**Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding**|Bo Zhao Team|[2507.00416](http://arxiv.org/abs/2507.00416)|null|

<p align=right>(<a href=#updated-on-20251019>back to top</a>)</p>

## Long-horizon Planning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-11**|**ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks**|Chunhua Shen Team|[2508.08240](http://arxiv.org/abs/2508.08240)|null|
|**2025-08-11**|**MLego: Interactive and Scalable Topic Exploration Through Model Reuse**|X. Sean Wang Team|[2508.07654](http://arxiv.org/abs/2508.07654)|null|
|**2025-08-11**|**GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions**|Hong Zhang Team|[2508.07650](http://arxiv.org/abs/2508.07650)|null|
|**2025-08-11**|**In-situ Value-aligned Human-Robot Interactions with Physical Constraints**|Zilong Zheng Team|[2508.07606](http://arxiv.org/abs/2508.07606)|null|
|**2025-08-09**|**$\mathcal{P}^3$ : Toward Versatile Embodied Agents**|Feng Zheng Team|[2508.07033](http://arxiv.org/abs/2508.07033)|null|
|**2025-08-07**|**Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning**|Sebastian Schreiber Team|[2508.05888](http://arxiv.org/abs/2508.05888)|null|
|**2025-08-05**|**Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark**|Muhammad Shafique Team|[2508.05674](http://arxiv.org/abs/2508.05674)|null|
|**2025-08-07**|**Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision**|Hao Li Team|[2508.05606](http://arxiv.org/abs/2508.05606)|**[link](https://sais-fuxi.github.io/projects/uni-cot/)**|
|**2025-08-05**|**Adaptive AI Agent Placement and Migration in Edge Intelligence Systems**|Weijia Jia Team|[2508.03345](http://arxiv.org/abs/2508.03345)|null|
|**2025-08-05**|**AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots**|Irene Li Team|[2508.02999](http://arxiv.org/abs/2508.02999)|null|
|**2025-08-02**|**How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective**|Gerard Canal Team|[2508.01300](http://arxiv.org/abs/2508.01300)|null|
|**2025-07-31**|**Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study**|Patrik Zips Team|[2507.23589](http://arxiv.org/abs/2507.23589)|null|
|**2025-07-29**|**MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation**|Songchang Jin Team|[2507.21953](http://arxiv.org/abs/2507.21953)|null|
|**2025-07-29**|**Pretraining a Unified PDDL Domain from Real-World Demonstrations for Generalizable Robot Task Planning**|Panpan Cai Team|[2507.21545](http://arxiv.org/abs/2507.21545)|null|
|**2025-07-29**|**Humanoid Occupancy: Enabling A Generalized Multimodal Occupancy Perception System on Humanoid Robots**|Qiang Zhang Team|[2507.20217](http://arxiv.org/abs/2507.20217)|null|
|**2025-07-26**|**CLASP: General-Purpose Clothes Manipulation with Semantic Keypoints**|David Hsu Team|[2507.19983](http://arxiv.org/abs/2507.19983)|null|
|**2025-07-26**|**AgentMesh: A Cooperative Multi-Agent Generative AI Framework for Software Development Automation**|Sourena Khanzadeh Team|[2507.19902](http://arxiv.org/abs/2507.19902)|null|
|**2025-07-26**|**Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models**|Mateja Novak Team|[2507.19854](http://arxiv.org/abs/2507.19854)|null|
|**2025-07-25**|**MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI Agents**|Wenhai Wang Team|[2507.19478](http://arxiv.org/abs/2507.19478)|null|
|**2025-07-29**|**VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback**|Harold Soh Team|[2507.17294](http://arxiv.org/abs/2507.17294)|null|
|**2025-07-19**|**AquaChat: An LLM-Guided ROV Framework for Adaptive Inspection of Aquaculture Net Pens**|Irfan Hussain Team|[2507.16841](http://arxiv.org/abs/2507.16841)|null|
|**2025-07-21**|**Fast Task Planning with Neuro-Symbolic Relaxation**|Chen Wang Team|[2507.15975](http://arxiv.org/abs/2507.15975)|null|
|**2025-07-21**|**FlowForge: Guiding the Creation of Multi-agent Workflows with Design Space Visualization as a Thinking Scaffold**|Qianwen Wang Team|[2507.15559](http://arxiv.org/abs/2507.15559)|null|
|**2025-07-20**|**FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models**|Shiqiang Zhu Team|[2507.14975](http://arxiv.org/abs/2507.14975)|null|
|**2025-07-18**|**CodeEdu: A Multi-Agent Collaborative Platform for Personalized Coding Education**|Bo Yuan Team|[2507.13814](http://arxiv.org/abs/2507.13814)|null|
|**2025-07-15**|**From Production Logistics to Smart Manufacturing: The Vision for a New RoboCup Industrial League**|Shohei Yasuda Team|[2507.11402](http://arxiv.org/abs/2507.11402)|null|
|**2025-07-10**|**Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning**|Xun Huan Team|[2507.07359](http://arxiv.org/abs/2507.07359)|null|
|**2025-07-09**|**LOVON: Legged Open-Vocabulary Object Navigator**|Jun Ma Team|[2507.06747](http://arxiv.org/abs/2507.06747)|null|
|**2025-07-10**|**GTA1: GUI Test-time Scaling Agent**|Junnan Li Team|[2507.05791](http://arxiv.org/abs/2507.05791)|null|
|**2025-07-08**|**Structured Task Solving via Modular Embodied Intelligence: A Case Study on Rubik's Cube**|Shenghai Yuan Team|[2507.05607](http://arxiv.org/abs/2507.05607)|null|
|**2025-07-07**|**LERa: Replanning with Visual Feedback in Instruction Following**|Aleksandr I. Panov Team|[2507.05135](http://arxiv.org/abs/2507.05135)|null|
|**2025-07-07**|**VerifyLLM: LLM-Based Pre-Execution Task Plan Verification for Robots**|Aleksandr I. Panov Team|[2507.05118](http://arxiv.org/abs/2507.05118)|null|
|**2025-07-06**|**"Hi AirStar, Guide Me to the Badminton Court."**|Si Liu Team|[2507.04430](http://arxiv.org/abs/2507.04430)|null|
|**2025-07-04**|**CodeAgents: A Token-Efficient Framework for Codified Multi-Agent Reasoning in LLMs**|David Hsu Team|[2507.03254](http://arxiv.org/abs/2507.03254)|null|
|**2025-07-02**|**VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process**|Alexander Carballo Team|[2507.01284](http://arxiv.org/abs/2507.01284)|null|
|**2025-06-29**|**Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning**|Xipeng Qiu Team|[2506.23127](http://arxiv.org/abs/2506.23127)|null|
|**2025-06-29**|**TOMI: Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure**|Ziyu Wang Team|[2506.23094](http://arxiv.org/abs/2506.23094)|null|
|**2025-07-10**|**Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation**|Navid Azizan Team|[2506.22827](http://arxiv.org/abs/2506.22827)|null|
|**2025-06-24**|**FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models**|Huiping Zhuang Team|[2506.21627](http://arxiv.org/abs/2506.21627)|null|
|**2025-06-26**|**MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification**|Abduz Zami Team|[2506.21199](http://arxiv.org/abs/2506.21199)|null|
|**2025-07-16**|**STEP Planner: Constructing cross-hierarchical subgoal tree as an embodied long-horizon task planner**|Yufeng Yue Team|[2506.21030](http://arxiv.org/abs/2506.21030)|null|
|**2025-06-25**|**SPARK: Graph-Based Online Semantic Integration System for Robot Task Planning**|Yusuke Iwasawa Team|[2506.20394](http://arxiv.org/abs/2506.20394)|null|
|**2025-06-30**|**Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning**|Tamim Asfour Team|[2506.19592](http://arxiv.org/abs/2506.19592)|null|
|**2025-06-23**|**Safety-Aware Optimal Scheduling for Autonomous Masonry Construction using Collaborative Heterogeneous Aerial Robots**|George Nikolakopoulos Team|[2506.18697](http://arxiv.org/abs/2506.18697)|null|
|**2025-06-21**|**CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning**|Xiaoling Wang Team|[2506.17629](http://arxiv.org/abs/2506.17629)|null|
|**2025-06-21**|**VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models**|Lin Shao Team|[2506.17561](http://arxiv.org/abs/2506.17561)|null|
|**2025-06-20**|**Towards AI Search Paradigm**|Dawei Yin Team|[2506.17188](http://arxiv.org/abs/2506.17188)|null|
|**2025-06-20**|**Multimodal Fused Learning for Solving the Generalized Traveling Salesman Problem in Robotic Task Planning**|Guillaume Adrien Sartoretti Team|[2506.16931](http://arxiv.org/abs/2506.16931)|null|

<p align=right>(<a href=#updated-on-20251019>back to top</a>)</p>

## Open Vocabulary Robotics

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-11**|**ReferSplat: Referring Segmentation in 3D Gaussian Splatting**|Henghui Ding Team|[2508.08252](http://arxiv.org/abs/2508.08252)|**[link](https://github.com/heshuting555/ReferSplat)**|
|**2025-08-08**|**SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation**|Yunhao Liu Team|[2508.06115](http://arxiv.org/abs/2508.06115)|null|
|**2025-08-08**|**Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts**|Srikrishna Karanam Team|[2508.06032](http://arxiv.org/abs/2508.06032)|null|
|**2025-08-07**|**DART: Dual Adaptive Refinement Transfer for Open-Vocabulary Multi-Label Recognition**|Liang Lin Team|[2508.05585](http://arxiv.org/abs/2508.05585)|null|
|**2025-08-07**|**Textual Inversion for Efficient Adaptation of Open-Vocabulary Object Detectors Without Forgetting**|Hugo Kuijf Team|[2508.05323](http://arxiv.org/abs/2508.05323)|null|
|**2025-08-06**|**Keyword Spotting with Hyper-Matched Filters for Small Footprint Devices**|Joseph Keshet Team|[2508.04857](http://arxiv.org/abs/2508.04857)|null|
|**2025-08-06**|**$NavA^3$ : Understanding Any Instruction, Navigating Anywhere, Finding Anything**|Shanghang Zhang Team|[2508.04598](http://arxiv.org/abs/2508.04598)|null|
|**2025-08-06**|**What Holds Back Open-Vocabulary Segmentation?**|Siniša Šegvić Team|[2508.04211](http://arxiv.org/abs/2508.04211)|null|
|**2025-08-11**|**Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images**|Eunbyung Park Team|[2508.03643](http://arxiv.org/abs/2508.03643)|**[link](https://github.com/HorizonRobotics/Uni3R)**|
|**2025-08-05**|**Open-Vocabulary HOI Detection with Interaction-aware Prompt and Concept Calibration**|Yang Liu Team|[2508.03207](http://arxiv.org/abs/2508.03207)|null|
|**2025-08-03**|**AG $^2$ aussian: Anchor-Graph Structured Gaussian Splatting for Instance-Level 3D Scene Understanding and Editing**|Changhe Tu Team|[2508.01740](http://arxiv.org/abs/2508.01740)|null|
|**2025-08-03**|**OpenMap: Instruction Grounding via Open-Vocabulary Visual-Language Mapping**|Zheng Yang Team|[2508.01723](http://arxiv.org/abs/2508.01723)|null|
|**2025-08-03**|**DAG: Unleash the Potential of Diffusion Model for Open-Vocabulary 3D Affordance Grounding**|Hangxing Zhang Team|[2508.01651](http://arxiv.org/abs/2508.01651)|null|
|**2025-08-02**|**AffectGPT-R1: Leveraging Reinforcement Learning for Open-Vocabulary Emotion Recognition**|Zheng Lian Team|[2508.01318](http://arxiv.org/abs/2508.01318)|null|
|**2025-08-02**|**ODOV: Towards Open-Domain Open-Vocabulary Object Detection**|Liang Wan Team|[2508.01253](http://arxiv.org/abs/2508.01253)|null|
|**2025-08-02**|**OpenGS-Fusion: Open-Vocabulary Dense Mapping with Hybrid 3D Gaussian Splatting for Refined Object-Level Understanding**|Yi Yang Team|[2508.01150](http://arxiv.org/abs/2508.01150)|null|
|**2025-08-01**|**ROVI: A VLM-LLM Re-Captioned Dataset for Open-Vocabulary Instance-Grounded Text-to-Image Generation**|Kun Zhou Team|[2508.01008](http://arxiv.org/abs/2508.01008)|null|
|**2025-08-01**|**YOLO-Count: Differentiable Object Counting for Text-to-Image Generation**|Zhuowen Tu Team|[2508.00728](http://arxiv.org/abs/2508.00728)|null|
|**2025-08-12**|**Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving**|Fabian B. Flohr Team|[2508.00589](http://arxiv.org/abs/2508.00589)|**[link](https://iv.ee.hm.edu/contextmotionclip/)**|
|**2025-08-01**|**Training-Free Class Purification for Open-Vocabulary Semantic Segmentation**|Xiaohua Xie Team|[2508.00557](http://arxiv.org/abs/2508.00557)|null|
|**2025-07-23**|**Dynamic-DINO: Fine-Grained Mixture of Experts Tuning for Real-time Open-Vocabulary Object Detection**|Xi Li Team|[2507.17436](http://arxiv.org/abs/2507.17436)|null|
|**2025-07-23**|**Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models**|Guanghui Sun Team|[2507.17379](http://arxiv.org/abs/2507.17379)|null|
|**2025-07-22**|**Detect Any Sound: Open-Vocabulary Sound Event Detection with Multi-Modal Queries**|Ian McLoughlin Team|[2507.16343](http://arxiv.org/abs/2507.16343)|null|
|**2025-07-21**|**ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting**|Bo Dai Team|[2507.15454](http://arxiv.org/abs/2507.15454)|null|
|**2025-07-19**|**From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition**|Soo Chin Liew Team|[2507.14686](http://arxiv.org/abs/2507.14686)|null|
|**2025-07-19**|**DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF**|Loïc Barthe Team|[2507.14596](http://arxiv.org/abs/2507.14596)|null|
|**2025-07-06**|**Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop**|Mehar Khurana Team|[2507.13363](http://arxiv.org/abs/2507.13363)|null|
|**2025-07-04**|**Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives**|Xizhe Xue Team|[2507.13359](http://arxiv.org/abs/2507.13359)|null|
|**2025-07-17**|**SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation**|Bihan Wen Team|[2507.12857](http://arxiv.org/abs/2507.12857)|null|
|**2025-07-17**|**osmAG-LLM: Zero-Shot Open-Vocabulary Object Navigation via Semantic Maps and Large Language Models Reasoning**|Hermann Blum Team|[2507.12753](http://arxiv.org/abs/2507.12753)|null|
|**2025-07-16**|**NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting**|Chaoli Wang Team|[2507.12621](http://arxiv.org/abs/2507.12621)|null|
|**2025-07-16**|**Mitigating Object Hallucinations via Sentence-Level Early Intervention**|Zhuotao Tian Team|[2507.12455](http://arxiv.org/abs/2507.12455)|null|
|**2025-07-16**|**Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph**|Gleb Naumov Team|[2507.12123](http://arxiv.org/abs/2507.12123)|null|
|**2025-07-15**|**Personalized OVSS: Understanding Personal Concept in Open-Vocabulary Semantic Segmentation**|Fatih Porikli Team|[2507.11030](http://arxiv.org/abs/2507.11030)|null|
|**2025-07-14**|**LLM-Guided Agentic Object Detection for Open-World Understanding**|Yasin Yilmaz Team|[2507.10844](http://arxiv.org/abs/2507.10844)|null|
|**2025-07-14**|**OpenHuman4D: Open-Vocabulary 4D Human Parsing**|Truong Nguyen Team|[2507.09880](http://arxiv.org/abs/2507.09880)|null|
|**2025-07-11**|**VISTA: A Visual Analytics Framework to Enhance Foundation Model-Generated Data Labels**|Liu Ren Team|[2507.09008](http://arxiv.org/abs/2507.09008)|null|
|**2025-07-08**|**OTAS: Open-vocabulary Token Alignment for Outdoor Segmentation**|Gerald Steinbauer-Wagner Team|[2507.08851](http://arxiv.org/abs/2507.08851)|null|
|**2025-07-10**|**LOSC: LiDAR Open-voc Segmentation Consolidator**|Renaud Marlet Team|[2507.07605](http://arxiv.org/abs/2507.07605)|null|
|**2025-07-09**|**LangSplatV2: High-dimensional 3D Language Gaussian Splatting with 450+ FPS**|Hanspeter Pfister Team|[2507.07136](http://arxiv.org/abs/2507.07136)|null|
|**2025-07-09**|**LOVON: Legged Open-Vocabulary Object Navigator**|Jun Ma Team|[2507.06747](http://arxiv.org/abs/2507.06747)|null|
|**2025-07-09**|**A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding**|Yanwei Fu Team|[2507.06719](http://arxiv.org/abs/2507.06719)|null|
|**2025-07-09**|**Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection**|Xiangmin Xu Team|[2507.06510](http://arxiv.org/abs/2507.06510)|null|
|**2025-07-08**|**SPADE: Spatial-Aware Denoising Network for Open-vocabulary Panoptic Scene Graph Generation with Long- and Local-range Context Reasoning**|Tao He Team|[2507.05798](http://arxiv.org/abs/2507.05798)|null|
|**2025-07-07**|**OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts**|Priyadarshini Panda Team|[2507.05427](http://arxiv.org/abs/2507.05427)|null|
|**2025-07-04**|**Leveraging Out-of-Distribution Unlabeled Images: Semi-Supervised Semantic Segmentation with an Open-Vocabulary Model**|Sung Won Han Team|[2507.03302](http://arxiv.org/abs/2507.03302)|null|
|**2025-07-03**|**LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion**|Yueqi Duan Team|[2507.02813](http://arxiv.org/abs/2507.02813)|null|
|**2025-07-01**|**VISTA: Open-Vocabulary, Task-Relevant Robot Exploration with Online Semantic Gaussian Splatting**|Mac Schwager Team|[2507.01125](http://arxiv.org/abs/2507.01125)|null|
|**2025-06-30**|**Diffusion-Based Image Augmentation for Semantic Segmentation in Outdoor Robotics**|Mirko Maehlisch Team|[2507.00153](http://arxiv.org/abs/2507.00153)|null|
|**2025-06-30**|**Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?**|Matthias Rottmann Team|[2506.23751](http://arxiv.org/abs/2506.23751)|null|
|**2025-06-30**|**PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum**|Yanyong Zhang Team|[2506.23607](http://arxiv.org/abs/2506.23607)|null|
|**2025-07-15**|**FA-Seg: A Fast and Accurate Diffusion-Based Method for Open-Vocabulary Segmentation**|Vinh-Tiep Nguyen Team|[2506.23323](http://arxiv.org/abs/2506.23323)|null|
|**2025-06-28**|**Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding**|Nannan Wang Team|[2506.22817](http://arxiv.org/abs/2506.22817)|null|
|**2025-06-28**|**VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding**|Liang Zhang Team|[2506.22799](http://arxiv.org/abs/2506.22799)|null|
|**2025-06-27**|**Embodied Domain Adaptation for Object Detection**|Feras Dayoub Team|[2506.21860](http://arxiv.org/abs/2506.21860)|null|
|**2025-06-27**|**ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation**|Kwan-Liu Ma Team|[2506.21233](http://arxiv.org/abs/2506.21233)|null|
|**2025-06-27**|**Shape2Animal: Creative Animal Generation from Natural Silhouettes**|Trung-Nghia Le Team|[2506.20616](http://arxiv.org/abs/2506.20616)|null|
|**2025-06-25**|**Video Perception Models for 3D Scene Synthesis**|Francis Engelmann Team|[2506.20601](http://arxiv.org/abs/2506.20601)|null|
|**2025-06-24**|**Segment Any 3D-Part in a Scene from a Sentence**|Cees G. M. Snoek Team|[2506.19331](http://arxiv.org/abs/2506.19331)|null|
|**2025-06-24**|**Open-Vocabulary Camouflaged Object Segmentation with Cascaded Vision Language Models**|Dan Zeng Team|[2506.19300](http://arxiv.org/abs/2506.19300)|null|
|**2025-06-24**|**OpenWildlife: Open-Vocabulary Multi-Species Wildlife Detector for Geographically-Diverse Aerial Imagery**|David Clausi Team|[2506.19204](http://arxiv.org/abs/2506.19204)|null|
|**2025-06-23**|**Context Biasing for Pronunciations-Orthography Mismatch in Automatic Speech Recognition**|Alexander Waibel Team|[2506.18703](http://arxiv.org/abs/2506.18703)|null|
|**2025-06-21**|**DRAMA-X: A Fine-grained Intent Prediction and Risk Reasoning Benchmark For Driving**|Zhengzhong Tu Team|[2506.17590](http://arxiv.org/abs/2506.17590)|null|

<p align=right>(<a href=#updated-on-20251019>back to top</a>)</p>

## Robot Reasoning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-12**|**A Framework for FAIR and CLEAR Ecological Data and Knowledge: Semantic Units for Synthesis and Causal Modelling**|Tina Heger Team|[2508.08959](http://arxiv.org/abs/2508.08959)|null|
|**2025-08-12**|**3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs**|Eddy Ilg Team|[2508.08821](http://arxiv.org/abs/2508.08821)|null|
|**2025-08-11**|**Re:Verse -- Can Your VLM Read a Manga?**|Shruti Vyas Team|[2508.08508](http://arxiv.org/abs/2508.08508)|null|
|**2025-08-11**|**GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games**|Julian Togelius Team|[2508.08501](http://arxiv.org/abs/2508.08501)|null|
|**2025-08-11**|**ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks**|Chunhua Shen Team|[2508.08240](http://arxiv.org/abs/2508.08240)|null|
|**2025-08-11**|**SAGOnline: Segment Any Gaussians Online**|Jonathan Li Team|[2508.08219](http://arxiv.org/abs/2508.08219)|null|
|**2025-08-11**|**Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model**|Shaoliang Peng Team|[2508.08199](http://arxiv.org/abs/2508.08199)|null|
|**2025-08-11**|**Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents**|Parisa Kordjamshidi Team|[2508.07642](http://arxiv.org/abs/2508.07642)|null|
|**2025-08-11**|**Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction**|Yisi Liu Team|[2508.07624](http://arxiv.org/abs/2508.07624)|null|
|**2025-08-11**|**FineBadminton: A Multi-Level Dataset for Fine-Grained Badminton Video Understanding**|Jianlong Wu Team|[2508.07554](http://arxiv.org/abs/2508.07554)|null|
|**2025-08-12**|**Understanding Dynamic Scenes in Ego Centric 4D Point Clouds**|Gaoang Wang Team|[2508.07251](http://arxiv.org/abs/2508.07251)|null|
|**2025-08-09**|**ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting**|Steven L. Waslander Team|[2508.07089](http://arxiv.org/abs/2508.07089)|null|
|**2025-08-08**|**V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles**|Glenn Geers Team|[2508.06404](http://arxiv.org/abs/2508.06404)|null|
|**2025-08-13**|**InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?**|Youngjae Yu Team|[2508.06220](http://arxiv.org/abs/2508.06220)|null|
|**2025-08-08**|**SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges**|Samuel F. Brown Team|[2508.06111](http://arxiv.org/abs/2508.06111)|null|
|**2025-08-07**|**DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning**|Bo Zheng Team|[2508.05405](http://arxiv.org/abs/2508.05405)|null|
|**2025-08-07**|**B4DL: A Benchmark for 4D LiDAR LLM in Spatio-Temporal Understanding**|Junmo Kim Team|[2508.05269](http://arxiv.org/abs/2508.05269)|null|
|**2025-08-07**|**Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses**|Bill Howe Team|[2508.05009](http://arxiv.org/abs/2508.05009)|null|
|**2025-08-06**|**Causal Reflection with Language Models**|Zac Liu Team|[2508.04495](http://arxiv.org/abs/2508.04495)|null|
|**2025-08-06**|**Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success**|Daniil Gavrilov Team|[2508.04280](http://arxiv.org/abs/2508.04280)|null|
|**2025-07-23**|**LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning**|Stefano Melacci Team|[2507.17482](http://arxiv.org/abs/2507.17482)|null|
|**2025-07-22**|**CausalStep: A Benchmark for Explicit Stepwise Causal Reasoning in Videos**|Wentao Zhang Team|[2507.16878](http://arxiv.org/abs/2507.16878)|null|
|**2025-07-22**|**Temporally-Constrained Video Reasoning Segmentation and Automated Benchmark Construction**|Mathias Unberath Team|[2507.16718](http://arxiv.org/abs/2507.16718)|null|
|**2025-07-22**|**Explicit Context Reasoning with Supervision for Visual Tracking**|Shuxiang Song Team|[2507.16191](http://arxiv.org/abs/2507.16191)|null|
|**2025-07-22**|**GUI-G $^2$ : Gaussian Reward Modeling for GUI Grounding**|Yueting Zhuang Team|[2507.15846](http://arxiv.org/abs/2507.15846)|null|
|**2025-07-20**|**FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models**|Mengnan Du Team|[2507.14823](http://arxiv.org/abs/2507.14823)|null|
|**2025-07-19**|**XplainAct: Visualization for Personalized Intervention Insights**|Klaus Mueller Team|[2507.14767](http://arxiv.org/abs/2507.14767)|null|
|**2025-07-18**|**Can AR-Embedded Visualizations Foster Appropriate Reliance on AI in Spatial Decision Making? A Comparative Study of AR See-Through vs. 2D Minimap**|Chen Zhu-Tian Team|[2507.14316](http://arxiv.org/abs/2507.14316)|null|
|**2025-07-18**|**How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs**|Dongyeop Kang Team|[2507.14307](http://arxiv.org/abs/2507.14307)|null|
|**2025-07-18**|**Towards Constraint Temporal Answer Set Programming**|Igor Stéphan Team|[2507.13958](http://arxiv.org/abs/2507.13958)|null|
|**2025-07-18**|**Cross-modal Causal Intervention for Alzheimer's Disease Prediction**|Tianrui Li Team|[2507.13956](http://arxiv.org/abs/2507.13956)|null|
|**2025-07-16**|**DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning**|Philip S. Yu Team|[2507.13396](http://arxiv.org/abs/2507.13396)|null|
|**2025-07-17**|**A Translation of Probabilistic Event Calculus into Markov Decision Processes**|Luke Dickens Team|[2507.12989](http://arxiv.org/abs/2507.12989)|null|
|**2025-07-17**|**World Model-Based End-to-End Scene Generation for Accident Anticipation in Autonomous Driving**|Zhenning Li Team|[2507.12762](http://arxiv.org/abs/2507.12762)|null|
|**2025-07-16**|**MindJourney: Test-Time Scaling with World Models for Spatial Reasoning**|Chuang Gan Team|[2507.12508](http://arxiv.org/abs/2507.12508)|null|
|**2025-07-16**|**Assessing the Value of Visual Input: A Benchmark of Multimodal Large Language Models for Robotic Path Planning**|Yasuhisa Hasegawa Team|[2507.12391](http://arxiv.org/abs/2507.12391)|null|
|**2025-07-16**|**Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph**|Gleb Naumov Team|[2507.12123](http://arxiv.org/abs/2507.12123)|null|
|**2025-07-14**|**Warehouse Spatial Question Answering with LLM Agent**|Jenq-Neng Hwang Team|[2507.10778](http://arxiv.org/abs/2507.10778)|null|
|**2025-07-14**|**Spatial Reasoners for Continuous Variables in Any Domain**|Jan Eric Lenssen Team|[2507.10768](http://arxiv.org/abs/2507.10768)|null|
|**2025-07-14**|**CWNet: Causal Wavelet Network for Low-Light Image Enhancement**|Qiuzhan Zhou Team|[2507.10689](http://arxiv.org/abs/2507.10689)|null|
|**2025-07-14**|**EmbRACE-3K: Embodied Reasoning and Action in Complex Environments**|Xiaojuan Qi Team|[2507.10548](http://arxiv.org/abs/2507.10548)|null|
|**2025-07-22**|**T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs**|Guillaume Rabusseau Team|[2507.10183](http://arxiv.org/abs/2507.10183)|null|
|**2025-07-13**|**GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them?**|Huaxiu Yao Team|[2507.09491](http://arxiv.org/abs/2507.09491)|null|
|**2025-07-12**|**Online Long-term Point Tracking in the Foundation Model Era**|Görkay Aydemir Team|[2507.09217](http://arxiv.org/abs/2507.09217)|null|
|**2025-07-11**|**ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way**|Subarna Tripathi Team|[2507.08679](http://arxiv.org/abs/2507.08679)|null|
|**2025-07-11**|**M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning**|Ziping Ma Team|[2507.08306](http://arxiv.org/abs/2507.08306)|null|
|**2025-07-11**|**InsightBuild: LLM-Powered Causal Reasoning in Smart Building Systems**|Rajiv Ramnath Team|[2507.08235](http://arxiv.org/abs/2507.08235)|null|
|**2025-07-10**|**OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding**|Jiangmiao Pang Team|[2507.07984](http://arxiv.org/abs/2507.07984)|null|
|**2025-07-10**|**Scaling RL to Long Videos**|Song Han Team|[2507.07966](http://arxiv.org/abs/2507.07966)|null|
|**2025-07-10**|**SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes**|Mingming Gong Team|[2507.07781](http://arxiv.org/abs/2507.07781)|null|
|**2025-07-10**|**PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations**|Peter Wonka Team|[2507.07644](http://arxiv.org/abs/2507.07644)|null|
|**2025-07-10**|**Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning**|Xun Huan Team|[2507.07359](http://arxiv.org/abs/2507.07359)|null|
|**2025-07-09**|**Probability-Raising Causality for Uncertain Parametric Markov Decision Processes with PAC Guarantees**|yuji Ito Team|[2507.07319](http://arxiv.org/abs/2507.07319)|null|
|**2025-07-09**|**Temporal Information Retrieval via Time-Specifier Model Merging**|Jong C. Park Team|[2507.06782](http://arxiv.org/abs/2507.06782)|null|
|**2025-07-09**|**A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding**|Yanwei Fu Team|[2507.06719](http://arxiv.org/abs/2507.06719)|null|
|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Nick Haber Team|[2507.06484](http://arxiv.org/abs/2507.06484)|null|
|**2025-07-08**|**Video Event Reasoning and Prediction by Fusing World Knowledge from LLMs with Vision Foundation Models**|Santiago Munoz Team|[2507.05822](http://arxiv.org/abs/2507.05822)|null|
|**2025-07-07**|**CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale**|Boyuan Chen Team|[2507.05178](http://arxiv.org/abs/2507.05178)|null|
|**2025-07-07**|**HV-MMBench: Benchmarking MLLMs for Human-Centric Video Understanding**|Xiang Bai Team|[2507.04909](http://arxiv.org/abs/2507.04909)|null|
|**2025-07-07**|**Tempo-R0: A Video-MLLM for Temporal Video Grounding through Efficient Temporal Sensing Reinforcement Learning**|Rong Shen Team|[2507.04702](http://arxiv.org/abs/2507.04702)|null|
|**2025-07-07**|**Learn 3D VQA Better with Active Selection and Reannotation**|Feng Zheng Team|[2507.04630](http://arxiv.org/abs/2507.04630)|null|
|**2025-07-05**|**Pedestrian Intention Prediction via Vision-Language Foundation Models**|He Wang Team|[2507.04141](http://arxiv.org/abs/2507.04141)|null|
|**2025-07-09**|**Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models**|Changliang Xu Team|[2507.03916](http://arxiv.org/abs/2507.03916)|null|
|**2025-07-04**|**Causal-SAM-LLM: Large Language Models as Causal Reasoners for Robust Medical Segmentation**|Zhixiang Lu Team|[2507.03585](http://arxiv.org/abs/2507.03585)|null|
|**2025-07-01**|**Ascending the Infinite Ladder: Benchmarking Spatial Deformation Reasoning in Vision-Language Models**|Kaicheng Yu Team|[2507.02978](http://arxiv.org/abs/2507.02978)|null|
|**2025-07-02**|**Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain**|Verena Klös Team|[2507.02016](http://arxiv.org/abs/2507.02016)|null|
|**2025-07-08**|**Future Slot Prediction for Unsupervised Object Discovery in Surgical Video**|Daniel A. Hashimoto Team|[2507.01882](http://arxiv.org/abs/2507.01882)|null|
|**2025-07-02**|**HCNQA: Enhancing 3D VQA with Hierarchical Concentration Narrowing Supervision**|Feng Zheng Team|[2507.01800](http://arxiv.org/abs/2507.01800)|null|
|**2025-07-02**|**VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process**|Alexander Carballo Team|[2507.01284](http://arxiv.org/abs/2507.01284)|null|
|**2025-07-02**|**Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care**|Charles B Malpas Team|[2507.01282](http://arxiv.org/abs/2507.01282)|null|
|**2025-07-01**|**CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs**|Wei Yang Bryan Lim Team|[2507.00817](http://arxiv.org/abs/2507.00817)|null|
|**2025-07-01**|**Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving**|Yadan Luo Team|[2507.00525](http://arxiv.org/abs/2507.00525)|null|
|**2025-06-29**|**GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields**|Yutaka Matsuo Team|[2506.23352](http://arxiv.org/abs/2506.23352)|null|
|**2025-06-29**|**UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding**|Yong Li Team|[2506.23219](http://arxiv.org/abs/2506.23219)|null|
|**2025-06-29**|**Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation**|Li Jiang Team|[2506.23120](http://arxiv.org/abs/2506.23120)|null|
|**2025-06-28**|**MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning**|Michael Moor Team|[2506.22992](http://arxiv.org/abs/2506.22992)|null|

<p align=right>(<a href=#updated-on-20251019>back to top</a>)</p>

## Subtask Decomposition

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-12**|**Rational Inverse Reasoning**|Leslie Pack Kaelbling Team|[2508.08983](http://arxiv.org/abs/2508.08983)|null|
|**2025-08-12**|**LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement**|Arvind Agarwal Team|[2508.08653](http://arxiv.org/abs/2508.08653)|null|
|**2025-08-11**|**FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis**|Chunfeng Lian Team|[2508.07950](http://arxiv.org/abs/2508.07950)|null|
|**2025-08-09**|**Talk2Image: A Multi-Agent System for Multi-Turn Image Generation and Editing**|Yang Wang Team|[2508.06916](http://arxiv.org/abs/2508.06916)|null|
|**2025-08-06**|**VeriGUI: Verifiable Long-Chain GUI Dataset**|Dacheng Tao Team|[2508.04026](http://arxiv.org/abs/2508.04026)|null|
|**2025-08-06**|**Tensorized Clustered LoRA Merging for Multi-Task Interference**|Jian-Yun Nie Team|[2508.03999](http://arxiv.org/abs/2508.03999)|null|
|**2025-08-08**|**CoAct-1: Computer-using Agents with Coding as Actions**|Caiming Xiong Team|[2508.03923](http://arxiv.org/abs/2508.03923)|null|
|**2025-08-07**|**Patho-AgenticRAG: Towards Multimodal Agentic Retrieval-Augmented Generation for Pathology VLMs via Reinforcement Learning**|Hong Bu Team|[2508.02258](http://arxiv.org/abs/2508.02258)|null|
|**2025-08-02**|**Show or Tell? Modeling the evolution of request-making in Human-LLM conversations**|David Mimno Team|[2508.01213](http://arxiv.org/abs/2508.01213)|null|
|**2025-08-01**|**AutoEDA: Enabling EDA Flow Automation through Microservice-Based LLM Agents**|Yiran Chen Team|[2508.01012](http://arxiv.org/abs/2508.01012)|null|
|**2025-07-31**|**A Survey on Code Generation with LLM-based Agents**|Ge Li Team|[2508.00083](http://arxiv.org/abs/2508.00083)|null|
|**2025-08-01**|**Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI**|Dusit Niyato Team|[2507.23565](http://arxiv.org/abs/2507.23565)|null|
|**2025-07-28**|**LLMs-guided adaptive compensator: Bringing Adaptivity to Automatic Control Systems with Large Language Models**|Yusuke Iwasawa Team|[2507.20509](http://arxiv.org/abs/2507.20509)|null|
|**2025-07-28**|**Investigating the Effect of Spatial Context on Multi-Task Sea Ice Segmentation**|Morteza Karimzadeh Team|[2507.20507](http://arxiv.org/abs/2507.20507)|null|
|**2025-07-25**|**Solar Photovoltaic Assessment with Large Language Model**|Yang Weng Team|[2507.19144](http://arxiv.org/abs/2507.19144)|null|
|**2025-07-23**|**Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks**|Tim Verbelen Team|[2507.17338](http://arxiv.org/abs/2507.17338)|null|
|**2025-07-18**|**Assessing the Reliability of Large Language Models for Deductive Qualitative Coding: A Comparative Study of ChatGPT Interventions**|Elliott Hauser Team|[2507.14384](http://arxiv.org/abs/2507.14384)|null|
|**2025-07-14**|**DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base**|Botian Shi Team|[2507.14189](http://arxiv.org/abs/2507.14189)|null|
|**2025-07-28**|**Beyond Load: Understanding Cognitive Effort through Neural Efficiency and Involvement using fNIRS and Machine Learning**|Roghayeh Leila Barmaki Team|[2507.13952](http://arxiv.org/abs/2507.13952)|null|
|**2025-07-13**|**GoalfyMax: A Protocol-Driven Multi-Agent System for Intelligent Experience Entities**|Tianyu Shi Team|[2507.09497](http://arxiv.org/abs/2507.09497)|null|
|**2025-07-10**|**Collaborative Human-Robot Surgery for Mandibular Angle Split Osteotomy: Optical Tracking based Approach**|Xingguang Duan Team|[2507.07794](http://arxiv.org/abs/2507.07794)|null|
|**2025-07-10**|**PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving**|Tomas Pfister Team|[2507.07495](http://arxiv.org/abs/2507.07495)|null|
|**2025-06-26**|**ViStruct: Simulating Expert-Like Reasoning Through Task Decomposition and Visual Attention Cues**|Carolina Nobre Team|[2506.21762](http://arxiv.org/abs/2506.21762)|null|
|**2025-07-22**|**Hierarchical Reasoning Model**|Yasin Abbasi Yadkori Team|[2506.21734](http://arxiv.org/abs/2506.21734)|null|
|**2025-06-20**|**Automatic Large Language Models Creation of Interactive Learning Lessons**|Kenneth R. Koedinger Team|[2506.17356](http://arxiv.org/abs/2506.17356)|null|
|**2025-06-20**|**Chain-of-Trust: A Progressive Trust Evaluation Framework Enabled by Generative AI**|Shen Team|[2506.17130](http://arxiv.org/abs/2506.17130)|null|
|**2025-06-18**|**DeckFlow: Iterative Specification on a Multimodal Generative Canvas**|Cyrus Omar Team|[2506.15873](http://arxiv.org/abs/2506.15873)|null|
|**2025-06-16**|**A Comprehensive Survey on Deep Learning Solutions for 3D Flood Mapping**|Lihong Zheng Team|[2506.13201](http://arxiv.org/abs/2506.13201)|null|
|**2025-06-13**|**Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation**|Beidi Chen Team|[2506.09991](http://arxiv.org/abs/2506.09991)|null|
|**2025-06-11**|**Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis**|Michael Tin-Cheung Ying Team|[2506.08849](http://arxiv.org/abs/2506.08849)|**[link](https://github.com/jinggqu/nextgen-uia)**|
|**2025-06-09**|**SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition**|Wenliang Chen Team|[2506.07557](http://arxiv.org/abs/2506.07557)|null|
|**2025-06-06**|**Hierarchical Debate-Based Large Language Model (LLM) for Complex Task Planning of 6G Network Management**|Zhang Team|[2506.06519](http://arxiv.org/abs/2506.06519)|null|
|**2025-06-06**|**Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router**|Yong Li Team|[2506.05901](http://arxiv.org/abs/2506.05901)|null|
|**2025-06-09**|**Zero-Shot Event Causality Identification via Multi-source Evidence Fuzzy Aggregation with Large Language Models**|Zhong Liu Team|[2506.05675](http://arxiv.org/abs/2506.05675)|null|
|**2025-06-05**|**Attack Effect Model based Malicious Behavior Detection**|Kai Ye Team|[2506.05001](http://arxiv.org/abs/2506.05001)|null|
|**2025-06-04**|**Comparative Analysis of AI Agent Architectures for Entity Relationship Classification**|Amin Sehati Team|[2506.02426](http://arxiv.org/abs/2506.02426)|**[link](https://github.com/maryambrj/alien)**|
|**2025-06-02**|**COALESCE: Economic and Security Dynamics of Skill-Based Task Outsourcing Among Team of Autonomous LLM Agents**|Idan Habler Team|[2506.01900](http://arxiv.org/abs/2506.01900)|null|
|**2025-05-30**|**Reasoning Can Hurt the Inductive Abilities of Large Language Models**|Haohan Wang Team|[2505.24225](http://arxiv.org/abs/2505.24225)|null|
|**2025-06-11**|**OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation**|Guohao Li Team|[2505.23885](http://arxiv.org/abs/2505.23885)|**[link](https://github.com/camel-ai/owl)**|
|**2025-05-29**|**EL4NER: Ensemble Learning for Named Entity Recognition via Multiple Small-Parameter Large Language Models**|Junfeng Zhao Team|[2505.23038](http://arxiv.org/abs/2505.23038)|null|
|**2025-05-28**|**Learning Composable Chains-of-Thought**|Greg Durrett Team|[2505.22635](http://arxiv.org/abs/2505.22635)|null|
|**2025-05-28**|**AudioGenie: A Training-Free Multi-Agent Framework for Diverse Multimodality-to-Multiaudio Generation**|Li Liu Team|[2505.22053](http://arxiv.org/abs/2505.22053)|null|

<p align=right>(<a href=#updated-on-20251019>back to top</a>)</p>

## Robot Memory

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-09**|**Narrative Memory in Machines: Multi-Agent Arc Extraction in Serialized TV**|Guglielmo Pescatore Team|[2508.07010](http://arxiv.org/abs/2508.07010)|null|
|**2025-08-08**|**MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration**|Weichao Wu Team|[2508.06189](http://arxiv.org/abs/2508.06189)|null|
|**2025-08-08**|**Ensemble-Based Graph Representation of fMRI Data for Cognitive Brain State Classification**|Denis Zakharov Team|[2508.06118](http://arxiv.org/abs/2508.06118)|null|
|**2025-08-07**|**Space-Efficient Hierholzer: Eulerian Cycles in O(m) Time and O(n) Space**|Sebastian Wild Team|[2508.05251](http://arxiv.org/abs/2508.05251)|null|
|**2025-08-06**|**Occupancy Learning with Spatiotemporal Memory**|Bolei Zhou Team|[2508.04705](http://arxiv.org/abs/2508.04705)|**[link](https://matthew-leng.github.io/stocc)**|
|**2025-08-06**|**Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management**|Yunxin Liu Team|[2508.04664](http://arxiv.org/abs/2508.04664)|null|
|**2025-08-06**|**Hierarchical Event Memory for Accurate and Low-latency Online Video Temporal Grounding**|Yang Liu Team|[2508.04546](http://arxiv.org/abs/2508.04546)|null|
|**2025-08-05**|**If-T: A Benchmark for Type Narrowing**|Ben Greenman Team|[2508.03830](http://arxiv.org/abs/2508.03830)|null|
|**2025-08-05**|**ActionSink: Toward Precise Robot Manipulation with Dynamic Integration of Action Flow**|Xiaodan Liang Team|[2508.03218](http://arxiv.org/abs/2508.03218)|null|
|**2025-08-05**|**Rethinking Selectivity in State Space Models: A Minimal Predictive Sufficiency Approach**|Qingyang Li Team|[2508.03158](http://arxiv.org/abs/2508.03158)|null|
|**2025-08-05**|**AVATAR: Reinforcement Learning to See, Hear, and Reason Over Video**|Pooyan Fazli Team|[2508.03100](http://arxiv.org/abs/2508.03100)|null|
|**2025-08-03**|**EgoTrigger: Toward Audio-Driven Image Capture for Human Memory Enhancement in All-Day Energy-Efficient Smart Glasses**|Ishan Chatterjee Team|[2508.01915](http://arxiv.org/abs/2508.01915)|null|
|**2025-08-02**|**HT-Transformer: Event Sequences Classification by Accumulating Prefix Information with History Tokens**|Andrey Savchenko Team|[2508.01474](http://arxiv.org/abs/2508.01474)|null|
|**2025-08-02**|**Exploitation Is All You Need... for Exploration**|Jesse Roberts Team|[2508.01287](http://arxiv.org/abs/2508.01287)|null|
|**2025-07-30**|**XAutoLM: Efficient Fine-Tuning of Language Models via Meta-Learning and AutoML**|Ruslan Mitkov Team|[2508.00924](http://arxiv.org/abs/2508.00924)|null|
|**2025-07-30**|**Neural Energy Landscapes Predict Working Memory Decline After Brain Tumor Resection**|Sina Khanmohammadi Team|[2507.23057](http://arxiv.org/abs/2507.23057)|null|
|**2025-08-01**|**Segment Anything for Video: A Comprehensive Review of Video Object Segmentation and Tracking from Past to Future**|You Zhang Team|[2507.22792](http://arxiv.org/abs/2507.22792)|null|
|**2025-07-29**|**Structure-Informed Deep Reinforcement Learning for Inventory Management**|Dominique Perrault-Joncas Team|[2507.22040](http://arxiv.org/abs/2507.22040)|null|
|**2025-07-28**|**ProMemAssist: Exploring Timely Proactive Assistance Through Working Memory Modeling in Multi-Modal Wearable Devices**|Tanya Jonker Team|[2507.21378](http://arxiv.org/abs/2507.21378)|null|
|**2025-08-01**|**Verification Cost Asymmetry in Cognitive Warfare: A Complexity-Theoretic Framework**|Joshua Luberisse Team|[2507.21258](http://arxiv.org/abs/2507.21258)|null|
|**2025-07-22**|**Beyond Context Limits: Subconscious Threads for Long-Horizon Reasoning**|James Glass Team|[2507.16784](http://arxiv.org/abs/2507.16784)|null|
|**2025-07-22**|**Analogy making as amortised model construction**|Peter Dayan Team|[2507.16511](http://arxiv.org/abs/2507.16511)|null|
|**2025-07-22**|**Explicit Context Reasoning with Supervision for Visual Tracking**|Shuxiang Song Team|[2507.16191](http://arxiv.org/abs/2507.16191)|null|
|**2025-07-16**|**Autonomic Arousal in Social Anxiety: An Electrodermal Activity Study During an Emotionally Salient Cognitive Task**|Haroon R Lone Team|[2507.15871](http://arxiv.org/abs/2507.15871)|null|
|**2025-07-04**|**VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs**|Jia Deng Team|[2507.13361](http://arxiv.org/abs/2507.13361)|null|
|**2025-07-17**|**RemVerse: Supporting Reminiscence Activities for Older Adults through AI-Assisted Virtual Reality**|Mingming Fan Team|[2507.13247](http://arxiv.org/abs/2507.13247)|null|
|**2025-07-17**|**Emergence of Functionally Differentiated Structures via Mutual Information Optimization in Recurrent Neural Networks**|Yutaka Yamaguti Team|[2507.12858](http://arxiv.org/abs/2507.12858)|null|
|**2025-07-17**|**Enter the Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering**|Shayegan Omidshafiei Team|[2507.12846](http://arxiv.org/abs/2507.12846)|null|
|**2025-07-15**|**Streaming 4D Visual Geometry Transformer**|Jiwen Lu Team|[2507.11539](http://arxiv.org/abs/2507.11539)|null|
|**2025-07-14**|**Bridging Brains and Machines: A Unified Frontier in Neuroscience, Artificial Intelligence, and Neuromorphic Systems**|Tianming Liu Team|[2507.10722](http://arxiv.org/abs/2507.10722)|null|
|**2025-07-17**|**Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving**|Wangchunshu Zhou Team|[2507.06229](http://arxiv.org/abs/2507.06229)|null|
|**2025-07-08**|**Unconditional Diffusion for Generative Sequential Recommendation**|Tat-Seng Chua Team|[2507.06121](http://arxiv.org/abs/2507.06121)|null|
|**2025-07-07**|**Heterogeneous Causal Learning for Optimizing Aggregated Functions in User Growth**|Will Y. Zou Team|[2507.05510](http://arxiv.org/abs/2507.05510)|null|
|**2025-07-07**|**Dynamical Archetype Analysis: Autonomous Computation**|Il Memming Park Team|[2507.05505](http://arxiv.org/abs/2507.05505)|null|
|**2025-07-07**|**Transcribing Spanish Texts from the Past: Experiments with Transkribus, Tesseract and Granite**|Ana García-Serrano Team|[2507.04878](http://arxiv.org/abs/2507.04878)|null|
|**2025-07-14**|**PRIME: Large Language Model Personalization with Cognitive Memory and Thought Processes**|Lu Wang Team|[2507.04607](http://arxiv.org/abs/2507.04607)|null|
|**2025-07-06**|**Entropy measures as indicators of connectivity paths in the human brain**|Holger Kantz Team|[2507.04442](http://arxiv.org/abs/2507.04442)|null|
|**2025-07-04**|**Less is More: Empowering GUI Agent with Context-Aware Simplification**|Liqiang Nie Team|[2507.03730](http://arxiv.org/abs/2507.03730)|null|
|**2025-06-25**|**Echo State Transformer: When chaos brings memory**|Xavier Hinaut Team|[2507.02917](http://arxiv.org/abs/2507.02917)|null|
|**2025-07-03**|**A learning model predictive control for virtual coupling in railroads**|Jesus Felez Team|[2507.02383](http://arxiv.org/abs/2507.02383)|null|
|**2025-07-02**|**REMI: Reconstructing Episodic Memory During Intrinsic Path Planning**|Vijay Balasubramanian Team|[2507.02064](http://arxiv.org/abs/2507.02064)|null|
|**2025-07-02**|**Characterizing control between interacting subsystems with deep Jacobian estimation**|Ila R. Fiete Team|[2507.01946](http://arxiv.org/abs/2507.01946)|null|
|**2025-06-23**|**Catastrophic Forgetting Mitigation via Discrepancy-Weighted Experience Replay**|Shan Jiang Team|[2507.00042](http://arxiv.org/abs/2507.00042)|null|
|**2025-06-30**|**Ella: Embodied Social Agents with Lifelong Memory**|Chuang Gan Team|[2506.24019](http://arxiv.org/abs/2506.24019)|null|
|**2025-07-22**|**GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding**|Bihan Wen Team|[2506.21188](http://arxiv.org/abs/2506.21188)|null|
|**2025-06-26**|**FedDAA: Dynamic Client Clustering for Concept Drift Adaptation in Federated Learning**|Ming Tang Team|[2506.21054](http://arxiv.org/abs/2506.21054)|null|
|**2025-06-25**|**THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion**|Calin Teodor Ioan Team|[2506.20877](http://arxiv.org/abs/2506.20877)|null|
|**2025-06-26**|**From Memories to Maps: Mechanisms of In-Context Reinforcement Learning in Transformers**|Kanaka Rajan Team|[2506.19686](http://arxiv.org/abs/2506.19686)|null|
|**2025-07-03**|**Reliability-Adjusted Prioritized Experience Replay**|Maximilian Schiffer Team|[2506.18482](http://arxiv.org/abs/2506.18482)|null|
|**2025-06-22**|**Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation**|Teng Li Team|[2506.18158](http://arxiv.org/abs/2506.18158)|null|

<p align=right>(<a href=#updated-on-20251019>back to top</a>)</p>

## Temporal Understanding

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-11**|**Re:Verse -- Can Your VLM Read a Manga?**|Shruti Vyas Team|[2508.08508](http://arxiv.org/abs/2508.08508)|null|
|**2025-08-11**|**Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents**|Parisa Kordjamshidi Team|[2508.07642](http://arxiv.org/abs/2508.07642)|null|
|**2025-08-11**|**FineBadminton: A Multi-Level Dataset for Fine-Grained Badminton Video Understanding**|Jianlong Wu Team|[2508.07554](http://arxiv.org/abs/2508.07554)|null|
|**2025-08-12**|**Understanding Dynamic Scenes in Ego Centric 4D Point Clouds**|Gaoang Wang Team|[2508.07251](http://arxiv.org/abs/2508.07251)|null|
|**2025-08-08**|**V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles**|Glenn Geers Team|[2508.06404](http://arxiv.org/abs/2508.06404)|null|
|**2025-08-07**|**B4DL: A Benchmark for 4D LiDAR LLM in Spatio-Temporal Understanding**|Junmo Kim Team|[2508.05269](http://arxiv.org/abs/2508.05269)|null|
|**2025-07-29**|**From Waveforms to Pixels: A Survey on Audio-Visual Segmentation**|Yapeng Tian Team|[2508.03724](http://arxiv.org/abs/2508.03724)|null|
|**2025-08-05**|**Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning**|Steffen Staab Team|[2508.03251](http://arxiv.org/abs/2508.03251)|null|
|**2025-08-03**|**T-GRAG: A Dynamic GraphRAG Framework for Resolving Temporal Conflicts and Redundancy in Knowledge Retrieval**|Jianxing Liu Team|[2508.01680](http://arxiv.org/abs/2508.01680)|null|
|**2025-08-03**|**ReasonAct: Progressive Training for Fine-Grained Video Reasoning in Small Models**|Zhaolu Kang Team|[2508.01533](http://arxiv.org/abs/2508.01533)|null|
|**2025-08-02**|**WinkTPG: An Execution Framework for Multi-Agent Path Finding Using Temporal Reasoning**|Jiaoyang Li Team|[2508.01495](http://arxiv.org/abs/2508.01495)|null|
|**2025-08-01**|**Analysing Temporal Reasoning in Description Logics Using Formal Grammars**|Michaël Thomazo Team|[2508.00575](http://arxiv.org/abs/2508.00575)|null|
|**2025-07-31**|**Punching Bag vs. Punching Person: Motion Transferability in Videos**|Yogesh Rawat Team|[2508.00085](http://arxiv.org/abs/2508.00085)|null|
|**2025-07-31**|**Beyond Gloss: A Hand-Centric Framework for Gloss-Free Sign Language Translation**|Richard Bowden Team|[2507.23575](http://arxiv.org/abs/2507.23575)|null|
|**2025-07-30**|**Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance**|Slim Frikha Team|[2507.22448](http://arxiv.org/abs/2507.22448)|null|
|**2025-07-25**|**MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI Agents**|Wenhai Wang Team|[2507.19478](http://arxiv.org/abs/2507.19478)|null|
|**2025-07-24**|**EgoExoBench: A Benchmark for First- and Third-person View Video Understanding in MLLMs**|Jiangmiao Pang Team|[2507.18342](http://arxiv.org/abs/2507.18342)|null|
|**2025-07-23**|**LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning**|Stefano Melacci Team|[2507.17482](http://arxiv.org/abs/2507.17482)|null|
|**2025-07-22**|**Temporally-Constrained Video Reasoning Segmentation and Automated Benchmark Construction**|Mathias Unberath Team|[2507.16718](http://arxiv.org/abs/2507.16718)|null|
|**2025-07-22**|**Explicit Context Reasoning with Supervision for Visual Tracking**|Shuxiang Song Team|[2507.16191](http://arxiv.org/abs/2507.16191)|null|
|**2025-07-18**|**Towards Constraint Temporal Answer Set Programming**|Igor Stéphan Team|[2507.13958](http://arxiv.org/abs/2507.13958)|null|
|**2025-07-16**|**DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning**|Philip S. Yu Team|[2507.13396](http://arxiv.org/abs/2507.13396)|null|
|**2025-07-17**|**A Translation of Probabilistic Event Calculus into Markov Decision Processes**|Luke Dickens Team|[2507.12989](http://arxiv.org/abs/2507.12989)|null|
|**2025-07-17**|**World Model-Based End-to-End Scene Generation for Accident Anticipation in Autonomous Driving**|Zhenning Li Team|[2507.12762](http://arxiv.org/abs/2507.12762)|null|
|**2025-07-22**|**T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs**|Guillaume Rabusseau Team|[2507.10183](http://arxiv.org/abs/2507.10183)|null|
|**2025-07-13**|**GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them?**|Huaxiu Yao Team|[2507.09491](http://arxiv.org/abs/2507.09491)|null|
|**2025-07-12**|**Online Long-term Point Tracking in the Foundation Model Era**|Görkay Aydemir Team|[2507.09217](http://arxiv.org/abs/2507.09217)|null|
|**2025-07-10**|**OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding**|Jiangmiao Pang Team|[2507.07984](http://arxiv.org/abs/2507.07984)|null|
|**2025-07-10**|**Scaling RL to Long Videos**|Song Han Team|[2507.07966](http://arxiv.org/abs/2507.07966)|null|
|**2025-07-09**|**Temporal Information Retrieval via Time-Specifier Model Merging**|Jong C. Park Team|[2507.06782](http://arxiv.org/abs/2507.06782)|null|
|**2025-07-08**|**DocTalk: Scalable Graph-based Dialogue Synthesis for Enhancing LLM Conversational Capabilities**|Haodong Wang Team|[2507.05750](http://arxiv.org/abs/2507.05750)|null|
|**2025-07-07**|**HV-MMBench: Benchmarking MLLMs for Human-Centric Video Understanding**|Xiang Bai Team|[2507.04909](http://arxiv.org/abs/2507.04909)|null|
|**2025-07-07**|**Tempo-R0: A Video-MLLM for Temporal Video Grounding through Efficient Temporal Sensing Reinforcement Learning**|Rong Shen Team|[2507.04702](http://arxiv.org/abs/2507.04702)|null|
|**2025-07-09**|**Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models**|Changliang Xu Team|[2507.03916](http://arxiv.org/abs/2507.03916)|null|
|**2025-07-08**|**Future Slot Prediction for Unsupervised Object Discovery in Surgical Video**|Daniel A. Hashimoto Team|[2507.01882](http://arxiv.org/abs/2507.01882)|null|
|**2025-07-01**|**CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs**|Wei Yang Bryan Lim Team|[2507.00817](http://arxiv.org/abs/2507.00817)|null|
|**2025-07-01**|**Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving**|Yadan Luo Team|[2507.00525](http://arxiv.org/abs/2507.00525)|null|
|**2025-06-28**|**MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding**|Daniel Tang Team|[2507.00068](http://arxiv.org/abs/2507.00068)|null|
|**2025-06-30**|**Flash-VStream: Efficient Real-Time Understanding for Long Video Streams**|Xiaojie Jin Team|[2506.23825](http://arxiv.org/abs/2506.23825)|null|
|**2025-07-01**|**Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning**|Ark Abhyudaya Team|[2506.22919](http://arxiv.org/abs/2506.22919)|null|
|**2025-06-28**|**AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results**|Saeid Rezaei Team|[2506.22843](http://arxiv.org/abs/2506.22843)|null|
|**2025-06-26**|**GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding**|Bihan Wen Team|[2506.21188](http://arxiv.org/abs/2506.21188)|null|
|**2025-06-25**|**A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs**|Jingyuan Wang Team|[2506.20073](http://arxiv.org/abs/2506.20073)|null|
|**2025-06-24**|**JCAPT: A Joint Modeling Approach for CAPT**|Berlin Chen Team|[2506.19315](http://arxiv.org/abs/2506.19315)|null|
|**2025-06-23**|**TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting**|Ertai E Team|[2506.18862](http://arxiv.org/abs/2506.18862)|null|
|**2025-06-23**|**T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent**|Hong Qing Yu Team|[2506.18559](http://arxiv.org/abs/2506.18559)|null|
|**2025-06-21**|**Machine Learning Model Integration with Open World Temporal Logic for Process Automation**|Paulo Shakarian Team|[2506.17776](http://arxiv.org/abs/2506.17776)|null|
|**2025-06-17**|**A Vision for Geo-Temporal Deep Research Systems: Towards Comprehensive, Transparent, and Reproducible Geo-Temporal Information Synthesis**|Piotr Gramacki Team|[2506.14345](http://arxiv.org/abs/2506.14345)|null|
|**2025-06-24**|**DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs**|Feng-Chi Chen Team|[2506.11558](http://arxiv.org/abs/2506.11558)|null|
|**2025-06-12**|**VRBench: A Benchmark for Multi-Step Reasoning in Long Narrative Videos**|Limin Wang Team|[2506.10857](http://arxiv.org/abs/2506.10857)|null|

<p align=right>(<a href=#updated-on-20251019>back to top</a>)</p>

## Robot Datasets

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-12**|**Load-Altering Attacks Against Power Grids: A Case Study Using the GB-36 Bus System Open Dataset**|Subhash Lakshminarayana Team|[2508.08945](http://arxiv.org/abs/2508.08945)|null|
|**2025-08-12**|**MolmoAct: Action Reasoning Models that can Reason in Space**|Ranjay Krishna Team|[2508.07917](http://arxiv.org/abs/2508.07917)|**[link](https://allenai.org/blog/molmoact)**|
|**2025-08-11**|**AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning**|Yang Liu Team|[2508.07626](http://arxiv.org/abs/2508.07626)|null|
|**2025-08-06**|**A tutorial note on collecting simulated data for vision-language-action models**|Jingfeng Zhang Team|[2508.06547](http://arxiv.org/abs/2508.06547)|null|
|**2025-08-08**|**Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation**|Jingkuan Song Team|[2508.06426](http://arxiv.org/abs/2508.06426)|null|
|**2025-08-07**|**Everything You Need to Know About CS Education: Open Results from a Survey of More Than 18,000 Participants**|Anastasiia Birillo Team|[2508.05286](http://arxiv.org/abs/2508.05286)|null|
|**2025-08-07**|**CSRAP: Enhanced Canvas Attention Scheduling for Real-Time Mission Critical Perception**|Tarek Abdelzaher Team|[2508.04976](http://arxiv.org/abs/2508.04976)|null|
|**2025-08-06**|**A Foundation Model for DAS Signal Recognition and Visual Prompt Tuning of the Pre-trained Model for Downstream Tasks**|Qi Xuan Team|[2508.04316](http://arxiv.org/abs/2508.04316)|null|
|**2025-08-05**|**Dynaword: From One-shot to Continuously Developed Datasets**|Kristoffer Nielbo Team|[2508.02271](http://arxiv.org/abs/2508.02271)|null|
|**2025-08-12**|**Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving**|Fabian B. Flohr Team|[2508.00589](http://arxiv.org/abs/2508.00589)|**[link](https://iv.ee.hm.edu/contextmotionclip/)**|
|**2025-08-01**|**H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation**|Jun Zhu Team|[2507.23523](http://arxiv.org/abs/2507.23523)|null|
|**2025-07-25**|**Graph Structure Learning with Privacy Guarantees for Open Graph Data**|Shengzhe Chen Team|[2507.19116](http://arxiv.org/abs/2507.19116)|null|
|**2025-07-23**|**BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems**|Christian Berger Team|[2507.17722](http://arxiv.org/abs/2507.17722)|null|
|**2025-07-22**|**MegaScience: Pushing the Frontiers of Post-Training Datasets for Science Reasoning**|Pengfei Liu Team|[2507.16812](http://arxiv.org/abs/2507.16812)|**[link](https://github.com/GAIR-NLP/MegaScience)**|
|**2025-07-15**|**An open dataset of neural networks for hypernetwork research**|Lior Shamir Team|[2507.15869](http://arxiv.org/abs/2507.15869)|null|
|**2025-07-21**|**Data-Driven MPC with Data Selection for Flexible Cable-Driven Robotic Arms**|Long Zeng Team|[2507.15677](http://arxiv.org/abs/2507.15677)|null|
|**2025-07-18**|**NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining**|Aleksandr Gordeev Team|[2507.14119](http://arxiv.org/abs/2507.14119)|null|
|**2025-07-18**|**CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis**|Kevin Kam Fung Yuen Team|[2507.14022](http://arxiv.org/abs/2507.14022)|null|
|**2025-07-17**|**Latent Policy Steering with Embodiment-Agnostic Pretrained World Models**|Jeff Schneider Team|[2507.13340](http://arxiv.org/abs/2507.13340)|null|
|**2025-07-18**|**EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos**|Xiaolong Wang Team|[2507.12440](http://arxiv.org/abs/2507.12440)|**[link](https://rchalyang.github.io/EgoVLA)**|
|**2025-07-16**|**A Multimodal Data Fusion Generative Adversarial Network for Real Time Underwater Sound Speed Field Construction**|Hao Zhang Team|[2507.11812](http://arxiv.org/abs/2507.11812)|null|
|**2025-07-15**|**Deciphering Delivery Mobility: A City-Scale, Path-Reconstructed Trajectory Dataset of Instant Delivery Riders**|Zuopeng Xiao Team|[2507.11584](http://arxiv.org/abs/2507.11584)|null|
|**2025-07-15**|**Multi-IMU Sensor Fusion for Legged Robots**|Zachary Manchester Team|[2507.11447](http://arxiv.org/abs/2507.11447)|null|
|**2025-07-14**|**Devanagari Handwritten Character Recognition using Convolutional Neural Network**|Prateek Mehta Team|[2507.10398](http://arxiv.org/abs/2507.10398)|null|
|**2025-07-11**|**Learning human-to-robot handovers through 3D scene reconstruction**|Changjae Oh Team|[2507.08726](http://arxiv.org/abs/2507.08726)|null|
|**2025-07-09**|**Evaluating Large Multimodal Models for Nutrition Analysis: A Benchmark Enriched with Contextual Metadata**|Fengqing Zhu Team|[2507.07048](http://arxiv.org/abs/2507.07048)|null|
|**2025-07-08**|**Is Diversity All You Need for Scalable Robotic Manipulation?**|Hongyang Li Team|[2507.06219](http://arxiv.org/abs/2507.06219)|null|
|**2025-07-07**|**A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation**|Russ Tedrake Team|[2507.05331](http://arxiv.org/abs/2507.05331)|null|
|**2025-07-04**|**Efficient and Effective Query Context-Aware Learning-to-Rank Model for Sequential Recommendation**|Marjan Celikik Team|[2507.03789](http://arxiv.org/abs/2507.03789)|null|
|**2025-07-03**|**MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real**|Alexei A. Efros Team|[2507.02864](http://arxiv.org/abs/2507.02864)|null|
|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Yanwei Fu Team|[2507.01424](http://arxiv.org/abs/2507.01424)|null|
|**2025-07-01**|**Geometry-aware 4D Video Generation for Robot Manipulation**|Shuran Song Team|[2507.01099](http://arxiv.org/abs/2507.01099)|null|
|**2025-07-01**|**HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning**|Chenjia Bai Team|[2507.00833](http://arxiv.org/abs/2507.00833)|null|
|**2025-07-01**|**The impact of the following vehicles behaviors on the car following behaviors of the ego-vehicle**|Dengbo He Team|[2507.00452](http://arxiv.org/abs/2507.00452)|null|
|**2025-06-27**|**MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages**|Dorothea Kolossa Team|[2506.22529](http://arxiv.org/abs/2506.22529)|null|
|**2025-06-27**|**4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration**|Li Zhang Team|[2506.22242](http://arxiv.org/abs/2506.22242)|null|
|**2025-07-08**|**BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve Gaussian Splatting**|Li Zhang Team|[2506.22099](http://arxiv.org/abs/2506.22099)|null|
|**2025-06-25**|**DemoDiffusion: One-Shot Human Imitation using pre-trained Diffusion Policy**|Shubham Tulsiani Team|[2506.20668](http://arxiv.org/abs/2506.20668)|null|
|**2025-06-24**|**ConStellaration: A dataset of QI-like stellarator plasma boundaries and optimization benchmarks**|Markus Kaiser Team|[2506.19583](http://arxiv.org/abs/2506.19583)|null|
|**2025-06-23**|**CUPID: Curating Data your Robot Loves with Influence Functions**|Jeannette Bohg Team|[2506.19121](http://arxiv.org/abs/2506.19121)|null|
|**2025-06-20**|**LLM-Generated Feedback Supports Learning If Learners Choose to Use It**|Kenneth R. Koedinger Team|[2506.17006](http://arxiv.org/abs/2506.17006)|**[link](https://github.com/conradborchers/ai-feedback-exp)**|
|**2025-07-07**|**Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining**|Ding Zhao Team|[2506.16475](http://arxiv.org/abs/2506.16475)|null|
|**2025-06-19**|**CapsDT: Diffusion-Transformer for Capsule Robot Manipulation**|Hongliang Ren Team|[2506.16263](http://arxiv.org/abs/2506.16263)|null|
|**2025-06-17**|**Data Driven Approach to Input Shaping for Vibration Suppression in a Flexible Robot Arm**|Markku Suomalainen Team|[2506.14405](http://arxiv.org/abs/2506.14405)|null|
|**2025-06-16**|**What Matters in Learning from Large-Scale Datasets for Robot Manipulation**|Danfei Xu Team|[2506.13536](http://arxiv.org/abs/2506.13536)|null|
|**2025-06-11**|**R-CARLA: High-Fidelity Sensor Simulations with Interchangeable Dynamics for Autonomous Racing**|Michele Magno Team|[2506.09629](http://arxiv.org/abs/2506.09629)|null|

<p align=right>(<a href=#updated-on-20251019>back to top</a>)</p>

## Multi-task Learning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-12**|**Link Prediction for Event Logs in the Process Industry**|Bela Gipp Team|[2508.09096](http://arxiv.org/abs/2508.09096)|null|
|**2025-08-12**|**Unified and Semantically Grounded Domain Adaptation for Medical Image Segmentation**|Chun Yuan Team|[2508.08660](http://arxiv.org/abs/2508.08660)|null|
|**2025-08-12**|**AgriGPT: a Large Language Model Ecosystem for Agriculture**|Shijian Li Team|[2508.08632](http://arxiv.org/abs/2508.08632)|null|
|**2025-08-12**|**Optimizing Retrieval-Augmented Generation (RAG) for Colloquial Cantonese: A LoRA-Based Systematic Review**|Linda Smail Team|[2508.08610](http://arxiv.org/abs/2508.08610)|null|
|**2025-08-12**|**DepressLLM: Interpretable domain-adapted language model for depression detection from real-world narratives**|Ju-Wan Kim Team|[2508.08591](http://arxiv.org/abs/2508.08591)|null|
|**2025-08-12**|**Boosting Generic Semi-Supervised Medical Image Segmentation via Diverse Teaching and Label Propagation**|Huihua Yang Team|[2508.08549](http://arxiv.org/abs/2508.08549)|null|
|**2025-08-12**|**Training Kindai OCR with parallel textline images and self-attention feature distance-based loss**|Asanobu Kitamoto Team|[2508.08537](http://arxiv.org/abs/2508.08537)|null|
|**2025-08-11**|**Sparse Partial Optimal Transport via Quadratic Regularization**|Dung Luong Team|[2508.08476](http://arxiv.org/abs/2508.08476)|null|
|**2025-08-11**|**UrzaGPT: LoRA-Tuned Large Language Models for Card Selection in Collectible Card Games**|Timo Bertram Team|[2508.08382](http://arxiv.org/abs/2508.08382)|null|
|**2025-08-10**|**Empirical Bayes for Data Integration**|David Rossell Team|[2508.08336](http://arxiv.org/abs/2508.08336)|null|
|**2025-08-11**|**Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion**|Fani Deligianni Team|[2508.08216](http://arxiv.org/abs/2508.08216)|null|
|**2025-08-11**|**From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations**|Martin Matzner Team|[2508.08061](http://arxiv.org/abs/2508.08061)|null|
|**2025-08-11**|**FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis**|Chunfeng Lian Team|[2508.07950](http://arxiv.org/abs/2508.07950)|null|
|**2025-08-11**|**CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning**|Ruixiang Tang Team|[2508.07871](http://arxiv.org/abs/2508.07871)|null|
|**2025-08-11**|**Exploiting Layer Normalization Fine-tuning in Visual Transformer Foundation Models for Classification**|Xi Yang Team|[2508.07577](http://arxiv.org/abs/2508.07577)|null|
|**2025-08-11**|**Physics-Informed Multimodal Bearing Fault Classification under Variable Operating Conditions using Transfer Learning**|Shivakumar Raman Team|[2508.07536](http://arxiv.org/abs/2508.07536)|null|
|**2025-08-10**|**CCFQA: A Benchmark for Cross-Lingual and Cross-Modal Speech and Text Factuality Evaluation**|Ming Liu Team|[2508.07295](http://arxiv.org/abs/2508.07295)|null|
|**2025-08-09**|**Reconstruction of Solar EUV Irradiance Using CaII K Images and SOHO/SEM Data with Bayesian Deep Learning and Uncertainty Quantification**|Serena Criscuoli Team|[2508.07065](http://arxiv.org/abs/2508.07065)|null|
|**2025-08-09**|**Statistical Inference for Autoencoder-based Anomaly Detection after Representation Learning-based Domain Adaptation**|Vo Nguyen Le Duy Team|[2508.07049](http://arxiv.org/abs/2508.07049)|null|
|**2025-08-09**|**Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification**|Eric Granger Team|[2508.06831](http://arxiv.org/abs/2508.06831)|null|
|**2025-07-23**|**On the Interaction of Compressibility and Adversarial Robustness**|Tolga Birdal Team|[2507.17725](http://arxiv.org/abs/2507.17725)|null|
|**2025-07-23**|**The Early Bird Identifies the Worm: You Can't Beat a Head Start in Long-Term Body Re-ID (ECHO-BID)**|Alice J. O'Toole Team|[2507.17640](http://arxiv.org/abs/2507.17640)|null|
|**2025-07-23**|**SDC-Net: A Domain Adaptation Framework with Semantic-Dynamic Consistency for Cross-Subject EEG Emotion Recognition**|Zi-Gang Huang Team|[2507.17524](http://arxiv.org/abs/2507.17524)|null|
|**2025-07-23**|**SFUOD: Source-Free Unknown Object Detection**|Gyeong-Moon Park Team|[2507.17373](http://arxiv.org/abs/2507.17373)|null|
|**2025-07-23**|**Model Compression Engine for Wearable Devices Skin Cancer Diagnosis**|Wilfredo E. Lugo-Beauchamp Team|[2507.17125](http://arxiv.org/abs/2507.17125)|null|
|**2025-07-23**|**Robust Five-Class and binary Diabetic Retinopathy Classification Using Transfer Learning and Data Augmentation**|Mohammad Alfrad Nobel Bhuiyan Team|[2507.17121](http://arxiv.org/abs/2507.17121)|null|
|**2025-07-22**|**Sensor Drift Compensation in Electronic-Nose-Based Gas Recognition Using Knowledge Distillation**|Xianghao Zhan Team|[2507.17071](http://arxiv.org/abs/2507.17071)|null|
|**2025-07-22**|**A Unifying Scheme for Extractive Content Selection Tasks**|Ido Dagan Team|[2507.16922](http://arxiv.org/abs/2507.16922)|null|
|**2025-07-22**|**Improving U-Net Confidence on TEM Image Data with L2-Regularization, Transfer Learning, and Deep Fine-Tuning**|Xing Wang Team|[2507.16779](http://arxiv.org/abs/2507.16779)|null|
|**2025-07-22**|**Synthetic Data Matters: Re-training with Geo-typical Synthetic Labels for Building Detection**|Rongjun Qin Team|[2507.16657](http://arxiv.org/abs/2507.16657)|null|
|**2025-07-22**|**Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox**|Giorgio Buttazzo Team|[2507.16413](http://arxiv.org/abs/2507.16413)|null|
|**2025-07-22**|**Continuous Test-time Domain Adaptation for Efficient Fault Detection under Evolving Operating Conditions**|Olga Fink Team|[2507.16354](http://arxiv.org/abs/2507.16354)|null|
|**2025-07-22**|**Perovskite-R1: A Domain-Specialized LLM for Intelligent Discovery of Precursor Additives and Experimental Design**|Zhong-Yi Lu Team|[2507.16307](http://arxiv.org/abs/2507.16307)|null|
|**2025-07-21**|**An empirical study for the early detection of Mpox from skin lesion images using pretrained CNN models leveraging XAI technique**|Ahmed Moustafa Team|[2507.15915](http://arxiv.org/abs/2507.15915)|null|
|**2025-07-21**|**Sufficiency-principled Transfer Learning via Model Averaging**|Xinyu Zhang Team|[2507.15416](http://arxiv.org/abs/2507.15416)|null|
|**2025-07-21**|**Universal crystal material property prediction via multi-view geometric fusion in graph transformers**|Yuen Wu Team|[2507.15303](http://arxiv.org/abs/2507.15303)|null|
|**2025-07-21**|**IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry**|Seunghwa Ryu Team|[2507.15268](http://arxiv.org/abs/2507.15268)|null|
|**2025-07-20**|**A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script**|Seid Muhie Yimam Team|[2507.15142](http://arxiv.org/abs/2507.15142)|null|
|**2025-07-20**|**Deep Generative Models in Condition and Structural Health Monitoring: Opportunities, Limitations and Future Outlook**|Dimitrios Chronopoulos Team|[2507.15026](http://arxiv.org/abs/2507.15026)|null|
|**2025-07-20**|**PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing**|Chia-Wen Lin Team|[2507.14826](http://arxiv.org/abs/2507.14826)|null|
|**2025-07-20**|**Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards**|Yingxue Zhang Team|[2507.14783](http://arxiv.org/abs/2507.14783)|null|
|**2025-07-19**|**GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset**|Juepeng Zheng Team|[2507.14697](http://arxiv.org/abs/2507.14697)|null|
|**2025-07-19**|**Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation**|Ulya Bayram Team|[2507.14693](http://arxiv.org/abs/2507.14693)|null|
|**2025-07-19**|**When few labeled target data suffice: a theory of semi-supervised domain adaptation via fine-tuning from multiple adaptive starts**|Yuansi Chen Team|[2507.14661](http://arxiv.org/abs/2507.14661)|null|
|**2025-07-19**|**Depthwise-Dilated Convolutional Adapters for Medical Object Tracking and Segmentation Using the Segment Anything Model 2**|You Zhang Team|[2507.14613](http://arxiv.org/abs/2507.14613)|null|
|**2025-07-19**|**Towards a Proactive Autoscaling Framework for Data Stream Processing at the Edge using GRU and Transfer Learning**|Linda Amoako Bannning Team|[2507.14597](http://arxiv.org/abs/2507.14597)|null|
|**2025-07-19**|**Parameter-transfer in spatial autoregressive models via model averaging**|Xinyu Zhang Team|[2507.14453](http://arxiv.org/abs/2507.14453)|null|
|**2025-07-19**|**IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark**|Ruiheng Zhang Team|[2507.14449](http://arxiv.org/abs/2507.14449)|null|
|**2025-07-18**|**Language Models as Ontology Encoders**|Ian Horrocks Team|[2507.14334](http://arxiv.org/abs/2507.14334)|null|
|**2025-07-18**|**SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering**|Michael Kampffmeyer Team|[2507.13779](http://arxiv.org/abs/2507.13779)|null|
|**2025-07-18**|**ISAC: From Human to Environmental Sensing**|Y. Jay Guo Team|[2507.13766](http://arxiv.org/abs/2507.13766)|null|
|**2025-07-18**|**CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer**|Teerapong Panboonyuen Team|[2507.13655](http://arxiv.org/abs/2507.13655)|null|
|**2025-07-17**|**Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica**|Walter Willinger Team|[2507.13476](http://arxiv.org/abs/2507.13476)|null|
|**2025-07-17**|**Disentangling coincident cell events using deep transfer learning and compressive sensing**|Oliver Hayden Team|[2507.13176](http://arxiv.org/abs/2507.13176)|null|
|**2025-07-17**|**Improving Diagnostic Accuracy of Pigmented Skin Lesions With CNNs: an Application on the DermaMNIST Dataset**|Medina Kapo Team|[2507.12961](http://arxiv.org/abs/2507.12961)|null|
|**2025-07-17**|**IDS-Net: A novel framework for few-shot photovoltaic power prediction with interpretable dynamic selection and feature information fusion**|Dunnan Liu Team|[2507.12745](http://arxiv.org/abs/2507.12745)|null|
|**2025-07-17**|**A Privacy-Preserving Semantic-Segmentation Method Using Domain-Adaptation Technique**|Hitoshi Kiya Team|[2507.12730](http://arxiv.org/abs/2507.12730)|null|
|**2025-07-16**|**Improving physics-informed neural network extrapolation via transfer learning and adaptive activation functions**|Zhandong Liu Team|[2507.12659](http://arxiv.org/abs/2507.12659)|null|
|**2025-07-16**|**Best Practices for Large-Scale, Pixel-Wise Crop Mapping and Transfer Learning Workflows**|Molly Sears Team|[2507.12590](http://arxiv.org/abs/2507.12590)|null|
|**2025-07-14**|**Quantum Transfer Learning to Boost Dementia Detection**|Himanshu Thapliyal Team|[2507.12485](http://arxiv.org/abs/2507.12485)|null|
|**2025-07-16**|**Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification**|Jihie Kim Team|[2507.12177](http://arxiv.org/abs/2507.12177)|null|
|**2025-07-16**|**SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection**|Fanman Meng Team|[2507.12017](http://arxiv.org/abs/2507.12017)|null|
|**2025-07-16**|**Dual form Complementary Masking for Domain-Adaptive Image Segmentation**|Zhiwei Xiong Team|[2507.12008](http://arxiv.org/abs/2507.12008)|null|
|**2025-07-15**|**Physics-Informed Transfer Learning for Data-Driven Sound Source Reconstruction in Near-Field Acoustic Holography**|Augusto Sarti Team|[2507.11070](http://arxiv.org/abs/2507.11070)|null|
|**2025-07-15**|**LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP**|Jing Dong Team|[2507.11052](http://arxiv.org/abs/2507.11052)|null|
|**2025-07-19**|**Domain-Adaptive Small Language Models for Structured Tax Code Prediction**|Luis Perez Team|[2507.10880](http://arxiv.org/abs/2507.10880)|null|
|**2025-07-14**|**HEIMDALL: a grapH-based sEIsMic Detector And Locator for microseismicity**|Davide Bacciu Team|[2507.10850](http://arxiv.org/abs/2507.10850)|null|
|**2025-07-20**|**Supporting SENCOTEN Language Documentation Efforts with Automatic Speech Recognition**|Roland Kuhn Team|[2507.10827](http://arxiv.org/abs/2507.10827)|null|
|**2025-07-14**|**National level satellite-based crop field inventories in smallholder landscapes**|Patrick Meyfroidt Team|[2507.10499](http://arxiv.org/abs/2507.10499)|null|
|**2025-07-14**|**Toward Real-World Table Agents: Capabilities, Workflows, and Design Principles for LLM-based Table Intelligence**|Junbo Zhao Team|[2507.10281](http://arxiv.org/abs/2507.10281)|null|
|**2025-07-14**|**Minimizing the Pretraining Gap: Domain-aligned Text-Based Person Retrieval**|Zhedong Zheng Team|[2507.10195](http://arxiv.org/abs/2507.10195)|null|
|**2025-07-14**|**Domain Borders Are There to Be Crossed With Federated Few-Shot Adaptation**|Frank-Michael Schleif Team|[2507.10160](http://arxiv.org/abs/2507.10160)|null|
|**2025-07-14**|**A Transfer Learning-Based Method for Water Body Segmentation in Remote Sensing Imagery: A Case Study of the Zhada Tulin Area**|Xin Tong Team|[2507.10084](http://arxiv.org/abs/2507.10084)|null|
|**2025-07-14**|**Leveraging Swin Transformer for enhanced diagnosis of Alzheimer's disease using multi-shell diffusion MRI**|Benoît Macq Team|[2507.09996](http://arxiv.org/abs/2507.09996)|null|
|**2025-07-14**|**Statistical Inference for Conditional Group Distributionally Robust Optimization with Cross-Entropy Loss**|Francis Bach Team|[2507.09905](http://arxiv.org/abs/2507.09905)|null|
|**2025-07-13**|**Low-Rank Adaptation of Deep Prior Neural Networks For Room Impulse Response Reconstruction**|Fabio Antonacci Team|[2507.09806](http://arxiv.org/abs/2507.09806)|null|
|**2025-07-13**|**Pre-trained Under Noise: A Framework for Robust Bone Fracture Detection in Medical Imaging**|Chengcheng Li Team|[2507.09731](http://arxiv.org/abs/2507.09731)|null|
|**2025-07-13**|**Hybrid Quantum-Classical Generative Adversarial Networks with Transfer Learning**|Ebrahim Ardeshir Larijani Team|[2507.09706](http://arxiv.org/abs/2507.09706)|null|
|**2025-07-13**|**NMIXX: Domain-Adapted Neural Embeddings for Cross-Lingual eXploration of Finance**|Youngjae Yu Team|[2507.09601](http://arxiv.org/abs/2507.09601)|null|
|**2025-07-13**|**Enhancing ALS Progression Tracking with Semi-Supervised ALSFRS-R Scores Estimated from Ambient Home Health Monitoring**|Xing Song Team|[2507.09460](http://arxiv.org/abs/2507.09460)|null|
|**2025-07-12**|**Domain Adaptation and Multi-view Attention for Learnable Landmark Tracking with Sparse Data**|Karthik Dantu Team|[2507.09420](http://arxiv.org/abs/2507.09420)|null|
|**2025-07-12**|**EduFlow: Advancing MLLMs' Problem-Solving Proficiency through Multi-Stage, Multi-Perspective Critique**|Jian Xie Team|[2507.09374](http://arxiv.org/abs/2507.09374)|null|
|**2025-07-12**|**Simplifying Traffic Anomaly Detection with Video Foundation Models**|Gijs Dubbelman Team|[2507.09338](http://arxiv.org/abs/2507.09338)|null|
|**2025-07-12**|**Calibrated and Robust Foundation Models for Vision-Language and Medical Image Tasks Under Distribution Shift**|Tahir Syed Team|[2507.09222](http://arxiv.org/abs/2507.09222)|null|
|**2025-07-12**|**CycleGAN-Driven Transfer Learning for Electronics Response Emulation in High-Purity Germanium Detectors**|Aobo Li Team|[2507.09106](http://arxiv.org/abs/2507.09106)|null|
|**2025-07-11**|**Domain Adaptation-Enabled Realistic Map-Based Channel Estimation for MIMO-OFDM**|Georges Kaddoum Team|[2507.08974](http://arxiv.org/abs/2507.08974)|null|
|**2025-07-11**|**The Bayesian Approach to Continual Learning: An Overview**|Tameem Adel Team|[2507.08922](http://arxiv.org/abs/2507.08922)|null|
|**2025-07-15**|**Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning**|Tao Chen Team|[2507.08730](http://arxiv.org/abs/2507.08730)|null|
|**2025-07-11**|**From Enhancement to Understanding: Build a Generalized Bridge for Low-light Vision via Semantically Consistent Unsupervised Fine-tuning**|Lizhuang Ma Team|[2507.08380](http://arxiv.org/abs/2507.08380)|null|
|**2025-07-11**|**MM-Gesture: Towards Precise Micro-Gesture Recognition through Multimodal Fusion**|Dan Guo Team|[2507.08344](http://arxiv.org/abs/2507.08344)|null|
|**2025-07-11**|**Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment**|Lamei Zhang Team|[2507.08290](http://arxiv.org/abs/2507.08290)|null|
|**2025-07-11**|**Transfer Learning and Mixup for Fine-Grained Few-Shot Fungi Classification**|Anthony Miyaguchi Team|[2507.08248](http://arxiv.org/abs/2507.08248)|null|
|**2025-07-10**|**An Embedded Real-time Object Alert System for Visually Impaired: A Monocular Depth Estimation based Approach through Computer Vision**|Md. Ishan Arefin Hossain Team|[2507.08165](http://arxiv.org/abs/2507.08165)|null|
|**2025-07-10**|**An Object-Based Deep Learning Approach for Building Height Estimation from Single SAR Images**|Paolo Gamba Team|[2507.08096](http://arxiv.org/abs/2507.08096)|null|
|**2025-07-08**|**Self-Consistency in Vision-Language Models for Precision Agriculture: Multi-Response Consensus for Crop Disease Management**|Pratik Desai Team|[2507.08024](http://arxiv.org/abs/2507.08024)|null|
|**2025-07-11**|**Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection**|Yi-Zhe Song Team|[2507.07994](http://arxiv.org/abs/2507.07994)|null|
|**2025-07-10**|**Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal Inconsistency for Remote Physiological Measurement**|Dengbo He Team|[2507.07908](http://arxiv.org/abs/2507.07908)|null|
|**2025-07-10**|**BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning**|Yize Chen Team|[2507.07769](http://arxiv.org/abs/2507.07769)|null|
|**2025-07-10**|**Sparse Causal Discovery with Generative Intervention for Unsupervised Graph Domain Adaptation**|Ming Zhang Team|[2507.07621](http://arxiv.org/abs/2507.07621)|null|
|**2025-07-08**|**CoPT: Unsupervised Domain Adaptive Segmentation using Domain-Agnostic Text Embeddings**|Michael S. Ryoo Team|[2507.07125](http://arxiv.org/abs/2507.07125)|null|
|**2025-07-09**|**Deep Brain Net: An Optimized Deep Learning Model for Brain tumor Detection in MRI Images Using EfficientNetB0 and ResNet50 with Transfer Learning**|Ravish Desai Team|[2507.07011](http://arxiv.org/abs/2507.07011)|null|
|**2025-07-10**|**ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining**|Byoung-Ki Jeon Team|[2507.06795](http://arxiv.org/abs/2507.06795)|null|
|**2025-07-09**|**Tailoring deep learning for real-time brain-computer interfaces: From offline models to calibration-free online decoding**|Bin Yang Team|[2507.06779](http://arxiv.org/abs/2507.06779)|null|
|**2025-07-09**|**On the Hardness of Unsupervised Domain Adaptation: Optimal Learners and Information-Theoretic Perspective**|Yongyi Mao Team|[2507.06552](http://arxiv.org/abs/2507.06552)|null|
|**2025-07-08**|**Bridging Data Gaps of Rare Conditions in ICU: A Multi-Disease Adaptation Approach for Clinical Prediction**|Tingting Zhu Team|[2507.06432](http://arxiv.org/abs/2507.06432)|null|
|**2025-07-08**|**Mitigating Multi-Sequence 3D Prostate MRI Data Scarcity through Domain Adaptation using Locally-Trained Latent Diffusion Models for Prostate Cancer Detection**|Masoom A. Haider Team|[2507.06384](http://arxiv.org/abs/2507.06384)|null|
|**2025-07-08**|**DS@GT at CheckThat! 2025: Detecting Subjectivity via Transfer-Learning and Corrective Data Augmentation**|Dionne Bang Team|[2507.06189](http://arxiv.org/abs/2507.06189)|null|
|**2025-07-09**|**A Survey on Prompt Tuning**|Nigel Collier Team|[2507.06085](http://arxiv.org/abs/2507.06085)|null|
|**2025-07-08**|**Contrastive and Transfer Learning for Effective Audio Fingerprinting through a Real-World Evaluation Protocol**|Theodoros Giannakopoulos Team|[2507.06070](http://arxiv.org/abs/2507.06070)|null|
|**2025-07-08**|**Improving Robustness of Foundation Models in Domain Adaptation with Soup-Adapters**|Marco Roschkowski Team|[2507.05807](http://arxiv.org/abs/2507.05807)|null|
|**2025-07-08**|**PSAT: Pediatric Segmentation Approaches via Adult Augmentations and Transfer Learning**|Philippe Meyer Team|[2507.05764](http://arxiv.org/abs/2507.05764)|null|
|**2025-07-08**|**Domain adaptation of large language models for geotechnical applications**|Cheng Chen Team|[2507.05613](http://arxiv.org/abs/2507.05613)|null|
|**2025-07-07**|**Predicting mutational effects on protein binding from folding energy**|Brian Trippe Team|[2507.05502](http://arxiv.org/abs/2507.05502)|null|
|**2025-07-07**|**YOLO-APD: Enhancing YOLOv8 for Robust Pedestrian Detection on Complex Road Geometries**|John Kandiri Team|[2507.05376](http://arxiv.org/abs/2507.05376)|null|
|**2025-07-07**|**Conditional Graph Neural Network for Predicting Soft Tissue Deformation and Forces**|Philippe C. Cattin Team|[2507.05315](http://arxiv.org/abs/2507.05315)|null|
|**2025-07-07**|**$\varphi$ -Adapt: A Physics-Informed Adaptation Learning Approach to 2D Quantum Material Discovery**|Khoa Luu Team|[2507.05184](http://arxiv.org/abs/2507.05184)|null|
|**2025-07-07**|**O_FT@EvalLLM2025 : étude comparative de choix de données et de stratégies d'apprentissage pour l'adaptation de modèles de langue à un domaine**|Géraldine Damnati Team|[2507.04895](http://arxiv.org/abs/2507.04895)|null|
|**2025-07-07**|**HGNet: High-Order Spatial Awareness Hypergraph and Multi-Scale Context Attention Network for Colorectal Polyp Detection**|Bin zhao Team|[2507.04880](http://arxiv.org/abs/2507.04880)|null|
|**2025-07-07**|**Towards Human-in-the-Loop Onset Detection: A Transfer Learning Approach for Maracatu**|António Sá Pinto Team|[2507.04858](http://arxiv.org/abs/2507.04858)|null|
|**2025-07-07**|**Model Compression using Progressive Channel Pruning**|Dong Xu Team|[2507.04792](http://arxiv.org/abs/2507.04792)|null|
|**2025-07-07**|**Interaction-Merged Motion Planning: Effectively Leveraging Diverse Motion Datasets for Robust Planning**|Kuk-Jin Yoon Team|[2507.04790](http://arxiv.org/abs/2507.04790)|null|
|**2025-07-07**|**An analysis of vision-language models for fabric retrieval**|Fabio Poiesi Team|[2507.04735](http://arxiv.org/abs/2507.04735)|null|
|**2025-07-06**|**Transfer Learning in Infinite Width Feature Learning Networks**|Cengiz Pehlevan Team|[2507.04448](http://arxiv.org/abs/2507.04448)|null|
|**2025-07-06**|**Domain Adaptation of Drag Reduction Policy to Partial Measurements**|Georgios Rigas Team|[2507.04309](http://arxiv.org/abs/2507.04309)|null|
|**2025-07-06**|**Mixed-Sample SGD: an End-to-end Analysis of Supervised Transfer Learning**|Samory Kpotufe Team|[2507.04194](http://arxiv.org/abs/2507.04194)|null|
|**2025-07-05**|**When Data-Free Knowledge Distillation Meets Non-Transferable Teacher: Escaping Out-of-Distribution Trap is All You Need**|Tongliang Liu Team|[2507.04119](http://arxiv.org/abs/2507.04119)|null|

<p align=right>(<a href=#updated-on-20251019>back to top</a>)</p>

## Robot Foundation Models

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-12**|**MolmoAct: Action Reasoning Models that can Reason in Space**|Ranjay Krishna Team|[2508.07917](http://arxiv.org/abs/2508.07917)|**[link](https://allenai.org/blog/molmoact)**|
|**2025-08-08**|**EcBot: Data-Driven Energy Consumption Open-Source MATLAB Library for Manipulators**|Mikkel Baun Kjærgaard Team|[2508.06276](http://arxiv.org/abs/2508.06276)|null|
|**2025-08-06**|**Open Scene Graphs for Open-World Object-Goal Navigation**|David Hsu Team|[2508.04678](http://arxiv.org/abs/2508.04678)|null|
|**2025-08-01**|**H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation**|Jun Zhu Team|[2507.23523](http://arxiv.org/abs/2507.23523)|null|
|**2025-07-25**|**Foundation Model-Driven Grasping of Unknown Objects via Center of Gravity Estimation**|Yuru Bai Team|[2507.19242](http://arxiv.org/abs/2507.19242)|null|
|**2025-07-15**|**Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning**|Jun Morimoto Team|[2507.10899](http://arxiv.org/abs/2507.10899)|null|
|**2025-07-14**|**Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection**|Colin Bellinger Team|[2507.10814](http://arxiv.org/abs/2507.10814)|null|
|**2025-07-14**|**Foundation Model Driven Robotics: A Comprehensive Review**|Ammar Waheed Team|[2507.10087](http://arxiv.org/abs/2507.10087)|null|
|**2025-07-24**|**Hand Gesture Recognition for Collaborative Robots Using Lightweight Deep Learning in Real-Time Robotic Systems**|Mauridhi Hery Purnomo Team|[2507.10055](http://arxiv.org/abs/2507.10055)|null|
|**2025-07-07**|**A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation**|Russ Tedrake Team|[2507.05331](http://arxiv.org/abs/2507.05331)|null|
|**2025-06-30**|**World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation**|Lin Shao Team|[2506.23919](http://arxiv.org/abs/2506.23919)|null|
|**2025-06-24**|**Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI**|Dongzhan Zhou Team|[2506.19613](http://arxiv.org/abs/2506.19613)|null|
|**2025-06-21**|**Risk-Guided Diffusion: Toward Deploying Robot Foundation Models in Space, Where Failure Is Not An Option**|Shehryar Khattak Team|[2506.17601](http://arxiv.org/abs/2506.17601)|null|
|**2025-06-20**|**General-Purpose Robotic Navigation via LVLM-Orchestrated Perception, Reasoning, and Acting**|Georgios Georgakis Team|[2506.17462](http://arxiv.org/abs/2506.17462)|null|
|**2025-06-13**|**mimic-one: a Scalable Model Recipe for General Purpose Robot Dexterity**|Robert K. Katzschmann Team|[2506.11916](http://arxiv.org/abs/2506.11916)|null|
|**2025-05-28**|**ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation**|Wenqiang Zhang Team|[2505.22159](http://arxiv.org/abs/2505.22159)|null|
|**2025-05-29**|**ChatVLA-2: Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge**|Yi Xu Team|[2505.21906](http://arxiv.org/abs/2505.21906)|**[link](https://chatvla-2.github.io/)**|
|**2025-06-16**|**PartInstruct: Part-level Instruction Following for Fine-grained Robot Manipulation**|Tianmin Shu Team|[2505.21652](http://arxiv.org/abs/2505.21652)|null|
|**2025-07-08**|**Hume: Introducing System-2 Thinking in Visual-Language-Action Model**|Xuelong Li Team|[2505.21432](http://arxiv.org/abs/2505.21432)|null|
|**2025-05-27**|**Think Twice, Act Once: Token-Aware Compression and Action Reuse for Efficient Inference in Vision-Language-Action Models**|Tao Chen Team|[2505.21200](http://arxiv.org/abs/2505.21200)|null|
|**2025-05-27**|**Spatial RoboGrasp: Generalized Robotic Grasping Control Policy**|Luhui Hu Team|[2505.20814](http://arxiv.org/abs/2505.20814)|null|
|**2025-06-03**|**EgoZero: Robot Learning from Smart Glasses**|Lerrel Pinto Team|[2505.20290](http://arxiv.org/abs/2505.20290)|null|
|**2025-05-21**|**WaveTouch: Active Tactile Sensing Using Vibro-Feedback for Classification of Variable Stiffness and Infill Density Objects**|Bakhtiyar Orazbayev Team|[2505.16062](http://arxiv.org/abs/2505.16062)|null|
|**2025-05-24**|**Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization**|Junwei Liang Team|[2505.15660](http://arxiv.org/abs/2505.15660)|**[link](https://github.com/jiaming-zhou/X-ICM)**|
|**2025-05-24**|**RoboCulture: A Robotics Platform for Automated Biological Experimentation**|Milica Radisic Team|[2505.14941](http://arxiv.org/abs/2505.14941)|null|
|**2025-05-22**|**InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning**|Jingkuan Song Team|[2505.13888](http://arxiv.org/abs/2505.13888)|**[link](https://github.com/inspirevla/inspire)**|
|**2025-05-22**|**Policy Contrastive Decoding for Robotic Foundation Models**|Lianli Gao Team|[2505.13255](http://arxiv.org/abs/2505.13255)|**[link](https://github.com/Koorye/PCD)**|
|**2025-05-17**|**OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning**|Yang Gao Team|[2505.11917](http://arxiv.org/abs/2505.11917)|null|
|**2025-05-15**|**Towards Safe Robot Foundation Models Using Inductive Biases**|Jan Peters Team|[2505.10219](http://arxiv.org/abs/2505.10219)|null|

<p align=right>(<a href=#updated-on-20251019>back to top</a>)</p>

## Vision Language Models

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-08-12**|**OpenCUA: Open Foundations for Computer-Use Agents**|Tao Yu Team|[2508.09123](http://arxiv.org/abs/2508.09123)|null|
|**2025-08-12**|**Bridging Formal Language with Chain-of-Thought Reasoning to Geometry Problem Solving**|Tian Ding Team|[2508.09099](http://arxiv.org/abs/2508.09099)|null|
|**2025-08-12**|**Addressing Bias in VLMs for Glaucoma Detection Without Protected Attribute Supervision**|Prashnna Gyawali Team|[2508.09087](http://arxiv.org/abs/2508.09087)|null|
|**2025-08-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Jiale Cao Team|[2508.09071](http://arxiv.org/abs/2508.09071)|**[link](https://linsun449.github.io/GeoVLA/)**|
|**2025-08-12**|**VLM-3D:End-to-End Vision-Language Models for Open-World 3D Perception**|Lei He Team|[2508.09061](http://arxiv.org/abs/2508.09061)|null|
|**2025-08-12**|**MVISU-Bench: Benchmarking Mobile Agents for Real-World Tasks by Multi-App, Vague, Interactive, Single-App and Unethical Instructions**|Jin Xu Team|[2508.09057](http://arxiv.org/abs/2508.09057)|null|
|**2025-08-12**|**Rational Inverse Reasoning**|Leslie Pack Kaelbling Team|[2508.08983](http://arxiv.org/abs/2508.08983)|null|
|**2025-08-12**|**How Does a Virtual Agent Decide Where to Look? -- Symbolic Cognitive Reasoning for Embodied Head Rotation**|Hyeongyeop Kang Team|[2508.08930](http://arxiv.org/abs/2508.08930)|null|
|**2025-08-12**|**Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models**|Xuelong Li Team|[2508.08926](http://arxiv.org/abs/2508.08926)|null|
|**2025-08-12**|**3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs**|Eddy Ilg Team|[2508.08821](http://arxiv.org/abs/2508.08821)|null|
|**2025-08-12**|**SafeFix: Targeted Model Repair via Controlled Image Generation**|Yunhui Guo Team|[2508.08701](http://arxiv.org/abs/2508.08701)|null|
|**2025-08-12**|**STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision**|Marios Savvides Team|[2508.08688](http://arxiv.org/abs/2508.08688)|null|
|**2025-08-12**|**AME: Aligned Manifold Entropy for Robust Vision-Language Distillation**|Yuming Ou Team|[2508.08644](http://arxiv.org/abs/2508.08644)|null|
|**2025-08-13**|**Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization**|Hyunwoo J. Kim Team|[2508.08604](http://arxiv.org/abs/2508.08604)|null|
|**2025-08-12**|**Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation**|Qi Lei Team|[2508.08570](http://arxiv.org/abs/2508.08570)|null|
|**2025-08-11**|**VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models**|Ravikumar Balakrishnan Team|[2508.08521](http://arxiv.org/abs/2508.08521)|null|
|**2025-08-11**|**Re:Verse -- Can Your VLM Read a Manga?**|Shruti Vyas Team|[2508.08508](http://arxiv.org/abs/2508.08508)|null|
|**2025-08-11**|**ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks**|Chunhua Shen Team|[2508.08240](http://arxiv.org/abs/2508.08240)|null|
|**2025-08-11**|**Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model**|Shaoliang Peng Team|[2508.08199](http://arxiv.org/abs/2508.08199)|null|
|**2025-08-11**|**BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models**|Bo Wang Team|[2508.08040](http://arxiv.org/abs/2508.08040)|null|
|**2025-07-23**|**BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems**|Christian Berger Team|[2507.17722](http://arxiv.org/abs/2507.17722)|null|
|**2025-07-23**|**InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation**|Jiangmiao Pang Team|[2507.17520](http://arxiv.org/abs/2507.17520)|null|
|**2025-07-23**|**Dynamic Scoring with Enhanced Semantics for Training-Free Human-Object Interaction Detection**|Elisa Ricci Team|[2507.17456](http://arxiv.org/abs/2507.17456)|null|
|**2025-07-23**|**VLM-Guided Visual Place Recognition for Planet-Scale Geo-Localization**|Shoaib Ehsan Team|[2507.17455](http://arxiv.org/abs/2507.17455)|null|
|**2025-07-23**|**Dynamic-DINO: Fine-Grained Mixture of Experts Tuning for Real-time Open-Vocabulary Object Detection**|Xi Li Team|[2507.17436](http://arxiv.org/abs/2507.17436)|null|
|**2025-07-23**|**Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models**|Guanghui Sun Team|[2507.17379](http://arxiv.org/abs/2507.17379)|null|
|**2025-07-23**|**RoadBench: A Vision-Language Foundation Model and Benchmark for Road Damage Understanding**|Tianyang Wang Team|[2507.17353](http://arxiv.org/abs/2507.17353)|null|
|**2025-07-23**|**HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study**|Maria Spence Team|[2507.17118](http://arxiv.org/abs/2507.17118)|null|
|**2025-07-23**|**FedVLM: Scalable Personalized Vision-Language Models through Federated Learning**|Habeeb Olufowobi Team|[2507.17088](http://arxiv.org/abs/2507.17088)|null|
|**2025-07-22**|**VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings**|Kannan Achan Team|[2507.17080](http://arxiv.org/abs/2507.17080)|null|
|**2025-07-22**|**Controllable Hybrid Captioner for Improved Long-form Video Understanding**|Arun Reddy Team|[2507.17047](http://arxiv.org/abs/2507.17047)|null|
|**2025-07-22**|**Semi-off-Policy Reinforcement Learning for Vision-Language Slow-thinking Reasoning**|Kai Chen Team|[2507.16814](http://arxiv.org/abs/2507.16814)|null|
|**2025-07-22**|**Cooling Matters: Benchmarking Large Language Models and Vision-Language Models on Liquid-Cooled Versus Air-Cooled H100 GPU Systems**|Arslan Munir Team|[2507.16781](http://arxiv.org/abs/2507.16781)|null|
|**2025-07-22**|**Enhancing Remote Sensing Vision-Language Models Through MLLM and LLM-Based High-Quality Image-Text Dataset Generation**|Ke Yang Team|[2507.16716](http://arxiv.org/abs/2507.16716)|null|
|**2025-07-22**|**Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory**|Marco Hutter Team|[2507.16713](http://arxiv.org/abs/2507.16713)|null|
|**2025-07-22**|**Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models**|Chao Zhang Team|[2507.16524](http://arxiv.org/abs/2507.16524)|null|
|**2025-07-22**|**SceneLoom: Communicating Data with Scene Context**|Siming Chen Team|[2507.16466](http://arxiv.org/abs/2507.16466)|null|
|**2025-07-22**|**Quality Text, Robust Vision: The Role of Language in Enhancing Visual Robustness of Vision-Language Models**|Isao Echizen Team|[2507.16257](http://arxiv.org/abs/2507.16257)|null|
|**2025-07-22**|**SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction**|Jiaqi Wang Team|[2507.15852](http://arxiv.org/abs/2507.15852)|null|
|**2025-07-21**|**Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models**|Erkut Erdem Team|[2507.15824](http://arxiv.org/abs/2507.15824)|null|
|**2025-07-23**|**Visual-Language Model Knowledge Distillation Method for Image Quality Assessment**|Jiarun Song Team|[2507.15680](http://arxiv.org/abs/2507.15680)|null|
|**2025-07-21**|**Smart Eyes for Silent Threats: VLMs and In-Context Learning for THz Imaging**|Margret Keuper Team|[2507.15576](http://arxiv.org/abs/2507.15576)|null|
|**2025-07-21**|**HOLa: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation**|Robby T. Tan Team|[2507.15542](http://arxiv.org/abs/2507.15542)|null|
|**2025-07-21**|**Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner**|Lin Ma Team|[2507.15509](http://arxiv.org/abs/2507.15509)|null|
|**2025-07-21**|**One Last Attention for Your Vision-Language Model**|Zhiqiang Shen Team|[2507.15480](http://arxiv.org/abs/2507.15480)|null|
|**2025-07-21**|**EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent**|Xinlei Chen Team|[2507.15428](http://arxiv.org/abs/2507.15428)|null|
|**2025-07-21**|**In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems**|Christoph Busch Team|[2507.15285](http://arxiv.org/abs/2507.15285)|null|
|**2025-07-21**|**VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving**|Tong Heng Lee Team|[2507.15266](http://arxiv.org/abs/2507.15266)|null|
|**2025-07-20**|**Survey of GenAI for Automotive Software Development: From Requirements to Executable Code**|Alois Knoll Team|[2507.15025](http://arxiv.org/abs/2507.15025)|null|
|**2025-07-20**|**Hierarchical Cross-modal Prompt Learning for Vision-Language Models**|Zhenhua Huang Team|[2507.14976](http://arxiv.org/abs/2507.14976)|null|
|**2025-07-20**|**FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models**|Mengnan Du Team|[2507.14823](http://arxiv.org/abs/2507.14823)|null|
|**2025-07-19**|**IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark**|Ruiheng Zhang Team|[2507.14449](http://arxiv.org/abs/2507.14449)|null|
|**2025-07-18**|**CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation**|Nicolas Thome Team|[2507.14312](http://arxiv.org/abs/2507.14312)|null|
|**2025-07-18**|**In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding**|Leonid Sigal Team|[2507.14298](http://arxiv.org/abs/2507.14298)|null|
|**2025-07-18**|**VLA-Mark: A cross modal watermark for large vision-language alignment model**|Xuming Hu Team|[2507.14067](http://arxiv.org/abs/2507.14067)|null|
|**2025-07-18**|**EdgeVLA: Efficient Vision-Language-Action Models**|Benjamin Bolte Team|[2507.14049](http://arxiv.org/abs/2507.14049)|null|
|**2025-07-18**|**Moodifier: MLLM-Enhanced Emotion-Driven Image Editing**|Sharon X. Huang Team|[2507.14024](http://arxiv.org/abs/2507.14024)|null|
|**2025-07-18**|**When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models**|Alberto Cazzaniga Team|[2507.13868](http://arxiv.org/abs/2507.13868)|null|
|**2025-07-18**|**Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions**|Jiajun Zhang Team|[2507.13773](http://arxiv.org/abs/2507.13773)|null|
|**2025-07-17**|**LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning**|Margrit Betke Team|[2507.13568](http://arxiv.org/abs/2507.13568)|null|
|**2025-07-17**|**COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark**|Vasu Sharma Team|[2507.13405](http://arxiv.org/abs/2507.13405)|null|
|**2025-07-17**|**VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning**|Jiaya Jia Team|[2507.13348](http://arxiv.org/abs/2507.13348)|null|
|**2025-07-17**|**Leveraging Language Prior for Infrared Small Target Detection**|Pravendra Singh Team|[2507.13113](http://arxiv.org/abs/2507.13113)|null|
|**2025-07-17**|**GLAD: Generalizable Tuning for Vision-Language Models**|Shifeng Chen Team|[2507.13089](http://arxiv.org/abs/2507.13089)|null|
|**2025-07-17**|**Advancing Complex Wide-Area Scene Understanding with Hierarchical Coresets Selection**|Changwen Zheng Team|[2507.13061](http://arxiv.org/abs/2507.13061)|null|
|**2025-07-17**|**LaViPlan : Language-Guided Visual Path Planning with RLVR**|Hayeon Oh Team|[2507.12911](http://arxiv.org/abs/2507.12911)|null|
|**2025-07-17**|**City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning**|Xiaowen Chu Team|[2507.12795](http://arxiv.org/abs/2507.12795)|null|
|**2025-07-16**|**VLMgineer: Vision Language Models as Robotic Toolsmiths**|Dinesh Jayaraman Team|[2507.12644](http://arxiv.org/abs/2507.12644)|null|
|**2025-07-16**|**NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting**|Chaoli Wang Team|[2507.12621](http://arxiv.org/abs/2507.12621)|null|
|**2025-07-16**|**MindJourney: Test-Time Scaling with World Models for Spatial Reasoning**|Chuang Gan Team|[2507.12508](http://arxiv.org/abs/2507.12508)|null|
|**2025-07-16**|**ReAL-AD: Towards Human-Like Reasoning in End-to-End Autonomous Driving**|Xinge Zhu Team|[2507.12499](http://arxiv.org/abs/2507.12499)|null|
|**2025-07-15**|**Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering**|Dimosthenis Karatzas Team|[2507.12490](http://arxiv.org/abs/2507.12490)|null|
|**2025-07-20**|**PhysX-3D: Physical-Grounded 3D Asset Generation**|Ziwei Liu Team|[2507.12465](http://arxiv.org/abs/2507.12465)|null|
|**2025-07-16**|**Describe Anything Model for Visual Question Answering on Text-rich Images**|Min Xu Team|[2507.12441](http://arxiv.org/abs/2507.12441)|null|
|**2025-07-16**|**AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models**|Sihao Ding Team|[2507.12414](http://arxiv.org/abs/2507.12414)|null|
|**2025-07-16**|**Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models**|Bernhard Kainz Team|[2507.12236](http://arxiv.org/abs/2507.12236)|null|
|**2025-07-16**|**InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing**|Wen-Huang Cheng Team|[2507.12060](http://arxiv.org/abs/2507.12060)|null|
|**2025-07-16**|**GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models**|Rongrong Ji Team|[2507.11969](http://arxiv.org/abs/2507.11969)|null|
|**2025-07-16**|**POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering**|Qin Jin Team|[2507.11939](http://arxiv.org/abs/2507.11939)|null|
|**2025-07-15**|**Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis**|Lihang Ying Team|[2507.11730](http://arxiv.org/abs/2507.11730)|null|
|**2025-07-18**|**How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study**|Rossella Arcucci Team|[2507.11200](http://arxiv.org/abs/2507.11200)|null|
|**2025-07-15**|**Bridging the Gap in Vision Language Models in Identifying Unsafe Concepts Across Modalities**|Yang Zhang Team|[2507.11155](http://arxiv.org/abs/2507.11155)|null|
|**2025-07-15**|**Assessing Color Vision Test in Large Vision-language Models**|Hongyang Chen Team|[2507.11153](http://arxiv.org/abs/2507.11153)|null|
|**2025-07-15**|**MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models**|Hamza Moustafa Team|[2507.11114](http://arxiv.org/abs/2507.11114)|null|
|**2025-07-15**|**Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander**|Lei Chen Team|[2507.11079](http://arxiv.org/abs/2507.11079)|null|
|**2025-07-15**|**Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection**|Guanzhong Tian Team|[2507.11003](http://arxiv.org/abs/2507.11003)|null|
|**2025-07-14**|**EmbRACE-3K: Embodied Reasoning and Action in Complex Environments**|Xiaojuan Qi Team|[2507.10548](http://arxiv.org/abs/2507.10548)|null|
|**2025-07-14**|**CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding**|Yi Wang Team|[2507.10449](http://arxiv.org/abs/2507.10449)|null|
|**2025-07-14**|**Beyond Graph Model: Reliable VLM Fine-Tuning via Random Graph Adapter**|Bin Luo Team|[2507.10355](http://arxiv.org/abs/2507.10355)|null|
|**2025-07-14**|**Synthesizing Near-Boundary OOD Samples for Out-of-Distribution Detection**|Wenqiang Zhang Team|[2507.10225](http://arxiv.org/abs/2507.10225)|null|
|**2025-07-14**|**BlueGlass: A Framework for Composite AI Safety**|Kay-Ulrich Scholl Team|[2507.10106](http://arxiv.org/abs/2507.10106)|null|
|**2025-07-14**|**Foundation Model Driven Robotics: A Comprehensive Review**|Ammar Waheed Team|[2507.10087](http://arxiv.org/abs/2507.10087)|null|
|**2025-07-14**|**LayLens: Improving Deepfake Understanding through Simplified Explanations**|Abhinav Dhall Team|[2507.10066](http://arxiv.org/abs/2507.10066)|null|
|**2025-07-14**|**CoSMo: A Multimodal Transformer for Page Stream Segmentation in Comic Books**|Dimosthenis Karatzas Team|[2507.10053](http://arxiv.org/abs/2507.10053)|null|
|**2025-07-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Zhen Lei Team|[2507.09961](http://arxiv.org/abs/2507.09961)|null|
|**2025-07-13**|**NegRefine: Refining Negative Label-Based Zero-Shot OOD Detection**|Pulei Xiong Team|[2507.09795](http://arxiv.org/abs/2507.09795)|null|
|**2025-07-13**|**Towards Fine-Grained Adaptation of CLIP via a Self-Trained Alignment Score**|Muhammad Haris Khan Team|[2507.09615](http://arxiv.org/abs/2507.09615)|null|
|**2025-07-13**|**Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations**|Guiguang Ding Team|[2507.09500](http://arxiv.org/abs/2507.09500)|null|
|**2025-07-13**|**GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them?**|Huaxiu Yao Team|[2507.09491](http://arxiv.org/abs/2507.09491)|null|
|**2025-07-12**|**Uncertainty-Driven Expert Control: Enhancing the Reliability of Medical Vision-Language Models**|Tat-Seng Chua Team|[2507.09209](http://arxiv.org/abs/2507.09209)|null|
|**2025-07-12**|**MCA-LLaVA: Manhattan Causal Attention for Reducing Hallucination in Large Vision-Language Models**|Dahan Wang Team|[2507.09184](http://arxiv.org/abs/2507.09184)|null|
|**2025-07-12**|**OPENXRD: A Comprehensive Benchmark and Enhancement Framework for LLM/MLLM XRD Question Answering**|Niaz Abdolrahim Team|[2507.09155](http://arxiv.org/abs/2507.09155)|null|
|**2025-07-12**|**RadEyeVideo: Enhancing general-domain Large Vision Language Model for chest X-ray analysis with video representations of eye gaze**|Honghan Wu Team|[2507.09097](http://arxiv.org/abs/2507.09097)|null|
|**2025-07-11**|**BlindSight: Harnessing Sparsity for Efficient VLMs**|Steven K. Reinhardt Team|[2507.09071](http://arxiv.org/abs/2507.09071)|null|
|**2025-07-11**|**Beyond vividness: Content analysis of induced hallucinations reveals the hidden structure of individual differences in visual imagery**|Seana Coulson Team|[2507.09011](http://arxiv.org/abs/2507.09011)|null|
|**2025-07-11**|**VIP: Visual Information Protection through Adversarial Attacks on Vision-Language Models**|Olivier Déforges Team|[2507.08982](http://arxiv.org/abs/2507.08982)|null|
|**2025-07-11**|**ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way**|Subarna Tripathi Team|[2507.08679](http://arxiv.org/abs/2507.08679)|null|
|**2025-07-11**|**Adaptive Framework for Ambient Intelligence in Rehabilitation Assistance**|András Lőrincz Team|[2507.08624](http://arxiv.org/abs/2507.08624)|null|
|**2025-07-11**|**Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data**|Ambedkar Dukkipati Team|[2507.08610](http://arxiv.org/abs/2507.08610)|null|
|**2025-07-11**|**BayesTTA: Continual-Temporal Test-Time Adaptation for Vision-Language Models via Gaussian Discriminant Analysis**|Hui Xiong Team|[2507.08607](http://arxiv.org/abs/2507.08607)|null|
|**2025-07-11**|**Efficient Deployment of Vision-Language Models on Mobile Devices: A Case Study on OnePlus 13R**|Sanidhya Kashyap Team|[2507.08505](http://arxiv.org/abs/2507.08505)|null|
|**2025-07-11**|**LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning**|Lei Fan Team|[2507.08496](http://arxiv.org/abs/2507.08496)|null|
|**2025-07-11**|**Multi-modal Mutual-Guidance Conditional Prompt Learning for Vision-Language Models**|Jianping Fan Team|[2507.08410](http://arxiv.org/abs/2507.08410)|null|
|**2025-07-11**|**Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level Procedural Reasoning**|Yejin Choi Team|[2507.08224](http://arxiv.org/abs/2507.08224)|null|
|**2025-07-10**|**CLIP Won't Learn Object-Attribute Binding from Natural Data and Here is Why**|Thomas Brox Team|[2507.07985](http://arxiv.org/abs/2507.07985)|null|
|**2025-07-10**|**Scaling RL to Long Videos**|Song Han Team|[2507.07966](http://arxiv.org/abs/2507.07966)|null|
|**2025-07-10**|**SAGE: A Visual Language Model for Anomaly Detection via Fact Enhancement and Entropy-aware Alignment**|Lei Fan Team|[2507.07939](http://arxiv.org/abs/2507.07939)|null|
|**2025-07-10**|**MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving**|Chao Zhang Team|[2507.07818](http://arxiv.org/abs/2507.07818)|null|
|**2025-07-10**|**Energy-Guided Decoding for Object Hallucination Mitigation**|Christopher Zach Team|[2507.07731](http://arxiv.org/abs/2507.07731)|null|
|**2025-07-10**|**One Object, Multiple Lies: A Benchmark for Cross-task Adversarial Attack on Unified Vision-Language Models**|Cairong Zhao Team|[2507.07709](http://arxiv.org/abs/2507.07709)|null|
|**2025-07-10**|**Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought**|Daiki Chijiwa Team|[2507.07685](http://arxiv.org/abs/2507.07685)|null|
|**2025-07-11**|**ViLU: Learning Vision-Language Uncertainties for Failure Prediction**|Nicolas Thome Team|[2507.07620](http://arxiv.org/abs/2507.07620)|null|
|**2025-07-10**|**LOSC: LiDAR Open-voc Segmentation Consolidator**|Renaud Marlet Team|[2507.07605](http://arxiv.org/abs/2507.07605)|null|
|**2025-07-10**|**The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs**|Qun Liu Team|[2507.07562](http://arxiv.org/abs/2507.07562)|null|
|**2025-07-10**|**ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing**|Markus Huff Team|[2507.07551](http://arxiv.org/abs/2507.07551)|null|
|**2025-07-11**|**Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning**|David Martins de Matos Team|[2507.07340](http://arxiv.org/abs/2507.07340)|null|
|**2025-07-09**|**ADIEE: Automatic Dataset Creation and Scorer for Instruction-Guided Image Editing Evaluation**|Suren Kumar Team|[2507.07317](http://arxiv.org/abs/2507.07317)|null|
|**2025-07-09**|**LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation**|Angel X. Chang Team|[2507.07299](http://arxiv.org/abs/2507.07299)|null|
|**2025-07-09**|**MagiC: Evaluating Multimodal Cognition Toward Grounded Visual Reasoning**|Dan Goldwasser Team|[2507.07297](http://arxiv.org/abs/2507.07297)|null|
|**2025-07-09**|**4KAgent: Agentic Any Image to 4K Super-Resolution**|Zhengzhong Tu Team|[2507.07105](http://arxiv.org/abs/2507.07105)|null|
|**2025-07-11**|**Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models**|Junfei Xiao Team|[2507.07104](http://arxiv.org/abs/2507.07104)|null|
|**2025-07-09**|**Evaluating Attribute Confusion in Fashion Text-to-Image Generation**|Davide Talon Team|[2507.07079](http://arxiv.org/abs/2507.07079)|null|
|**2025-07-09**|**Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM**|Sibei Yang Team|[2507.06973](http://arxiv.org/abs/2507.06973)|null|
|**2025-07-09**|**CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale**|Quan Wang Team|[2507.06959](http://arxiv.org/abs/2507.06959)|null|
|**2025-07-09**|**VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation**|Tat-Seng Chua Team|[2507.06899](http://arxiv.org/abs/2507.06899)|null|
|**2025-07-09**|**HVI-CIDNet+: Beyond Extreme Darkness for Low-Light Image Enhancement**|Yanning Zhang Team|[2507.06814](http://arxiv.org/abs/2507.06814)|null|
|**2025-07-09**|**Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu**|Donghyeok Choi Team|[2507.06761](http://arxiv.org/abs/2507.06761)|null|
|**2025-07-09**|**Text-promptable Object Counting via Quantity Awareness Enhancement**|Li Li Team|[2507.06679](http://arxiv.org/abs/2507.06679)|null|
|**2025-07-09**|**Cross-Modal Dual-Causal Learning for Long-Term Action Recognition**|Fan Chao Team|[2507.06603](http://arxiv.org/abs/2507.06603)|null|
|**2025-07-09**|**Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection**|Xiangmin Xu Team|[2507.06510](http://arxiv.org/abs/2507.06510)|null|
|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Nick Haber Team|[2507.06484](http://arxiv.org/abs/2507.06484)|null|
|**2025-07-08**|**VisioPath: Vision-Language Enhanced Model Predictive Control for Safe Autonomous Navigation in Mixed Traffic**|Andreas A. Malikopoulos Team|[2507.06441](http://arxiv.org/abs/2507.06441)|null|
|**2025-07-08**|**CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions**|Yi R. Fung Team|[2507.06210](http://arxiv.org/abs/2507.06210)|null|
|**2025-07-08**|**Enhancing Scientific Visual Question Answering through Multimodal Reasoning and Ensemble Modeling**|Naga Harshita Marupaka Team|[2507.06183](http://arxiv.org/abs/2507.06183)|null|
|**2025-07-10**|**Skywork-R1V3 Technical Report**|Yahui Zhou Team|[2507.06167](http://arxiv.org/abs/2507.06167)|null|
|**2025-07-08**|**LangMamba: A Language-driven Mamba Framework for Low-dose CT Denoising with Vision-language Models**|Hongming Shan Team|[2507.06140](http://arxiv.org/abs/2507.06140)|null|
|**2025-07-08**|**GeoMag: A Vision-Language Model for Pixel-level Fine-Grained Remote Sensing Image Parsing**|Hao Liu Team|[2507.05887](http://arxiv.org/abs/2507.05887)|null|
|**2025-07-08**|**Bridging Perception and Language: A Systematic Benchmark for LVLMs' Understanding of Amodal Completion Reports**|Hitomi Yanaka Team|[2507.05799](http://arxiv.org/abs/2507.05799)|null|
|**2025-07-08**|**SPADE: Spatial-Aware Denoising Network for Open-vocabulary Panoptic Scene Graph Generation with Long- and Local-range Context Reasoning**|Tao He Team|[2507.05798](http://arxiv.org/abs/2507.05798)|null|
|**2025-07-08**|**A Satellite-Ground Synergistic Large Vision-Language Model System for Earth Observation**|Yue Gao Team|[2507.05731](http://arxiv.org/abs/2507.05731)|null|
|**2025-07-09**|**Integrated Structural Prompt Learning for Vision-Language Models**|Bin Luo Team|[2507.05677](http://arxiv.org/abs/2507.05677)|null|
|**2025-07-08**|**R-VLM: Region-Aware Vision Language Model for Precise GUI Grounding**|Shabnam Ghadar Team|[2507.05673](http://arxiv.org/abs/2507.05673)|null|
|**2025-07-08**|**Dynamic Rank Adaptation for Vision-Language Models**|Bin Luo Team|[2507.05668](http://arxiv.org/abs/2507.05668)|null|
|**2025-07-08**|**Structured Task Solving via Modular Embodied Intelligence: A Case Study on Rubik's Cube**|Shenghai Yuan Team|[2507.05607](http://arxiv.org/abs/2507.05607)|null|
|**2025-07-08**|**Rethinking Layered Graphic Design Generation with a Top-Down Approach**|Qifeng Chen Team|[2507.05601](http://arxiv.org/abs/2507.05601)|null|
|**2025-07-08**|**PaddleOCR 3.0 Technical Report**|Yanjun Ma Team|[2507.05595](http://arxiv.org/abs/2507.05595)|null|
|**2025-07-07**|**Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality**|Junxiao Wang Team|[2507.05515](http://arxiv.org/abs/2507.05515)|null|
|**2025-07-07**|**Llama Nemoretriever Colembed: Top-Performing Text-Image Retrieval Model**|Even Oldridge Team|[2507.05513](http://arxiv.org/abs/2507.05513)|null|
|**2025-07-07**|**OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts**|Priyadarshini Panda Team|[2507.05427](http://arxiv.org/abs/2507.05427)|null|
|**2025-07-07**|**pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models**|Ramtin Pedarsani Team|[2507.05394](http://arxiv.org/abs/2507.05394)|null|
|**2025-07-07**|**NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving**|Cheng Lu Team|[2507.05227](http://arxiv.org/abs/2507.05227)|null|
|**2025-07-07**|**All in One: Visual-Description-Guided Unified Point Cloud Segmentation**|Rao Muhammad Anwer Team|[2507.05211](http://arxiv.org/abs/2507.05211)|null|

<p align=right>(<a href=#updated-on-20251019>back to top</a>)</p>

