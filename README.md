## Updated on 2025.07.16
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#vla>VLA</a></li>
    <li><a href=#long-horizon-planning>Long-horizon Planning</a></li>
    <li><a href=#open-vocabulary-robotics>Open Vocabulary Robotics</a></li>
    <li><a href=#robot-reasoning>Robot Reasoning</a></li>
    <li><a href=#subtask-decomposition>Subtask Decomposition</a></li>
    <li><a href=#robot-memory>Robot Memory</a></li>
    <li><a href=#temporal-understanding>Temporal Understanding</a></li>
    <li><a href=#robot-datasets>Robot Datasets</a></li>
    <li><a href=#multi-task-learning>Multi-task Learning</a></li>
    <li><a href=#robot-foundation-models>Robot Foundation Models</a></li>
    <li><a href=#vision-language-models>Vision Language Models</a></li>
  </ol>
</details>

## VLA

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-14**|**ViTCoT: Video-Text Interleaved Chain-of-Thought for Boosting Video Understanding in Large Language Models**|Libo Qin Team|[2507.09876](http://arxiv.org/abs/2507.09876)|null|
|**2025-07-12**|**Online Long-term Point Tracking in the Foundation Model Era**|GÃ¶rkay Aydemir Team|[2507.09217](http://arxiv.org/abs/2507.09217)|null|
|**2025-07-12**|**Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization**|Yang Gao Team|[2507.09160](http://arxiv.org/abs/2507.09160)|null|
|**2025-07-15**|**View Invariant Learning for Vision-Language Navigation in Continuous Environments**|Mark Crowley Team|[2507.08831](http://arxiv.org/abs/2507.08831)|null|
|**2025-07-11**|**LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning**|Lei Fan Team|[2507.08496](http://arxiv.org/abs/2507.08496)|null|
|**2025-07-10**|**SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes**|Mingming Gong Team|[2507.07781](http://arxiv.org/abs/2507.07781)|null|
|**2025-07-09**|**A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding**|Yanwei Fu Team|[2507.06719](http://arxiv.org/abs/2507.06719)|null|
|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Nick Haber Team|[2507.06484](http://arxiv.org/abs/2507.06484)|null|
|**2025-07-08**|**DreamArt: Generating Interactable Articulated Objects from a Single Image**|Siyuan Huang Team|[2507.05763](http://arxiv.org/abs/2507.05763)|null|
|**2025-07-08**|**PAPRLE (Plug-And-Play Robotic Limb Environment): A Modular Ecosystem for Robotic Limbs**|Joohyung Kim Team|[2507.05555](http://arxiv.org/abs/2507.05555)|null|
|**2025-07-07**|**NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving**|Cheng Lu Team|[2507.05227](http://arxiv.org/abs/2507.05227)|null|
|**2025-07-07**|**EmbodieDreamer: Advancing Real2Sim2Real Transfer for Policy Training via Embodied World Modeling**|Xingang Wang Team|[2507.05198](http://arxiv.org/abs/2507.05198)|null|
|**2025-07-10**|**VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting**|Yanzhi Wang Team|[2507.05116](http://arxiv.org/abs/2507.05116)|null|
|**2025-07-07**|**Training-free Generation of Temporally Consistent Rewards from VLMs**|Jian Tang Team|[2507.04789](http://arxiv.org/abs/2507.04789)|null|
|**2025-07-06**|**SimLauncher: Launching Sample-Efficient Real-world Robotic Reinforcement Learning via Simulation Pre-training**|Hao Dong Team|[2507.04452](http://arxiv.org/abs/2507.04452)|null|
|**2025-07-06**|**DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge**|Xin Jin Team|[2507.04447](http://arxiv.org/abs/2507.04447)|null|
|**2025-07-06**|**Hijacking JARVIS: Benchmarking Mobile GUI Agents against Unprivileged Third Parties**|Yunxin Liu Team|[2507.04227](http://arxiv.org/abs/2507.04227)|null|
|**2025-07-05**|**Move to Understand a 3D Scene: Bridging Visual Grounding and Exploration for Efficient and Versatile Embodied Navigation**|Qing Li Team|[2507.04047](http://arxiv.org/abs/2507.04047)|null|
|**2025-07-03**|**DexVLG: Dexterous Vision-Language-Grasp Model at Scale**|He Wang Team|[2507.02747](http://arxiv.org/abs/2507.02747)|null|
|**2025-07-02**|**cVLA: Towards Efficient Camera-Space VLAs**|Thomas Brox Team|[2507.02190](http://arxiv.org/abs/2507.02190)|null|
|**2025-07-05**|**RoboBrain 2.0 Technical Report**|Shanghang Zhang Team|[2507.02029](http://arxiv.org/abs/2507.02029)|null|
|**2025-07-02**|**A Survey on Vision-Language-Action Models: An Action Tokenization Perspective**|Yaodong Yang Team|[2507.01925](http://arxiv.org/abs/2507.01925)|null|
|**2025-07-02**|**MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics**|Nadiya Shvai Team|[2507.01843](http://arxiv.org/abs/2507.01843)|null|
|**2025-07-02**|**What does really matter in image goal navigation?**|Christian Wolf Team|[2507.01667](http://arxiv.org/abs/2507.01667)|null|
|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Yanwei Fu Team|[2507.01424](http://arxiv.org/abs/2507.01424)|null|
|**2025-07-01**|**VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers**|Tong He Team|[2507.01016](http://arxiv.org/abs/2507.01016)|null|
|**2025-07-01**|**A Survey: Learning Embodied Intelligence from Physical Simulators and World Models**|Qionghai Dai Team|[2507.00917](http://arxiv.org/abs/2507.00917)|null|
|**2025-07-01**|**Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding**|Bo Zhao Team|[2507.00416](http://arxiv.org/abs/2507.00416)|null|

<p align=right>(<a href=#updated-on-20250716>back to top</a>)</p>

## Long-horizon Planning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-10**|**Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning**|Xun Huan Team|[2507.07359](http://arxiv.org/abs/2507.07359)|null|
|**2025-07-09**|**LOVON: Legged Open-Vocabulary Object Navigator**|Jun Ma Team|[2507.06747](http://arxiv.org/abs/2507.06747)|null|
|**2025-07-10**|**GTA1: GUI Test-time Scaling Agent**|Junnan Li Team|[2507.05791](http://arxiv.org/abs/2507.05791)|null|
|**2025-07-08**|**Structured Task Solving via Modular Embodied Intelligence: A Case Study on Rubik's Cube**|Shenghai Yuan Team|[2507.05607](http://arxiv.org/abs/2507.05607)|null|
|**2025-07-07**|**LERa: Replanning with Visual Feedback in Instruction Following**|Aleksandr I. Panov Team|[2507.05135](http://arxiv.org/abs/2507.05135)|null|
|**2025-07-07**|**VerifyLLM: LLM-Based Pre-Execution Task Plan Verification for Robots**|Aleksandr I. Panov Team|[2507.05118](http://arxiv.org/abs/2507.05118)|null|
|**2025-07-06**|**"Hi AirStar, Guide Me to the Badminton Court."**|Si Liu Team|[2507.04430](http://arxiv.org/abs/2507.04430)|null|
|**2025-07-04**|**CodeAgents: A Token-Efficient Framework for Codified Multi-Agent Reasoning in LLMs**|David Hsu Team|[2507.03254](http://arxiv.org/abs/2507.03254)|null|
|**2025-07-02**|**VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process**|Alexander Carballo Team|[2507.01284](http://arxiv.org/abs/2507.01284)|null|
|**2025-06-29**|**Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning**|Xipeng Qiu Team|[2506.23127](http://arxiv.org/abs/2506.23127)|null|
|**2025-06-29**|**TOMI: Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure**|Ziyu Wang Team|[2506.23094](http://arxiv.org/abs/2506.23094)|null|
|**2025-07-10**|**Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation**|Navid Azizan Team|[2506.22827](http://arxiv.org/abs/2506.22827)|null|
|**2025-06-24**|**FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models**|Huiping Zhuang Team|[2506.21627](http://arxiv.org/abs/2506.21627)|null|
|**2025-06-26**|**MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification**|Abduz Zami Team|[2506.21199](http://arxiv.org/abs/2506.21199)|null|
|**2025-06-26**|**STEP Planner: Constructing cross-hierarchical subgoal tree as an embodied long-horizon task planner**|Yue Yufeng Team|[2506.21030](http://arxiv.org/abs/2506.21030)|null|
|**2025-06-25**|**SPARK: Graph-Based Online Semantic Integration System for Robot Task Planning**|Yusuke Iwasawa Team|[2506.20394](http://arxiv.org/abs/2506.20394)|null|
|**2025-06-30**|**Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning**|Tamim Asfour Team|[2506.19592](http://arxiv.org/abs/2506.19592)|null|
|**2025-06-23**|**Safety-Aware Optimal Scheduling for Autonomous Masonry Construction using Collaborative Heterogeneous Aerial Robots**|George Nikolakopoulos Team|[2506.18697](http://arxiv.org/abs/2506.18697)|null|
|**2025-06-21**|**CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning**|Xiaoling Wang Team|[2506.17629](http://arxiv.org/abs/2506.17629)|null|
|**2025-06-21**|**VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models**|Lin Shao Team|[2506.17561](http://arxiv.org/abs/2506.17561)|null|
|**2025-06-20**|**Towards AI Search Paradigm**|Dawei Yin Team|[2506.17188](http://arxiv.org/abs/2506.17188)|null|
|**2025-06-20**|**Multimodal Fused Learning for Solving the Generalized Traveling Salesman Problem in Robotic Task Planning**|Guillaume Adrien Sartoretti Team|[2506.16931](http://arxiv.org/abs/2506.16931)|null|

<p align=right>(<a href=#updated-on-20250716>back to top</a>)</p>

## Open Vocabulary Robotics

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-14**|**OpenHuman4D: Open-Vocabulary 4D Human Parsing**|Truong Nguyen Team|[2507.09880](http://arxiv.org/abs/2507.09880)|null|
|**2025-07-11**|**VISTA: A Visual Analytics Framework to Enhance Foundation Model-Generated Data Labels**|Liu Ren Team|[2507.09008](http://arxiv.org/abs/2507.09008)|null|
|**2025-07-08**|**OTAS: Open-vocabulary Token Alignment for Outdoor Segmentation**|Gerald Steinbauer-Wagner Team|[2507.08851](http://arxiv.org/abs/2507.08851)|null|
|**2025-07-10**|**LOSC: LiDAR Open-voc Segmentation Consolidator**|Renaud Marlet Team|[2507.07605](http://arxiv.org/abs/2507.07605)|null|
|**2025-07-09**|**LangSplatV2: High-dimensional 3D Language Gaussian Splatting with 450+ FPS**|Hanspeter Pfister Team|[2507.07136](http://arxiv.org/abs/2507.07136)|null|
|**2025-07-09**|**LOVON: Legged Open-Vocabulary Object Navigator**|Jun Ma Team|[2507.06747](http://arxiv.org/abs/2507.06747)|null|
|**2025-07-09**|**A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding**|Yanwei Fu Team|[2507.06719](http://arxiv.org/abs/2507.06719)|null|
|**2025-07-09**|**Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection**|Xiangmin Xu Team|[2507.06510](http://arxiv.org/abs/2507.06510)|null|
|**2025-07-08**|**SPADE: Spatial-Aware Denoising Network for Open-vocabulary Panoptic Scene Graph Generation with Long- and Local-range Context Reasoning**|Tao He Team|[2507.05798](http://arxiv.org/abs/2507.05798)|null|
|**2025-07-07**|**OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts**|Priyadarshini Panda Team|[2507.05427](http://arxiv.org/abs/2507.05427)|null|
|**2025-07-04**|**Leveraging Out-of-Distribution Unlabeled Images: Semi-Supervised Semantic Segmentation with an Open-Vocabulary Model**|Sung Won Han Team|[2507.03302](http://arxiv.org/abs/2507.03302)|null|
|**2025-07-03**|**LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion**|Yueqi Duan Team|[2507.02813](http://arxiv.org/abs/2507.02813)|null|
|**2025-07-01**|**VISTA: Open-Vocabulary, Task-Relevant Robot Exploration with Online Semantic Gaussian Splatting**|Mac Schwager Team|[2507.01125](http://arxiv.org/abs/2507.01125)|null|
|**2025-06-30**|**Diffusion-Based Image Augmentation for Semantic Segmentation in Outdoor Robotics**|Mirko Maehlisch Team|[2507.00153](http://arxiv.org/abs/2507.00153)|null|
|**2025-06-30**|**Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?**|Matthias Rottmann Team|[2506.23751](http://arxiv.org/abs/2506.23751)|null|
|**2025-06-30**|**PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum**|Yanyong Zhang Team|[2506.23607](http://arxiv.org/abs/2506.23607)|null|
|**2025-07-15**|**FA-Seg: A Fast and Accurate Diffusion-Based Method for Open-Vocabulary Segmentation**|Vinh-Tiep Nguyen Team|[2506.23323](http://arxiv.org/abs/2506.23323)|null|
|**2025-06-28**|**Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding**|Nannan Wang Team|[2506.22817](http://arxiv.org/abs/2506.22817)|null|
|**2025-06-28**|**VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding**|Liang Zhang Team|[2506.22799](http://arxiv.org/abs/2506.22799)|null|
|**2025-06-27**|**Embodied Domain Adaptation for Object Detection**|Feras Dayoub Team|[2506.21860](http://arxiv.org/abs/2506.21860)|null|
|**2025-06-27**|**ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation**|Kwan-Liu Ma Team|[2506.21233](http://arxiv.org/abs/2506.21233)|null|
|**2025-06-27**|**Shape2Animal: Creative Animal Generation from Natural Silhouettes**|Trung-Nghia Le Team|[2506.20616](http://arxiv.org/abs/2506.20616)|null|
|**2025-06-25**|**Video Perception Models for 3D Scene Synthesis**|Francis Engelmann Team|[2506.20601](http://arxiv.org/abs/2506.20601)|null|
|**2025-06-24**|**Segment Any 3D-Part in a Scene from a Sentence**|Cees G. M. Snoek Team|[2506.19331](http://arxiv.org/abs/2506.19331)|null|
|**2025-06-24**|**Open-Vocabulary Camouflaged Object Segmentation with Cascaded Vision Language Models**|Dan Zeng Team|[2506.19300](http://arxiv.org/abs/2506.19300)|null|
|**2025-06-24**|**OpenWildlife: Open-Vocabulary Multi-Species Wildlife Detector for Geographically-Diverse Aerial Imagery**|David Clausi Team|[2506.19204](http://arxiv.org/abs/2506.19204)|null|
|**2025-06-23**|**Context Biasing for Pronunciations-Orthography Mismatch in Automatic Speech Recognition**|Alexander Waibel Team|[2506.18703](http://arxiv.org/abs/2506.18703)|null|
|**2025-06-21**|**DRAMA-X: A Fine-grained Intent Prediction and Risk Reasoning Benchmark For Driving**|Zhengzhong Tu Team|[2506.17590](http://arxiv.org/abs/2506.17590)|null|

<p align=right>(<a href=#updated-on-20250716>back to top</a>)</p>

## Robot Reasoning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-14**|**EmbRACE-3K: Embodied Reasoning and Action in Complex Environments**|Xiaojuan Qi Team|[2507.10548](http://arxiv.org/abs/2507.10548)|null|
|**2025-07-14**|**T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs**|Guillaume Rabusseau Team|[2507.10183](http://arxiv.org/abs/2507.10183)|null|
|**2025-07-13**|**GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them?**|Huaxiu Yao Team|[2507.09491](http://arxiv.org/abs/2507.09491)|null|
|**2025-07-12**|**Online Long-term Point Tracking in the Foundation Model Era**|GÃ¶rkay Aydemir Team|[2507.09217](http://arxiv.org/abs/2507.09217)|null|
|**2025-07-11**|**ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way**|Subarna Tripathi Team|[2507.08679](http://arxiv.org/abs/2507.08679)|null|
|**2025-07-11**|**M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning**|Ziping Ma Team|[2507.08306](http://arxiv.org/abs/2507.08306)|null|
|**2025-07-11**|**InsightBuild: LLM-Powered Causal Reasoning in Smart Building Systems**|Rajiv Ramnath Team|[2507.08235](http://arxiv.org/abs/2507.08235)|null|
|**2025-07-10**|**OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding**|Jiangmiao Pang Team|[2507.07984](http://arxiv.org/abs/2507.07984)|null|
|**2025-07-10**|**Scaling RL to Long Videos**|Song Han Team|[2507.07966](http://arxiv.org/abs/2507.07966)|null|
|**2025-07-10**|**SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes**|Mingming Gong Team|[2507.07781](http://arxiv.org/abs/2507.07781)|null|
|**2025-07-10**|**PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations**|Peter Wonka Team|[2507.07644](http://arxiv.org/abs/2507.07644)|null|
|**2025-07-10**|**Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning**|Xun Huan Team|[2507.07359](http://arxiv.org/abs/2507.07359)|null|
|**2025-07-09**|**Probability-Raising Causality for Uncertain Parametric Markov Decision Processes with PAC Guarantees**|yuji Ito Team|[2507.07319](http://arxiv.org/abs/2507.07319)|null|
|**2025-07-09**|**Temporal Information Retrieval via Time-Specifier Model Merging**|Jong C. Park Team|[2507.06782](http://arxiv.org/abs/2507.06782)|null|
|**2025-07-09**|**A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding**|Yanwei Fu Team|[2507.06719](http://arxiv.org/abs/2507.06719)|null|
|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Nick Haber Team|[2507.06484](http://arxiv.org/abs/2507.06484)|null|
|**2025-07-08**|**Video Event Reasoning and Prediction by Fusing World Knowledge from LLMs with Vision Foundation Models**|Santiago Munoz Team|[2507.05822](http://arxiv.org/abs/2507.05822)|null|
|**2025-07-07**|**CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale**|Boyuan Chen Team|[2507.05178](http://arxiv.org/abs/2507.05178)|null|
|**2025-07-07**|**HV-MMBench: Benchmarking MLLMs for Human-Centric Video Understanding**|Xiang Bai Team|[2507.04909](http://arxiv.org/abs/2507.04909)|null|
|**2025-07-07**|**Tempo-R0: A Video-MLLM for Temporal Video Grounding through Efficient Temporal Sensing Reinforcement Learning**|Rong Shen Team|[2507.04702](http://arxiv.org/abs/2507.04702)|null|
|**2025-07-07**|**Learn 3D VQA Better with Active Selection and Reannotation**|Feng Zheng Team|[2507.04630](http://arxiv.org/abs/2507.04630)|null|
|**2025-07-05**|**Pedestrian Intention Prediction via Vision-Language Foundation Models**|He Wang Team|[2507.04141](http://arxiv.org/abs/2507.04141)|null|
|**2025-07-09**|**Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models**|Changliang Xu Team|[2507.03916](http://arxiv.org/abs/2507.03916)|null|
|**2025-07-04**|**Causal-SAM-LLM: Large Language Models as Causal Reasoners for Robust Medical Segmentation**|Zhixiang Lu Team|[2507.03585](http://arxiv.org/abs/2507.03585)|null|
|**2025-07-01**|**Ascending the Infinite Ladder: Benchmarking Spatial Deformation Reasoning in Vision-Language Models**|Kaicheng Yu Team|[2507.02978](http://arxiv.org/abs/2507.02978)|null|
|**2025-07-02**|**Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain**|Verena KlÃ¶s Team|[2507.02016](http://arxiv.org/abs/2507.02016)|null|
|**2025-07-08**|**Future Slot Prediction for Unsupervised Object Discovery in Surgical Video**|Daniel A. Hashimoto Team|[2507.01882](http://arxiv.org/abs/2507.01882)|null|
|**2025-07-02**|**HCNQA: Enhancing 3D VQA with Hierarchical Concentration Narrowing Supervision**|Feng Zheng Team|[2507.01800](http://arxiv.org/abs/2507.01800)|null|
|**2025-07-02**|**VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process**|Alexander Carballo Team|[2507.01284](http://arxiv.org/abs/2507.01284)|null|
|**2025-07-02**|**Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care**|Charles B Malpas Team|[2507.01282](http://arxiv.org/abs/2507.01282)|null|
|**2025-07-01**|**CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs**|Wei Yang Bryan Lim Team|[2507.00817](http://arxiv.org/abs/2507.00817)|null|
|**2025-07-01**|**Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving**|Yadan Luo Team|[2507.00525](http://arxiv.org/abs/2507.00525)|null|
|**2025-06-29**|**GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields**|Yutaka Matsuo Team|[2506.23352](http://arxiv.org/abs/2506.23352)|null|
|**2025-06-29**|**UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding**|Yong Li Team|[2506.23219](http://arxiv.org/abs/2506.23219)|null|
|**2025-06-29**|**Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation**|Li Jiang Team|[2506.23120](http://arxiv.org/abs/2506.23120)|null|
|**2025-06-28**|**MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning**|Michael Moor Team|[2506.22992](http://arxiv.org/abs/2506.22992)|null|

<p align=right>(<a href=#updated-on-20250716>back to top</a>)</p>

## Subtask Decomposition

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-13**|**GoalfyMax: A Protocol-Driven Multi-Agent System for Intelligent Experience Entities**|Tianyu Shi Team|[2507.09497](http://arxiv.org/abs/2507.09497)|null|
|**2025-07-10**|**Collaborative Human-Robot Surgery for Mandibular Angle Split Osteotomy: Optical Tracking based Approach**|Xingguang Duan Team|[2507.07794](http://arxiv.org/abs/2507.07794)|null|
|**2025-07-10**|**PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving**|Tomas Pfister Team|[2507.07495](http://arxiv.org/abs/2507.07495)|null|
|**2025-06-26**|**ViStruct: Simulating Expert-Like Reasoning Through Task Decomposition and Visual Attention Cues**|Carolina Nobre Team|[2506.21762](http://arxiv.org/abs/2506.21762)|null|
|**2025-06-26**|**Hierarchical Reasoning Model**|Yasin Abbasi Yadkori Team|[2506.21734](http://arxiv.org/abs/2506.21734)|null|
|**2025-06-20**|**Automatic Large Language Models Creation of Interactive Learning Lessons**|Kenneth R. Koedinger Team|[2506.17356](http://arxiv.org/abs/2506.17356)|null|
|**2025-06-20**|**Chain-of-Trust: A Progressive Trust Evaluation Framework Enabled by Generative AI**|Shen Team|[2506.17130](http://arxiv.org/abs/2506.17130)|null|
|**2025-06-18**|**DeckFlow: Iterative Specification on a Multimodal Generative Canvas**|Cyrus Omar Team|[2506.15873](http://arxiv.org/abs/2506.15873)|null|
|**2025-06-16**|**A Comprehensive Survey on Deep Learning Solutions for 3D Flood Mapping**|Lihong Zheng Team|[2506.13201](http://arxiv.org/abs/2506.13201)|null|
|**2025-06-13**|**Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation**|Beidi Chen Team|[2506.09991](http://arxiv.org/abs/2506.09991)|null|
|**2025-06-11**|**Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis**|Michael Tin-Cheung Ying Team|[2506.08849](http://arxiv.org/abs/2506.08849)|**[link](https://github.com/jinggqu/nextgen-uia)**|
|**2025-06-09**|**SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition**|Wenliang Chen Team|[2506.07557](http://arxiv.org/abs/2506.07557)|null|
|**2025-06-06**|**Hierarchical Debate-Based Large Language Model (LLM) for Complex Task Planning of 6G Network Management**|Zhang Team|[2506.06519](http://arxiv.org/abs/2506.06519)|null|
|**2025-06-06**|**Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router**|Yong Li Team|[2506.05901](http://arxiv.org/abs/2506.05901)|null|
|**2025-06-09**|**Zero-Shot Event Causality Identification via Multi-source Evidence Fuzzy Aggregation with Large Language Models**|Zhong Liu Team|[2506.05675](http://arxiv.org/abs/2506.05675)|null|
|**2025-06-05**|**Attack Effect Model based Malicious Behavior Detection**|Kai Ye Team|[2506.05001](http://arxiv.org/abs/2506.05001)|null|
|**2025-06-04**|**Comparative Analysis of AI Agent Architectures for Entity Relationship Classification**|Amin Sehati Team|[2506.02426](http://arxiv.org/abs/2506.02426)|**[link](https://github.com/maryambrj/alien)**|
|**2025-06-02**|**COALESCE: Economic and Security Dynamics of Skill-Based Task Outsourcing Among Team of Autonomous LLM Agents**|Idan Habler Team|[2506.01900](http://arxiv.org/abs/2506.01900)|null|
|**2025-05-30**|**Reasoning Can Hurt the Inductive Abilities of Large Language Models**|Haohan Wang Team|[2505.24225](http://arxiv.org/abs/2505.24225)|null|
|**2025-06-11**|**OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation**|Guohao Li Team|[2505.23885](http://arxiv.org/abs/2505.23885)|**[link](https://github.com/camel-ai/owl)**|
|**2025-05-29**|**EL4NER: Ensemble Learning for Named Entity Recognition via Multiple Small-Parameter Large Language Models**|Junfeng Zhao Team|[2505.23038](http://arxiv.org/abs/2505.23038)|null|
|**2025-05-28**|**Learning Composable Chains-of-Thought**|Greg Durrett Team|[2505.22635](http://arxiv.org/abs/2505.22635)|null|
|**2025-05-28**|**AudioGenie: A Training-Free Multi-Agent Framework for Diverse Multimodality-to-Multiaudio Generation**|Li Liu Team|[2505.22053](http://arxiv.org/abs/2505.22053)|null|

<p align=right>(<a href=#updated-on-20250716>back to top</a>)</p>

## Robot Memory

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-10**|**Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving**|Wangchunshu Zhou Team|[2507.06229](http://arxiv.org/abs/2507.06229)|null|
|**2025-07-08**|**Unconditional Diffusion for Generative Sequential Recommendation**|Tat-Seng Chua Team|[2507.06121](http://arxiv.org/abs/2507.06121)|null|
|**2025-07-07**|**Heterogeneous Causal Learning for Optimizing Aggregated Functions in User Growth**|Will Y. Zou Team|[2507.05510](http://arxiv.org/abs/2507.05510)|null|
|**2025-07-07**|**Dynamical Archetype Analysis: Autonomous Computation**|Il Memming Park Team|[2507.05505](http://arxiv.org/abs/2507.05505)|null|
|**2025-07-07**|**Transcribing Spanish Texts from the Past: Experiments with Transkribus, Tesseract and Granite**|Ana GarcÃ­a-Serrano Team|[2507.04878](http://arxiv.org/abs/2507.04878)|null|
|**2025-07-14**|**PRIME: Large Language Model Personalization with Cognitive Memory and Thought Processes**|Lu Wang Team|[2507.04607](http://arxiv.org/abs/2507.04607)|null|
|**2025-07-06**|**Entropy measures as indicators of connectivity paths in the human brain**|Holger Kantz Team|[2507.04442](http://arxiv.org/abs/2507.04442)|null|
|**2025-07-04**|**Less is More: Empowering GUI Agent with Context-Aware Simplification**|Liqiang Nie Team|[2507.03730](http://arxiv.org/abs/2507.03730)|null|
|**2025-06-25**|**Echo State Transformer: When chaos brings memory**|Xavier Hinaut Team|[2507.02917](http://arxiv.org/abs/2507.02917)|null|
|**2025-07-03**|**A learning model predictive control for virtual coupling in railroads**|Jesus Felez Team|[2507.02383](http://arxiv.org/abs/2507.02383)|null|
|**2025-07-02**|**REMI: Reconstructing Episodic Memory During Intrinsic Path Planning**|Vijay Balasubramanian Team|[2507.02064](http://arxiv.org/abs/2507.02064)|null|
|**2025-07-02**|**Characterizing control between interacting subsystems with deep Jacobian estimation**|Ila R. Fiete Team|[2507.01946](http://arxiv.org/abs/2507.01946)|null|
|**2025-06-23**|**Catastrophic Forgetting Mitigation via Discrepancy-Weighted Experience Replay**|Shan Jiang Team|[2507.00042](http://arxiv.org/abs/2507.00042)|null|
|**2025-06-30**|**Ella: Embodied Social Agents with Lifelong Memory**|Chuang Gan Team|[2506.24019](http://arxiv.org/abs/2506.24019)|null|
|**2025-06-26**|**GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding**|Bihan Wen Team|[2506.21188](http://arxiv.org/abs/2506.21188)|null|
|**2025-06-26**|**FedDAA: Dynamic Client Clustering for Concept Drift Adaptation in Federated Learning**|Ming Tang Team|[2506.21054](http://arxiv.org/abs/2506.21054)|null|
|**2025-06-25**|**THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion**|Calin Teodor Ioan Team|[2506.20877](http://arxiv.org/abs/2506.20877)|null|
|**2025-06-26**|**From Memories to Maps: Mechanisms of In-Context Reinforcement Learning in Transformers**|Kanaka Rajan Team|[2506.19686](http://arxiv.org/abs/2506.19686)|null|
|**2025-07-03**|**Reliability-Adjusted Prioritized Experience Replay**|Maximilian Schiffer Team|[2506.18482](http://arxiv.org/abs/2506.18482)|null|
|**2025-06-22**|**Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation**|Teng Li Team|[2506.18158](http://arxiv.org/abs/2506.18158)|null|

<p align=right>(<a href=#updated-on-20250716>back to top</a>)</p>

## Temporal Understanding

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-14**|**T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs**|Guillaume Rabusseau Team|[2507.10183](http://arxiv.org/abs/2507.10183)|null|
|**2025-07-13**|**GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them?**|Huaxiu Yao Team|[2507.09491](http://arxiv.org/abs/2507.09491)|null|
|**2025-07-12**|**Online Long-term Point Tracking in the Foundation Model Era**|GÃ¶rkay Aydemir Team|[2507.09217](http://arxiv.org/abs/2507.09217)|null|
|**2025-07-10**|**OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding**|Jiangmiao Pang Team|[2507.07984](http://arxiv.org/abs/2507.07984)|null|
|**2025-07-10**|**Scaling RL to Long Videos**|Song Han Team|[2507.07966](http://arxiv.org/abs/2507.07966)|null|
|**2025-07-09**|**Temporal Information Retrieval via Time-Specifier Model Merging**|Jong C. Park Team|[2507.06782](http://arxiv.org/abs/2507.06782)|null|
|**2025-07-08**|**DocTalk: Scalable Graph-based Dialogue Synthesis for Enhancing LLM Conversational Capabilities**|Haodong Wang Team|[2507.05750](http://arxiv.org/abs/2507.05750)|null|
|**2025-07-07**|**HV-MMBench: Benchmarking MLLMs for Human-Centric Video Understanding**|Xiang Bai Team|[2507.04909](http://arxiv.org/abs/2507.04909)|null|
|**2025-07-07**|**Tempo-R0: A Video-MLLM for Temporal Video Grounding through Efficient Temporal Sensing Reinforcement Learning**|Rong Shen Team|[2507.04702](http://arxiv.org/abs/2507.04702)|null|
|**2025-07-09**|**Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models**|Changliang Xu Team|[2507.03916](http://arxiv.org/abs/2507.03916)|null|
|**2025-07-08**|**Future Slot Prediction for Unsupervised Object Discovery in Surgical Video**|Daniel A. Hashimoto Team|[2507.01882](http://arxiv.org/abs/2507.01882)|null|
|**2025-07-01**|**CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs**|Wei Yang Bryan Lim Team|[2507.00817](http://arxiv.org/abs/2507.00817)|null|
|**2025-07-01**|**Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving**|Yadan Luo Team|[2507.00525](http://arxiv.org/abs/2507.00525)|null|
|**2025-06-28**|**MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding**|Daniel Tang Team|[2507.00068](http://arxiv.org/abs/2507.00068)|null|
|**2025-06-30**|**Flash-VStream: Efficient Real-Time Understanding for Long Video Streams**|Xiaojie Jin Team|[2506.23825](http://arxiv.org/abs/2506.23825)|null|
|**2025-07-01**|**Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning**|Ark Abhyudaya Team|[2506.22919](http://arxiv.org/abs/2506.22919)|null|
|**2025-06-28**|**AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results**|Saeid Rezaei Team|[2506.22843](http://arxiv.org/abs/2506.22843)|null|
|**2025-06-26**|**GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding**|Bihan Wen Team|[2506.21188](http://arxiv.org/abs/2506.21188)|null|
|**2025-06-25**|**A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs**|Jingyuan Wang Team|[2506.20073](http://arxiv.org/abs/2506.20073)|null|
|**2025-06-24**|**JCAPT: A Joint Modeling Approach for CAPT**|Berlin Chen Team|[2506.19315](http://arxiv.org/abs/2506.19315)|null|
|**2025-06-23**|**TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting**|Ertai E Team|[2506.18862](http://arxiv.org/abs/2506.18862)|null|
|**2025-06-23**|**T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent**|Hong Qing Yu Team|[2506.18559](http://arxiv.org/abs/2506.18559)|null|
|**2025-06-21**|**Machine Learning Model Integration with Open World Temporal Logic for Process Automation**|Paulo Shakarian Team|[2506.17776](http://arxiv.org/abs/2506.17776)|null|
|**2025-06-17**|**A Vision for Geo-Temporal Deep Research Systems: Towards Comprehensive, Transparent, and Reproducible Geo-Temporal Information Synthesis**|Piotr Gramacki Team|[2506.14345](http://arxiv.org/abs/2506.14345)|null|
|**2025-06-24**|**DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs**|Feng-Chi Chen Team|[2506.11558](http://arxiv.org/abs/2506.11558)|null|
|**2025-06-12**|**VRBench: A Benchmark for Multi-Step Reasoning in Long Narrative Videos**|Limin Wang Team|[2506.10857](http://arxiv.org/abs/2506.10857)|null|

<p align=right>(<a href=#updated-on-20250716>back to top</a>)</p>

## Robot Datasets

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-14**|**Devanagari Handwritten Character Recognition using Convolutional Neural Network**|Prateek Mehta Team|[2507.10398](http://arxiv.org/abs/2507.10398)|null|
|**2025-07-11**|**Learning human-to-robot handovers through 3D scene reconstruction**|Changjae Oh Team|[2507.08726](http://arxiv.org/abs/2507.08726)|null|
|**2025-07-09**|**Evaluating Large Multimodal Models for Nutrition Analysis: A Benchmark Enriched with Contextual Metadata**|Fengqing Zhu Team|[2507.07048](http://arxiv.org/abs/2507.07048)|null|
|**2025-07-08**|**Is Diversity All You Need for Scalable Robotic Manipulation?**|Hongyang Li Team|[2507.06219](http://arxiv.org/abs/2507.06219)|null|
|**2025-07-07**|**A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation**|Russ Tedrake Team|[2507.05331](http://arxiv.org/abs/2507.05331)|null|
|**2025-07-04**|**Efficient and Effective Query Context-Aware Learning-to-Rank Model for Sequential Recommendation**|Marjan Celikik Team|[2507.03789](http://arxiv.org/abs/2507.03789)|null|
|**2025-07-03**|**MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real**|Alexei A. Efros Team|[2507.02864](http://arxiv.org/abs/2507.02864)|null|
|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Yanwei Fu Team|[2507.01424](http://arxiv.org/abs/2507.01424)|null|
|**2025-07-01**|**Geometry-aware 4D Video Generation for Robot Manipulation**|Shuran Song Team|[2507.01099](http://arxiv.org/abs/2507.01099)|null|
|**2025-07-01**|**HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning**|Chenjia Bai Team|[2507.00833](http://arxiv.org/abs/2507.00833)|null|
|**2025-07-01**|**The impact of the following vehicles behaviors on the car following behaviors of the ego-vehicle**|Dengbo He Team|[2507.00452](http://arxiv.org/abs/2507.00452)|null|
|**2025-06-27**|**MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages**|Dorothea Kolossa Team|[2506.22529](http://arxiv.org/abs/2506.22529)|null|
|**2025-06-27**|**4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration**|Li Zhang Team|[2506.22242](http://arxiv.org/abs/2506.22242)|null|
|**2025-07-08**|**BÃ©zierGS: Dynamic Urban Scene Reconstruction with BÃ©zier Curve Gaussian Splatting**|Li Zhang Team|[2506.22099](http://arxiv.org/abs/2506.22099)|null|
|**2025-06-25**|**DemoDiffusion: One-Shot Human Imitation using pre-trained Diffusion Policy**|Shubham Tulsiani Team|[2506.20668](http://arxiv.org/abs/2506.20668)|null|
|**2025-06-24**|**ConStellaration: A dataset of QI-like stellarator plasma boundaries and optimization benchmarks**|Markus Kaiser Team|[2506.19583](http://arxiv.org/abs/2506.19583)|null|
|**2025-06-23**|**CUPID: Curating Data your Robot Loves with Influence Functions**|Jeannette Bohg Team|[2506.19121](http://arxiv.org/abs/2506.19121)|null|
|**2025-06-20**|**LLM-Generated Feedback Supports Learning If Learners Choose to Use It**|Kenneth R. Koedinger Team|[2506.17006](http://arxiv.org/abs/2506.17006)|**[link](https://github.com/conradborchers/ai-feedback-exp)**|
|**2025-07-07**|**Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining**|Ding Zhao Team|[2506.16475](http://arxiv.org/abs/2506.16475)|null|
|**2025-06-19**|**CapsDT: Diffusion-Transformer for Capsule Robot Manipulation**|Hongliang Ren Team|[2506.16263](http://arxiv.org/abs/2506.16263)|null|
|**2025-06-17**|**Data Driven Approach to Input Shaping for Vibration Suppression in a Flexible Robot Arm**|Markku Suomalainen Team|[2506.14405](http://arxiv.org/abs/2506.14405)|null|
|**2025-06-16**|**What Matters in Learning from Large-Scale Datasets for Robot Manipulation**|Danfei Xu Team|[2506.13536](http://arxiv.org/abs/2506.13536)|null|
|**2025-06-11**|**R-CARLA: High-Fidelity Sensor Simulations with Interchangeable Dynamics for Autonomous Racing**|Michele Magno Team|[2506.09629](http://arxiv.org/abs/2506.09629)|null|

<p align=right>(<a href=#updated-on-20250716>back to top</a>)</p>

## Multi-task Learning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-14**|**National level satellite-based crop field inventories in smallholder landscapes**|Patrick Meyfroidt Team|[2507.10499](http://arxiv.org/abs/2507.10499)|null|
|**2025-07-14**|**Toward Real-World Table Agents: Capabilities, Workflows, and Design Principles for LLM-based Table Intelligence**|Junbo Zhao Team|[2507.10281](http://arxiv.org/abs/2507.10281)|null|
|**2025-07-14**|**Minimizing the Pretraining Gap: Domain-aligned Text-Based Person Retrieval**|Zhedong Zheng Team|[2507.10195](http://arxiv.org/abs/2507.10195)|null|
|**2025-07-14**|**Domain Borders Are There to Be Crossed With Federated Few-Shot Adaptation**|Frank-Michael Schleif Team|[2507.10160](http://arxiv.org/abs/2507.10160)|null|
|**2025-07-14**|**A Transfer Learning-Based Method for Water Body Segmentation in Remote Sensing Imagery: A Case Study of the Zhada Tulin Area**|Xin Tong Team|[2507.10084](http://arxiv.org/abs/2507.10084)|null|
|**2025-07-14**|**Leveraging Swin Transformer for enhanced diagnosis of Alzheimer's disease using multi-shell diffusion MRI**|BenoÃ®t Macq Team|[2507.09996](http://arxiv.org/abs/2507.09996)|null|
|**2025-07-14**|**Statistical Inference for Conditional Group Distributionally Robust Optimization with Cross-Entropy Loss**|Francis Bach Team|[2507.09905](http://arxiv.org/abs/2507.09905)|null|
|**2025-07-13**|**Low-Rank Adaptation of Deep Prior Neural Networks For Room Impulse Response Reconstruction**|Fabio Antonacci Team|[2507.09806](http://arxiv.org/abs/2507.09806)|null|
|**2025-07-13**|**Pre-trained Under Noise: A Framework for Robust Bone Fracture Detection in Medical Imaging**|Chengcheng Li Team|[2507.09731](http://arxiv.org/abs/2507.09731)|null|
|**2025-07-13**|**Hybrid Quantum-Classical Generative Adversarial Networks with Transfer Learning**|Ebrahim Ardeshir Larijani Team|[2507.09706](http://arxiv.org/abs/2507.09706)|null|
|**2025-07-13**|**NMIXX: Domain-Adapted Neural Embeddings for Cross-Lingual eXploration of Finance**|Youngjae Yu Team|[2507.09601](http://arxiv.org/abs/2507.09601)|null|
|**2025-07-13**|**Enhancing ALS Progression Tracking with Semi-Supervised ALSFRS-R Scores Estimated from Ambient Home Health Monitoring**|Xing Song Team|[2507.09460](http://arxiv.org/abs/2507.09460)|null|
|**2025-07-12**|**Domain Adaptation and Multi-view Attention for Learnable Landmark Tracking with Sparse Data**|Karthik Dantu Team|[2507.09420](http://arxiv.org/abs/2507.09420)|null|
|**2025-07-12**|**EduFlow: Advancing MLLMs' Problem-Solving Proficiency through Multi-Stage, Multi-Perspective Critique**|Jian Xie Team|[2507.09374](http://arxiv.org/abs/2507.09374)|null|
|**2025-07-12**|**Simplifying Traffic Anomaly Detection with Video Foundation Models**|Gijs Dubbelman Team|[2507.09338](http://arxiv.org/abs/2507.09338)|null|
|**2025-07-12**|**Calibrated and Robust Foundation Models for Vision-Language and Medical Image Tasks Under Distribution Shift**|Tahir Syed Team|[2507.09222](http://arxiv.org/abs/2507.09222)|null|
|**2025-07-12**|**CycleGAN-Driven Transfer Learning for Electronics Response Emulation in High-Purity Germanium Detectors**|Aobo Li Team|[2507.09106](http://arxiv.org/abs/2507.09106)|null|
|**2025-07-11**|**Domain Adaptation-Enabled Realistic Map-Based Channel Estimation for MIMO-OFDM**|Georges Kaddoum Team|[2507.08974](http://arxiv.org/abs/2507.08974)|null|
|**2025-07-11**|**The Bayesian Approach to Continual Learning: An Overview**|Tameem Adel Team|[2507.08922](http://arxiv.org/abs/2507.08922)|null|
|**2025-07-15**|**Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning**|Tao Chen Team|[2507.08730](http://arxiv.org/abs/2507.08730)|null|
|**2025-07-11**|**From Enhancement to Understanding: Build a Generalized Bridge for Low-light Vision via Semantically Consistent Unsupervised Fine-tuning**|Lizhuang Ma Team|[2507.08380](http://arxiv.org/abs/2507.08380)|null|
|**2025-07-11**|**MM-Gesture: Towards Precise Micro-Gesture Recognition through Multimodal Fusion**|Dan Guo Team|[2507.08344](http://arxiv.org/abs/2507.08344)|null|
|**2025-07-11**|**Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment**|Lamei Zhang Team|[2507.08290](http://arxiv.org/abs/2507.08290)|null|
|**2025-07-11**|**Transfer Learning and Mixup for Fine-Grained Few-Shot Fungi Classification**|Anthony Miyaguchi Team|[2507.08248](http://arxiv.org/abs/2507.08248)|null|
|**2025-07-10**|**An Embedded Real-time Object Alert System for Visually Impaired: A Monocular Depth Estimation based Approach through Computer Vision**|Md. Ishan Arefin Hossain Team|[2507.08165](http://arxiv.org/abs/2507.08165)|null|
|**2025-07-10**|**An Object-Based Deep Learning Approach for Building Height Estimation from Single SAR Images**|Paolo Gamba Team|[2507.08096](http://arxiv.org/abs/2507.08096)|null|
|**2025-07-08**|**Self-Consistency in Vision-Language Models for Precision Agriculture: Multi-Response Consensus for Crop Disease Management**|Pratik Desai Team|[2507.08024](http://arxiv.org/abs/2507.08024)|null|
|**2025-07-11**|**Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection**|Yi-Zhe Song Team|[2507.07994](http://arxiv.org/abs/2507.07994)|null|
|**2025-07-10**|**Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal Inconsistency for Remote Physiological Measurement**|Dengbo He Team|[2507.07908](http://arxiv.org/abs/2507.07908)|null|
|**2025-07-10**|**BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning**|Yize Chen Team|[2507.07769](http://arxiv.org/abs/2507.07769)|null|
|**2025-07-10**|**Sparse Causal Discovery with Generative Intervention for Unsupervised Graph Domain Adaptation**|Ming Zhang Team|[2507.07621](http://arxiv.org/abs/2507.07621)|null|
|**2025-07-08**|**CoPT: Unsupervised Domain Adaptive Segmentation using Domain-Agnostic Text Embeddings**|Michael S. Ryoo Team|[2507.07125](http://arxiv.org/abs/2507.07125)|null|
|**2025-07-09**|**Deep Brain Net: An Optimized Deep Learning Model for Brain tumor Detection in MRI Images Using EfficientNetB0 and ResNet50 with Transfer Learning**|Ravish Desai Team|[2507.07011](http://arxiv.org/abs/2507.07011)|null|
|**2025-07-10**|**ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining**|Byoung-Ki Jeon Team|[2507.06795](http://arxiv.org/abs/2507.06795)|null|
|**2025-07-09**|**Tailoring deep learning for real-time brain-computer interfaces: From offline models to calibration-free online decoding**|Bin Yang Team|[2507.06779](http://arxiv.org/abs/2507.06779)|null|
|**2025-07-09**|**On the Hardness of Unsupervised Domain Adaptation: Optimal Learners and Information-Theoretic Perspective**|Yongyi Mao Team|[2507.06552](http://arxiv.org/abs/2507.06552)|null|
|**2025-07-08**|**Bridging Data Gaps of Rare Conditions in ICU: A Multi-Disease Adaptation Approach for Clinical Prediction**|Tingting Zhu Team|[2507.06432](http://arxiv.org/abs/2507.06432)|null|
|**2025-07-08**|**Mitigating Multi-Sequence 3D Prostate MRI Data Scarcity through Domain Adaptation using Locally-Trained Latent Diffusion Models for Prostate Cancer Detection**|Masoom A. Haider Team|[2507.06384](http://arxiv.org/abs/2507.06384)|null|
|**2025-07-08**|**DS@GT at CheckThat! 2025: Detecting Subjectivity via Transfer-Learning and Corrective Data Augmentation**|Dionne Bang Team|[2507.06189](http://arxiv.org/abs/2507.06189)|null|
|**2025-07-09**|**A Survey on Prompt Tuning**|Nigel Collier Team|[2507.06085](http://arxiv.org/abs/2507.06085)|null|
|**2025-07-08**|**Contrastive and Transfer Learning for Effective Audio Fingerprinting through a Real-World Evaluation Protocol**|Theodoros Giannakopoulos Team|[2507.06070](http://arxiv.org/abs/2507.06070)|null|
|**2025-07-08**|**Improving Robustness of Foundation Models in Domain Adaptation with Soup-Adapters**|Marco Roschkowski Team|[2507.05807](http://arxiv.org/abs/2507.05807)|null|
|**2025-07-08**|**PSAT: Pediatric Segmentation Approaches via Adult Augmentations and Transfer Learning**|Philippe Meyer Team|[2507.05764](http://arxiv.org/abs/2507.05764)|null|
|**2025-07-08**|**Domain adaptation of large language models for geotechnical applications**|Cheng Chen Team|[2507.05613](http://arxiv.org/abs/2507.05613)|null|
|**2025-07-07**|**Predicting mutational effects on protein binding from folding energy**|Brian Trippe Team|[2507.05502](http://arxiv.org/abs/2507.05502)|null|
|**2025-07-07**|**YOLO-APD: Enhancing YOLOv8 for Robust Pedestrian Detection on Complex Road Geometries**|John Kandiri Team|[2507.05376](http://arxiv.org/abs/2507.05376)|null|
|**2025-07-07**|**Conditional Graph Neural Network for Predicting Soft Tissue Deformation and Forces**|Philippe C. Cattin Team|[2507.05315](http://arxiv.org/abs/2507.05315)|null|
|**2025-07-07**|**$\varphi$ -Adapt: A Physics-Informed Adaptation Learning Approach to 2D Quantum Material Discovery**|Khoa Luu Team|[2507.05184](http://arxiv.org/abs/2507.05184)|null|
|**2025-07-07**|**O_FT@EvalLLM2025 : Ã©tude comparative de choix de donnÃ©es et de stratÃ©gies d'apprentissage pour l'adaptation de modÃ¨les de langue Ã  un domaine**|GÃ©raldine Damnati Team|[2507.04895](http://arxiv.org/abs/2507.04895)|null|
|**2025-07-07**|**HGNet: High-Order Spatial Awareness Hypergraph and Multi-Scale Context Attention Network for Colorectal Polyp Detection**|Bin zhao Team|[2507.04880](http://arxiv.org/abs/2507.04880)|null|
|**2025-07-07**|**Towards Human-in-the-Loop Onset Detection: A Transfer Learning Approach for Maracatu**|AntÃ³nio SÃ¡ Pinto Team|[2507.04858](http://arxiv.org/abs/2507.04858)|null|
|**2025-07-07**|**Model Compression using Progressive Channel Pruning**|Dong Xu Team|[2507.04792](http://arxiv.org/abs/2507.04792)|null|
|**2025-07-07**|**Interaction-Merged Motion Planning: Effectively Leveraging Diverse Motion Datasets for Robust Planning**|Kuk-Jin Yoon Team|[2507.04790](http://arxiv.org/abs/2507.04790)|null|
|**2025-07-07**|**An analysis of vision-language models for fabric retrieval**|Fabio Poiesi Team|[2507.04735](http://arxiv.org/abs/2507.04735)|null|
|**2025-07-06**|**Transfer Learning in Infinite Width Feature Learning Networks**|Cengiz Pehlevan Team|[2507.04448](http://arxiv.org/abs/2507.04448)|null|
|**2025-07-06**|**Domain Adaptation of Drag Reduction Policy to Partial Measurements**|Georgios Rigas Team|[2507.04309](http://arxiv.org/abs/2507.04309)|null|
|**2025-07-06**|**Mixed-Sample SGD: an End-to-end Analysis of Supervised Transfer Learning**|Samory Kpotufe Team|[2507.04194](http://arxiv.org/abs/2507.04194)|null|
|**2025-07-05**|**When Data-Free Knowledge Distillation Meets Non-Transferable Teacher: Escaping Out-of-Distribution Trap is All You Need**|Tongliang Liu Team|[2507.04119](http://arxiv.org/abs/2507.04119)|null|

<p align=right>(<a href=#updated-on-20250716>back to top</a>)</p>

## Robot Foundation Models

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-14**|**Foundation Model Driven Robotics: A Comprehensive Review**|Ammar Waheed Team|[2507.10087](http://arxiv.org/abs/2507.10087)|null|
|**2025-07-14**|**Hand Gesture Recognition for Collaborative Robots Using Lightweight Deep Learning in Real-Time Robotic Systems**|Mauridhi Hery Purnomo Team|[2507.10055](http://arxiv.org/abs/2507.10055)|null|
|**2025-07-07**|**A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation**|Russ Tedrake Team|[2507.05331](http://arxiv.org/abs/2507.05331)|null|
|**2025-06-30**|**World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation**|Lin Shao Team|[2506.23919](http://arxiv.org/abs/2506.23919)|null|
|**2025-06-24**|**Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI**|Dongzhan Zhou Team|[2506.19613](http://arxiv.org/abs/2506.19613)|null|
|**2025-06-21**|**Risk-Guided Diffusion: Toward Deploying Robot Foundation Models in Space, Where Failure Is Not An Option**|Shehryar Khattak Team|[2506.17601](http://arxiv.org/abs/2506.17601)|null|
|**2025-06-20**|**General-Purpose Robotic Navigation via LVLM-Orchestrated Perception, Reasoning, and Acting**|Georgios Georgakis Team|[2506.17462](http://arxiv.org/abs/2506.17462)|null|
|**2025-06-13**|**mimic-one: a Scalable Model Recipe for General Purpose Robot Dexterity**|Robert K. Katzschmann Team|[2506.11916](http://arxiv.org/abs/2506.11916)|null|
|**2025-05-28**|**ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation**|Wenqiang Zhang Team|[2505.22159](http://arxiv.org/abs/2505.22159)|null|
|**2025-05-29**|**ChatVLA-2: Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge**|Yi Xu Team|[2505.21906](http://arxiv.org/abs/2505.21906)|null|
|**2025-06-16**|**PartInstruct: Part-level Instruction Following for Fine-grained Robot Manipulation**|Tianmin Shu Team|[2505.21652](http://arxiv.org/abs/2505.21652)|null|
|**2025-07-08**|**Hume: Introducing System-2 Thinking in Visual-Language-Action Model**|Xuelong Li Team|[2505.21432](http://arxiv.org/abs/2505.21432)|null|
|**2025-05-27**|**Think Twice, Act Once: Token-Aware Compression and Action Reuse for Efficient Inference in Vision-Language-Action Models**|Tao Chen Team|[2505.21200](http://arxiv.org/abs/2505.21200)|null|
|**2025-05-27**|**Spatial RoboGrasp: Generalized Robotic Grasping Control Policy**|Luhui Hu Team|[2505.20814](http://arxiv.org/abs/2505.20814)|null|
|**2025-06-03**|**EgoZero: Robot Learning from Smart Glasses**|Lerrel Pinto Team|[2505.20290](http://arxiv.org/abs/2505.20290)|null|
|**2025-05-21**|**WaveTouch: Active Tactile Sensing Using Vibro-Feedback for Classification of Variable Stiffness and Infill Density Objects**|Bakhtiyar Orazbayev Team|[2505.16062](http://arxiv.org/abs/2505.16062)|null|
|**2025-05-24**|**Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization**|Junwei Liang Team|[2505.15660](http://arxiv.org/abs/2505.15660)|**[link](https://github.com/jiaming-zhou/X-ICM)**|
|**2025-05-24**|**RoboCulture: A Robotics Platform for Automated Biological Experimentation**|Milica Radisic Team|[2505.14941](http://arxiv.org/abs/2505.14941)|null|
|**2025-05-22**|**InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning**|Jingkuan Song Team|[2505.13888](http://arxiv.org/abs/2505.13888)|**[link](https://github.com/inspirevla/inspire)**|
|**2025-05-22**|**Policy Contrastive Decoding for Robotic Foundation Models**|Lianli Gao Team|[2505.13255](http://arxiv.org/abs/2505.13255)|**[link](https://github.com/Koorye/PCD)**|
|**2025-05-17**|**OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning**|Yang Gao Team|[2505.11917](http://arxiv.org/abs/2505.11917)|null|
|**2025-05-15**|**Towards Safe Robot Foundation Models Using Inductive Biases**|Jan Peters Team|[2505.10219](http://arxiv.org/abs/2505.10219)|null|

<p align=right>(<a href=#updated-on-20250716>back to top</a>)</p>

## Vision Language Models

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-14**|**EmbRACE-3K: Embodied Reasoning and Action in Complex Environments**|Xiaojuan Qi Team|[2507.10548](http://arxiv.org/abs/2507.10548)|null|
|**2025-07-14**|**CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding**|Yi Wang Team|[2507.10449](http://arxiv.org/abs/2507.10449)|null|
|**2025-07-14**|**Beyond Graph Model: Reliable VLM Fine-Tuning via Random Graph Adapter**|Bin Luo Team|[2507.10355](http://arxiv.org/abs/2507.10355)|null|
|**2025-07-14**|**Synthesizing Near-Boundary OOD Samples for Out-of-Distribution Detection**|Wenqiang Zhang Team|[2507.10225](http://arxiv.org/abs/2507.10225)|null|
|**2025-07-14**|**BlueGlass: A Framework for Composite AI Safety**|Kay-Ulrich Scholl Team|[2507.10106](http://arxiv.org/abs/2507.10106)|null|
|**2025-07-14**|**Foundation Model Driven Robotics: A Comprehensive Review**|Ammar Waheed Team|[2507.10087](http://arxiv.org/abs/2507.10087)|null|
|**2025-07-14**|**LayLens: Improving Deepfake Understanding through Simplified Explanations**|Abhinav Dhall Team|[2507.10066](http://arxiv.org/abs/2507.10066)|null|
|**2025-07-14**|**CoSMo: A Multimodal Transformer for Page Stream Segmentation in Comic Books**|Dimosthenis Karatzas Team|[2507.10053](http://arxiv.org/abs/2507.10053)|null|
|**2025-07-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Zhen Lei Team|[2507.09961](http://arxiv.org/abs/2507.09961)|null|
|**2025-07-13**|**NegRefine: Refining Negative Label-Based Zero-Shot OOD Detection**|Pulei Xiong Team|[2507.09795](http://arxiv.org/abs/2507.09795)|null|
|**2025-07-13**|**Towards Fine-Grained Adaptation of CLIP via a Self-Trained Alignment Score**|Muhammad Haris Khan Team|[2507.09615](http://arxiv.org/abs/2507.09615)|null|
|**2025-07-13**|**Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations**|Guiguang Ding Team|[2507.09500](http://arxiv.org/abs/2507.09500)|null|
|**2025-07-13**|**GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them?**|Huaxiu Yao Team|[2507.09491](http://arxiv.org/abs/2507.09491)|null|
|**2025-07-12**|**Uncertainty-Driven Expert Control: Enhancing the Reliability of Medical Vision-Language Models**|Tat-Seng Chua Team|[2507.09209](http://arxiv.org/abs/2507.09209)|null|
|**2025-07-12**|**MCA-LLaVA: Manhattan Causal Attention for Reducing Hallucination in Large Vision-Language Models**|Dahan Wang Team|[2507.09184](http://arxiv.org/abs/2507.09184)|null|
|**2025-07-12**|**OPENXRD: A Comprehensive Benchmark and Enhancement Framework for LLM/MLLM XRD Question Answering**|Niaz Abdolrahim Team|[2507.09155](http://arxiv.org/abs/2507.09155)|null|
|**2025-07-12**|**RadEyeVideo: Enhancing general-domain Large Vision Language Model for chest X-ray analysis with video representations of eye gaze**|Honghan Wu Team|[2507.09097](http://arxiv.org/abs/2507.09097)|null|
|**2025-07-11**|**BlindSight: Harnessing Sparsity for Efficient VLMs**|Steven K. Reinhardt Team|[2507.09071](http://arxiv.org/abs/2507.09071)|null|
|**2025-07-11**|**Beyond vividness: Content analysis of induced hallucinations reveals the hidden structure of individual differences in visual imagery**|Seana Coulson Team|[2507.09011](http://arxiv.org/abs/2507.09011)|null|
|**2025-07-11**|**VIP: Visual Information Protection through Adversarial Attacks on Vision-Language Models**|Olivier DÃ©forges Team|[2507.08982](http://arxiv.org/abs/2507.08982)|null|
|**2025-07-11**|**ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way**|Subarna Tripathi Team|[2507.08679](http://arxiv.org/abs/2507.08679)|null|
|**2025-07-11**|**Adaptive Framework for Ambient Intelligence in Rehabilitation Assistance**|AndrÃ¡s LÅrincz Team|[2507.08624](http://arxiv.org/abs/2507.08624)|null|
|**2025-07-11**|**Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data**|Ambedkar Dukkipati Team|[2507.08610](http://arxiv.org/abs/2507.08610)|null|
|**2025-07-11**|**BayesTTA: Continual-Temporal Test-Time Adaptation for Vision-Language Models via Gaussian Discriminant Analysis**|Hui Xiong Team|[2507.08607](http://arxiv.org/abs/2507.08607)|null|
|**2025-07-11**|**Efficient Deployment of Vision-Language Models on Mobile Devices: A Case Study on OnePlus 13R**|Sanidhya Kashyap Team|[2507.08505](http://arxiv.org/abs/2507.08505)|null|
|**2025-07-11**|**LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning**|Lei Fan Team|[2507.08496](http://arxiv.org/abs/2507.08496)|null|
|**2025-07-11**|**Multi-modal Mutual-Guidance Conditional Prompt Learning for Vision-Language Models**|Jianping Fan Team|[2507.08410](http://arxiv.org/abs/2507.08410)|null|
|**2025-07-11**|**Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level Procedural Reasoning**|Yejin Choi Team|[2507.08224](http://arxiv.org/abs/2507.08224)|null|
|**2025-07-10**|**CLIP Won't Learn Object-Attribute Binding from Natural Data and Here is Why**|Thomas Brox Team|[2507.07985](http://arxiv.org/abs/2507.07985)|null|
|**2025-07-10**|**Scaling RL to Long Videos**|Song Han Team|[2507.07966](http://arxiv.org/abs/2507.07966)|null|
|**2025-07-10**|**SAGE: A Visual Language Model for Anomaly Detection via Fact Enhancement and Entropy-aware Alignment**|Lei Fan Team|[2507.07939](http://arxiv.org/abs/2507.07939)|null|
|**2025-07-10**|**MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving**|Chao Zhang Team|[2507.07818](http://arxiv.org/abs/2507.07818)|null|
|**2025-07-10**|**Energy-Guided Decoding for Object Hallucination Mitigation**|Christopher Zach Team|[2507.07731](http://arxiv.org/abs/2507.07731)|null|
|**2025-07-10**|**One Object, Multiple Lies: A Benchmark for Cross-task Adversarial Attack on Unified Vision-Language Models**|Cairong Zhao Team|[2507.07709](http://arxiv.org/abs/2507.07709)|null|
|**2025-07-10**|**Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought**|Daiki Chijiwa Team|[2507.07685](http://arxiv.org/abs/2507.07685)|null|
|**2025-07-11**|**ViLU: Learning Vision-Language Uncertainties for Failure Prediction**|Nicolas Thome Team|[2507.07620](http://arxiv.org/abs/2507.07620)|null|
|**2025-07-10**|**LOSC: LiDAR Open-voc Segmentation Consolidator**|Renaud Marlet Team|[2507.07605](http://arxiv.org/abs/2507.07605)|null|
|**2025-07-10**|**The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs**|Qun Liu Team|[2507.07562](http://arxiv.org/abs/2507.07562)|null|
|**2025-07-10**|**ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing**|Markus Huff Team|[2507.07551](http://arxiv.org/abs/2507.07551)|null|
|**2025-07-11**|**Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning**|David Martins de Matos Team|[2507.07340](http://arxiv.org/abs/2507.07340)|null|
|**2025-07-09**|**ADIEE: Automatic Dataset Creation and Scorer for Instruction-Guided Image Editing Evaluation**|Suren Kumar Team|[2507.07317](http://arxiv.org/abs/2507.07317)|null|
|**2025-07-09**|**LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation**|Angel X. Chang Team|[2507.07299](http://arxiv.org/abs/2507.07299)|null|
|**2025-07-09**|**MagiC: Evaluating Multimodal Cognition Toward Grounded Visual Reasoning**|Dan Goldwasser Team|[2507.07297](http://arxiv.org/abs/2507.07297)|null|
|**2025-07-09**|**4KAgent: Agentic Any Image to 4K Super-Resolution**|Zhengzhong Tu Team|[2507.07105](http://arxiv.org/abs/2507.07105)|null|
|**2025-07-11**|**Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models**|Junfei Xiao Team|[2507.07104](http://arxiv.org/abs/2507.07104)|null|
|**2025-07-09**|**Evaluating Attribute Confusion in Fashion Text-to-Image Generation**|Davide Talon Team|[2507.07079](http://arxiv.org/abs/2507.07079)|null|
|**2025-07-09**|**Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM**|Sibei Yang Team|[2507.06973](http://arxiv.org/abs/2507.06973)|null|
|**2025-07-09**|**CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale**|Quan Wang Team|[2507.06959](http://arxiv.org/abs/2507.06959)|null|
|**2025-07-09**|**VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation**|Tat-Seng Chua Team|[2507.06899](http://arxiv.org/abs/2507.06899)|null|
|**2025-07-09**|**HVI-CIDNet+: Beyond Extreme Darkness for Low-Light Image Enhancement**|Yanning Zhang Team|[2507.06814](http://arxiv.org/abs/2507.06814)|null|
|**2025-07-09**|**Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu**|Donghyeok Choi Team|[2507.06761](http://arxiv.org/abs/2507.06761)|null|
|**2025-07-09**|**Text-promptable Object Counting via Quantity Awareness Enhancement**|Li Li Team|[2507.06679](http://arxiv.org/abs/2507.06679)|null|
|**2025-07-09**|**Cross-Modal Dual-Causal Learning for Long-Term Action Recognition**|Fan Chao Team|[2507.06603](http://arxiv.org/abs/2507.06603)|null|
|**2025-07-09**|**Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection**|Xiangmin Xu Team|[2507.06510](http://arxiv.org/abs/2507.06510)|null|
|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Nick Haber Team|[2507.06484](http://arxiv.org/abs/2507.06484)|null|
|**2025-07-08**|**VisioPath: Vision-Language Enhanced Model Predictive Control for Safe Autonomous Navigation in Mixed Traffic**|Andreas A. Malikopoulos Team|[2507.06441](http://arxiv.org/abs/2507.06441)|null|
|**2025-07-08**|**CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions**|Yi R. Fung Team|[2507.06210](http://arxiv.org/abs/2507.06210)|null|
|**2025-07-08**|**Enhancing Scientific Visual Question Answering through Multimodal Reasoning and Ensemble Modeling**|Naga Harshita Marupaka Team|[2507.06183](http://arxiv.org/abs/2507.06183)|null|
|**2025-07-10**|**Skywork-R1V3 Technical Report**|Yahui Zhou Team|[2507.06167](http://arxiv.org/abs/2507.06167)|null|
|**2025-07-08**|**LangMamba: A Language-driven Mamba Framework for Low-dose CT Denoising with Vision-language Models**|Hongming Shan Team|[2507.06140](http://arxiv.org/abs/2507.06140)|null|
|**2025-07-08**|**GeoMag: A Vision-Language Model for Pixel-level Fine-Grained Remote Sensing Image Parsing**|Hao Liu Team|[2507.05887](http://arxiv.org/abs/2507.05887)|null|
|**2025-07-08**|**Bridging Perception and Language: A Systematic Benchmark for LVLMs' Understanding of Amodal Completion Reports**|Hitomi Yanaka Team|[2507.05799](http://arxiv.org/abs/2507.05799)|null|
|**2025-07-08**|**SPADE: Spatial-Aware Denoising Network for Open-vocabulary Panoptic Scene Graph Generation with Long- and Local-range Context Reasoning**|Tao He Team|[2507.05798](http://arxiv.org/abs/2507.05798)|null|
|**2025-07-08**|**A Satellite-Ground Synergistic Large Vision-Language Model System for Earth Observation**|Yue Gao Team|[2507.05731](http://arxiv.org/abs/2507.05731)|null|
|**2025-07-09**|**Integrated Structural Prompt Learning for Vision-Language Models**|Bin Luo Team|[2507.05677](http://arxiv.org/abs/2507.05677)|null|
|**2025-07-08**|**R-VLM: Region-Aware Vision Language Model for Precise GUI Grounding**|Shabnam Ghadar Team|[2507.05673](http://arxiv.org/abs/2507.05673)|null|
|**2025-07-08**|**Dynamic Rank Adaptation for Vision-Language Models**|Bin Luo Team|[2507.05668](http://arxiv.org/abs/2507.05668)|null|
|**2025-07-08**|**Structured Task Solving via Modular Embodied Intelligence: A Case Study on Rubik's Cube**|Shenghai Yuan Team|[2507.05607](http://arxiv.org/abs/2507.05607)|null|
|**2025-07-08**|**Rethinking Layered Graphic Design Generation with a Top-Down Approach**|Qifeng Chen Team|[2507.05601](http://arxiv.org/abs/2507.05601)|null|
|**2025-07-08**|**PaddleOCR 3.0 Technical Report**|Yanjun Ma Team|[2507.05595](http://arxiv.org/abs/2507.05595)|null|
|**2025-07-07**|**Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality**|Junxiao Wang Team|[2507.05515](http://arxiv.org/abs/2507.05515)|null|
|**2025-07-07**|**Llama Nemoretriever Colembed: Top-Performing Text-Image Retrieval Model**|Even Oldridge Team|[2507.05513](http://arxiv.org/abs/2507.05513)|null|
|**2025-07-07**|**OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts**|Priyadarshini Panda Team|[2507.05427](http://arxiv.org/abs/2507.05427)|null|
|**2025-07-07**|**pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models**|Ramtin Pedarsani Team|[2507.05394](http://arxiv.org/abs/2507.05394)|null|
|**2025-07-07**|**NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving**|Cheng Lu Team|[2507.05227](http://arxiv.org/abs/2507.05227)|null|
|**2025-07-07**|**All in One: Visual-Description-Guided Unified Point Cloud Segmentation**|Rao Muhammad Anwer Team|[2507.05211](http://arxiv.org/abs/2507.05211)|null|

<p align=right>(<a href=#updated-on-20250716>back to top</a>)</p>

